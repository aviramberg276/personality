{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "personality_classifier",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1vOacBdZw5095jezUMhkX0R0obotVOAbM",
      "authorship_tag": "ABX9TyPuRuU8hYJSmxNoIXcwOBz/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aviramberg276/personality/blob/develop/personality_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzLNDGGNIa-2",
        "colab_type": "code",
        "outputId": "02c7f86e-21d9-405f-f235-d8e18106d817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import hypertools as hyp\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "sb.set(style=\"darkgrid\")\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus: \n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TjWACmsKzbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "database = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data/personality/Aviram_dataset_wide_A.csv\", index_col=[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzNKV-qMLSXD",
        "colab_type": "text"
      },
      "source": [
        "Seperate classes and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC7Lun4sK9A7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = database[database.columns[1:5]]\n",
        "data = database[database.columns[5:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZLD_GqCO50R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.fillna(data.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG0IeLSjLWGp",
        "colab_type": "code",
        "outputId": "b393f451-9ae5-4b06-d466-cb1c665add43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "classes"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AG</th>\n",
              "      <th>Compassion</th>\n",
              "      <th>Respectfulness</th>\n",
              "      <th>Trust</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.083333</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.50</td>\n",
              "      <td>6.00</td>\n",
              "      <td>2.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.333333</td>\n",
              "      <td>5.50</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.750000</td>\n",
              "      <td>5.75</td>\n",
              "      <td>5.25</td>\n",
              "      <td>3.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.416667</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.25</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>4.166667</td>\n",
              "      <td>5.50</td>\n",
              "      <td>3.75</td>\n",
              "      <td>3.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>4.833333</td>\n",
              "      <td>6.75</td>\n",
              "      <td>5.00</td>\n",
              "      <td>2.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>6.666667</td>\n",
              "      <td>6.75</td>\n",
              "      <td>6.75</td>\n",
              "      <td>6.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>5.083333</td>\n",
              "      <td>5.75</td>\n",
              "      <td>5.25</td>\n",
              "      <td>4.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>4.583333</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>225 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           AG  Compassion  Respectfulness  Trust\n",
              "1    5.083333        5.00            5.00   5.25\n",
              "2    5.000000        6.50            6.00   2.50\n",
              "3    5.333333        5.50            5.00   5.50\n",
              "4    4.750000        5.75            5.25   3.25\n",
              "5    4.416667        3.00            5.25   5.00\n",
              "..        ...         ...             ...    ...\n",
              "221  4.166667        5.50            3.75   3.25\n",
              "222  4.833333        6.75            5.00   2.75\n",
              "223  6.666667        6.75            6.75   6.50\n",
              "224  5.083333        5.75            5.25   4.25\n",
              "225  4.583333        5.00            5.00   3.75\n",
              "\n",
              "[225 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxhqerB8ppL8",
        "colab_type": "code",
        "outputId": "3d11c3bd-4c3e-4b9d-c8a0-b121ae6da4a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classes.values.min(), classes.values.max()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 7.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIbvZeAAR8Jn",
        "colab_type": "text"
      },
      "source": [
        "create a loss function that depends on the rules of each trait for example: if a=5 b = b * a/2 ... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv4mLl-VLYgQ",
        "colab_type": "code",
        "outputId": "b7ac4f59-865c-481c-f1e5-ce6e47197973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras.backend as K\n",
        "def custom_loss(layer):\n",
        "\n",
        "    # Create a loss function that adds the MSE loss to the mean of all squared activations of a specific layer\n",
        "    def loss(y_true,y_pred):\n",
        "        return K.mean(K.mean(y_true, axis=0), axis=-1)\n",
        "    return loss\n",
        "\n",
        "val = 0\n",
        "def loss3(y_true,y_pred):\n",
        "    global val\n",
        "    val= K.sum(K.sqrt(y_true -y_pred))\n",
        "    # print(K.sum((y_true -y_pred)**2))\n",
        "    return K.sum((y_true -y_pred)**2)\n",
        "\n",
        "def loss2(y_true,y_pred, num):\n",
        "#         return K.mean(K.square(y_pred - y_true) + K.square(layer), axis=-1)\n",
        "    return (np.abs((y_true - y_test)) < num).sum() / (y_test.shape[0] * y_test.shape[1]) * 100\n",
        "\n",
        "def mapping_to_target_range( x, target_min=1, target_max=7) :\n",
        "    x02 = K.tanh(x) + 1 # x in range(0,2)\n",
        "    scale = ( target_max-target_min )/2.\n",
        "    return  x02 * scale + target_min\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-q1SG36L8i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras import optimizers, regularizers\n",
        "\n",
        "def baseline_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1500, input_dim=2910, kernel_initializer='normal', activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
        "    model.add(Dropout(0.15, seed=np.random.seed(seed)))\n",
        "    model.add(Dense(500, input_dim=1000, kernel_initializer='normal', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
        "    model.add(Dense(200, input_dim=500, kernel_initializer='normal', activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
        "    model.add(Dropout(0.15, seed=np.random.seed(seed)))\n",
        "    model.add(Dense(100, input_dim=160, kernel_initializer='normal', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
        "    model.add(Dense(40, input_dim=100, kernel_initializer='normal', activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
        "    model.add(Dropout(0.15, seed=np.random.seed(seed)))\n",
        "    model.add(Dense(4, kernel_initializer='normal', activation=mapping_to_target_range))\n",
        "    # Compile model\n",
        "    # optimizer = optimizers.Adam(lr=0.0001)\n",
        "    optimizer = optimizers.Adam(lr=0.0001)\n",
        "    model.compile(loss=loss3, optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W8RA_7vXF2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def baseline_model():\n",
        "# \t# create model\n",
        "# \tmodel = Sequential()\n",
        "# \tmodel.add(Dense(4, input_dim=2910, kernel_initializer='normal', activation='relu'))\n",
        "# \tmodel.add(Dense(4, kernel_initializer='normal'))\n",
        "# \t# Compile model\n",
        "# \tmodel.compile(loss=loss3, optimizer='adam')\n",
        "# \treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nH9LLJ8MB_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.compat.v1.keras.backend import set_session\n",
        "from tensorflow.compat.v1.keras.backend import clear_session\n",
        "from tensorflow.compat.v1.keras.backend import get_session\n",
        "# import tensorflow\n",
        "\n",
        "# Reset Keras Session\n",
        "def reset_keras():\n",
        "    sess = get_session()\n",
        "    clear_session()\n",
        "    sess.close()\n",
        "    sess = get_session()\n",
        "\n",
        "    try:\n",
        "        del estimator\n",
        "        del clf# this is from global space - change this as you need\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "#     print(gc.collect()) # if it's done something you should see a number being outputted\n",
        "\n",
        "    # use the same config as you used to create the session\n",
        "#     config = tensorflow.ConfigProto()\n",
        "#     config.gpu_options.per_process_gpu_memory_fraction = 1\n",
        "#     config.gpu_options.visible_device_list = \"0\"\n",
        "#     set_session(tensorflow.Session(config=config))\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    for gpu in gpus: \n",
        "        tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF6lk1YYNJFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_keras()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU1B2SL9NPRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "scalar = StandardScaler()\n",
        "data2 = scalar.fit_transform(data)\n",
        "data2 = data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLZjcN9FsOPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "seed = 7\n",
        "# checkpoint\n",
        "# filepath=\"/content/drive/My Drive/Colab Notebooks/data/personality/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, mode='max')\n",
        "# callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNts5jwujOYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir=\"/content/drive/My Drive/Colab Notebooks/model/personality/reg/\"\n",
        "checkpoint_acc = ModelCheckpoint(log_dir + 'drop50_ep{epoch:03d}-loss{loss:.3f}-accuracy{accuracy:.3f}.h5',\n",
        "        monitor='accuracy', save_weights_only=True, save_best_only=True, period=3, mode='max')\n",
        "checkpoint_loss = ModelCheckpoint(log_dir + 'drop50_ep{epoch:03d}-accuracy{accuracy:.3f}-val_accuracy{val_accuracy:.3f}.h5',\n",
        "        monitor='val_accuracy', save_weights_only=True, save_best_only=True, period=3, mode='max')\n",
        "# callbacks_list = [checkpoint_acc]\n",
        "callbacks_list = [checkpoint_acc, checkpoint_loss]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y7T2rnajYy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "315c5bcf-6ac3-4bd8-edb4-f5a724e735a9"
      },
      "source": [
        "estimator = KerasRegressor(build_fn=baseline_model, epochs=500, batch_size=10, verbose=0, callbacks=callbacks_list,shuffle=True)\n",
        "# estimator.fit(x_train, y_train, nb_epoch=10000, batch_size=10, verbose=0, callbacks=callbacks_list, shuffle=True, validation_split=0.2)\n",
        "estimator.fit(scalar.fit_transform(data), classes, nb_epoch=100000, batch_size=5, verbose=0, callbacks=callbacks_list, shuffle=True, validation_split=0.3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py:151: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  history = self.model.fit(x, y, **fit_args)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K_atz2by-CG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras import optimizers\n",
        "\n",
        "def baseline_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    # model.add(Dense(1500, input_dim=2910, kernel_initializer='normal', activation='relu'))\n",
        "    # model.add(Dropout(0.3, seed=np.random.seed(seed)))\n",
        "    # model.add(Dense(500, input_dim=1000, kernel_initializer='normal'))\n",
        "    # model.add(Dense(200, input_dim=1000, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dense(170, input_dim=225, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dropout(0.3, seed=np.random.seed(seed)))\n",
        "    # model.add(Dense(100, input_dim=160, kernel_initializer='normal'))\n",
        "    model.add(Dense(40, input_dim=100, kernel_initializer='normal', activation='relu'))\n",
        "    model.add(Dropout(0.4, seed=np.random.seed(seed)))\n",
        "    model.add(Dense(4, kernel_initializer='normal', activation=mapping_to_target_range))\n",
        "    # Compile model\n",
        "    # optimizer = optimizers.Adam(lr=0.0001)\n",
        "    optimizer = optimizers.Adam(lr=0.0001)\n",
        "    model.compile(loss=loss3, optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "log_dir=\"/content/drive/My Drive/Colab Notebooks/model/personality/pca/\"\n",
        "checkpoint_acc = ModelCheckpoint(log_dir + 'drop50_ep{epoch:03d}-loss{loss:.3f}-accuracy{accuracy:.3f}.h5',\n",
        "        monitor='accuracy', save_weights_only=True, save_best_only=True, period=3, mode='max')\n",
        "checkpoint_loss = ModelCheckpoint(log_dir + 'drop50_ep{epoch:03d}-accuracy{accuracy:.3f}-val_accuracy{val_accuracy:.3f}.h5',\n",
        "        monitor='val_accuracy', save_weights_only=True, save_best_only=True, period=3, mode='max')\n",
        "# callbacks_list = [checkpoint_acc]\n",
        "callbacks_list = [checkpoint_acc, checkpoint_loss]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ4NmlGkJiJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFPIAZR_7r1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir=\"/content/drive/My Drive/Colab Notebooks/model/personality/\"\n",
        "checkpoint = ModelCheckpoint(log_dir + 'try2_ep{epoch:03d}-loss{loss:.3f}-accuracy{accuracy:.3f}.h5',\n",
        "        monitor='accuracy', save_weights_only=True, save_best_only=True, period=3, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU4bgmXj6-cq",
        "colab_type": "code",
        "outputId": "70892287-b2c9-400b-f1cf-bca9e94da71a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "x_val = scalar.fit_transform(data)[-50:]\n",
        "y_val = classes[-50:]\n",
        "x_train = scalar.fit_transform(data)[:-50]\n",
        "y_train = classes[:-50]\n",
        "pca = PCA(n_components=225)\n",
        "estimator = KerasRegressor(build_fn=baseline_model, epochs=500, batch_size=10, verbose=0, callbacks=callbacks_list,shuffle=True)\n",
        "# estimator.fit(x_train, y_train, nb_epoch=10000, batch_size=10, verbose=0, callbacks=callbacks_list, shuffle=True, validation_split=0.2)\n",
        "estimator.fit(pca.fit_transform(scalar.fit_transform(data)), classes, nb_epoch=100000, batch_size=5, verbose=0, callbacks=callbacks_list, shuffle=True, validation_split=0.3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py:151: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  history = self.model.fit(x, y, **fit_args)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fe01b1ecf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avzIF474v6Sq",
        "colab_type": "code",
        "outputId": "059b9c15-b2c4-4181-d60d-bf0a77302df8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "estimator = KerasRegressor(build_fn=baseline_model, epochs=500, batch_size=10, verbose=1, callbacks=callbacks_list,shuffle=True)\n",
        "estimator.fit(scalar.fit_transform(data), classes, nb_epoch=10000, batch_size=10, verbose=1, callbacks=callbacks_list, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py:151: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  history = self.model.fit(x, y, **fit_args)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "225/225 [==============================] - 0s 462us/step - loss: 4.1445 - accuracy: 0.8622\n",
            "Epoch 7502/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9087 - accuracy: 0.8578\n",
            "Epoch 7503/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 3.9102 - accuracy: 0.8533\n",
            "Epoch 7504/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9560 - accuracy: 0.8578\n",
            "Epoch 7505/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.1547 - accuracy: 0.8489\n",
            "Epoch 7506/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 3.7888 - accuracy: 0.8889\n",
            "Epoch 7507/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 4.0058 - accuracy: 0.8222\n",
            "Epoch 7508/10000\n",
            "225/225 [==============================] - 0s 512us/step - loss: 3.9557 - accuracy: 0.8533\n",
            "Epoch 7509/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9138 - accuracy: 0.8400\n",
            "Epoch 7510/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.7635 - accuracy: 0.8444\n",
            "Epoch 7511/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.8079 - accuracy: 0.8400\n",
            "Epoch 7512/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.8342 - accuracy: 0.8444\n",
            "Epoch 7513/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 4.0083 - accuracy: 0.8533\n",
            "Epoch 7514/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9921 - accuracy: 0.8756\n",
            "Epoch 7515/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 3.9819 - accuracy: 0.8267\n",
            "Epoch 7516/10000\n",
            "225/225 [==============================] - 0s 529us/step - loss: 3.9924 - accuracy: 0.8533\n",
            "Epoch 7517/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.6490 - accuracy: 0.8444\n",
            "Epoch 7518/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9668 - accuracy: 0.8844\n",
            "Epoch 7519/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9135 - accuracy: 0.8800\n",
            "Epoch 7520/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0254 - accuracy: 0.8356\n",
            "Epoch 7521/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0228 - accuracy: 0.8222\n",
            "Epoch 7522/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9268 - accuracy: 0.8711\n",
            "Epoch 7523/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 4.0594 - accuracy: 0.8667\n",
            "Epoch 7524/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 4.0296 - accuracy: 0.8578\n",
            "Epoch 7525/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9440 - accuracy: 0.8533\n",
            "Epoch 7526/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0011 - accuracy: 0.8756\n",
            "Epoch 7527/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.8651 - accuracy: 0.8622\n",
            "Epoch 7528/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.8139 - accuracy: 0.8667\n",
            "Epoch 7529/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9725 - accuracy: 0.8578\n",
            "Epoch 7530/10000\n",
            "225/225 [==============================] - 0s 535us/step - loss: 3.9311 - accuracy: 0.8578\n",
            "Epoch 7531/10000\n",
            "225/225 [==============================] - 0s 543us/step - loss: 4.0191 - accuracy: 0.8622\n",
            "Epoch 7532/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 4.0437 - accuracy: 0.8667\n",
            "Epoch 7533/10000\n",
            "225/225 [==============================] - 0s 552us/step - loss: 3.9973 - accuracy: 0.8311\n",
            "Epoch 7534/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 4.0379 - accuracy: 0.8533\n",
            "Epoch 7535/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.9444 - accuracy: 0.8489\n",
            "Epoch 7536/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.8727 - accuracy: 0.8578\n",
            "Epoch 7537/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.8844 - accuracy: 0.8267\n",
            "Epoch 7538/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.8950 - accuracy: 0.8533\n",
            "Epoch 7539/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.8946 - accuracy: 0.8533\n",
            "Epoch 7540/10000\n",
            "225/225 [==============================] - 0s 542us/step - loss: 4.0724 - accuracy: 0.8711\n",
            "Epoch 7541/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9786 - accuracy: 0.8533\n",
            "Epoch 7542/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.8254 - accuracy: 0.8622\n",
            "Epoch 7543/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.0647 - accuracy: 0.8578\n",
            "Epoch 7544/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 4.0546 - accuracy: 0.8533\n",
            "Epoch 7545/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9539 - accuracy: 0.8400\n",
            "Epoch 7546/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9777 - accuracy: 0.8533\n",
            "Epoch 7547/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9290 - accuracy: 0.8844\n",
            "Epoch 7548/10000\n",
            "225/225 [==============================] - 0s 532us/step - loss: 3.9520 - accuracy: 0.8578\n",
            "Epoch 7549/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.8865 - accuracy: 0.8933\n",
            "Epoch 7550/10000\n",
            "225/225 [==============================] - 0s 499us/step - loss: 3.6869 - accuracy: 0.8622\n",
            "Epoch 7551/10000\n",
            "225/225 [==============================] - 0s 588us/step - loss: 4.0690 - accuracy: 0.8622\n",
            "Epoch 7552/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0050 - accuracy: 0.8533\n",
            "Epoch 7553/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 4.0626 - accuracy: 0.8667\n",
            "Epoch 7554/10000\n",
            "225/225 [==============================] - 0s 551us/step - loss: 3.7724 - accuracy: 0.8800\n",
            "Epoch 7555/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.8911 - accuracy: 0.8622\n",
            "Epoch 7556/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9680 - accuracy: 0.8711\n",
            "Epoch 7557/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9739 - accuracy: 0.8622\n",
            "Epoch 7558/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9224 - accuracy: 0.8622\n",
            "Epoch 7559/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9306 - accuracy: 0.8267\n",
            "Epoch 7560/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 4.0183 - accuracy: 0.8489\n",
            "Epoch 7561/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.0615 - accuracy: 0.8533\n",
            "Epoch 7562/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.7815 - accuracy: 0.8489\n",
            "Epoch 7563/10000\n",
            "225/225 [==============================] - 0s 447us/step - loss: 3.9890 - accuracy: 0.8667\n",
            "Epoch 7564/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 4.0424 - accuracy: 0.8311\n",
            "Epoch 7565/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0233 - accuracy: 0.8800\n",
            "Epoch 7566/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 4.0045 - accuracy: 0.8711\n",
            "Epoch 7567/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9201 - accuracy: 0.8756\n",
            "Epoch 7568/10000\n",
            "225/225 [==============================] - 0s 498us/step - loss: 3.9377 - accuracy: 0.8444\n",
            "Epoch 7569/10000\n",
            "225/225 [==============================] - 0s 553us/step - loss: 3.8418 - accuracy: 0.8667\n",
            "Epoch 7570/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9469 - accuracy: 0.8711\n",
            "Epoch 7571/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9402 - accuracy: 0.8711\n",
            "Epoch 7572/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0610 - accuracy: 0.8667\n",
            "Epoch 7573/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.8342 - accuracy: 0.8622\n",
            "Epoch 7574/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9992 - accuracy: 0.8489\n",
            "Epoch 7575/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.1626 - accuracy: 0.8489\n",
            "Epoch 7576/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.8523 - accuracy: 0.8578\n",
            "Epoch 7577/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9267 - accuracy: 0.8844\n",
            "Epoch 7578/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.0234 - accuracy: 0.8800\n",
            "Epoch 7579/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.9278 - accuracy: 0.8667\n",
            "Epoch 7580/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9185 - accuracy: 0.8489\n",
            "Epoch 7581/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.7647 - accuracy: 0.8489\n",
            "Epoch 7582/10000\n",
            "225/225 [==============================] - 0s 447us/step - loss: 3.6791 - accuracy: 0.8933\n",
            "Epoch 7583/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9943 - accuracy: 0.8267\n",
            "Epoch 7584/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0284 - accuracy: 0.8889\n",
            "Epoch 7585/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8205 - accuracy: 0.8622\n",
            "Epoch 7586/10000\n",
            "225/225 [==============================] - 0s 497us/step - loss: 3.5828 - accuracy: 0.8578\n",
            "Epoch 7587/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 3.9138 - accuracy: 0.8489\n",
            "Epoch 7588/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 4.1309 - accuracy: 0.8844\n",
            "Epoch 7589/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9961 - accuracy: 0.8533\n",
            "Epoch 7590/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 4.0033 - accuracy: 0.8578\n",
            "Epoch 7591/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9772 - accuracy: 0.8578\n",
            "Epoch 7592/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.8319 - accuracy: 0.8711\n",
            "Epoch 7593/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.8709 - accuracy: 0.8444\n",
            "Epoch 7594/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9310 - accuracy: 0.8622\n",
            "Epoch 7595/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.7949 - accuracy: 0.8311\n",
            "Epoch 7596/10000\n",
            "225/225 [==============================] - 0s 524us/step - loss: 3.9236 - accuracy: 0.8311\n",
            "Epoch 7597/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 3.8256 - accuracy: 0.8400\n",
            "Epoch 7598/10000\n",
            "225/225 [==============================] - 0s 509us/step - loss: 3.9013 - accuracy: 0.8489\n",
            "Epoch 7599/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.9879 - accuracy: 0.8578\n",
            "Epoch 7600/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.8324 - accuracy: 0.8622\n",
            "Epoch 7601/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0367 - accuracy: 0.8533\n",
            "Epoch 7602/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9319 - accuracy: 0.8622\n",
            "Epoch 7603/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.8602 - accuracy: 0.8533\n",
            "Epoch 7604/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9841 - accuracy: 0.8578\n",
            "Epoch 7605/10000\n",
            "225/225 [==============================] - 0s 549us/step - loss: 4.0853 - accuracy: 0.8489\n",
            "Epoch 7606/10000\n",
            "225/225 [==============================] - 0s 510us/step - loss: 3.8979 - accuracy: 0.8844\n",
            "Epoch 7607/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0068 - accuracy: 0.8533\n",
            "Epoch 7608/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9573 - accuracy: 0.8578\n",
            "Epoch 7609/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0602 - accuracy: 0.8711\n",
            "Epoch 7610/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 4.0502 - accuracy: 0.8756\n",
            "Epoch 7611/10000\n",
            "225/225 [==============================] - 0s 551us/step - loss: 3.8631 - accuracy: 0.8622\n",
            "Epoch 7612/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 3.8845 - accuracy: 0.8533\n",
            "Epoch 7613/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9423 - accuracy: 0.8667\n",
            "Epoch 7614/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9796 - accuracy: 0.8444\n",
            "Epoch 7615/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 3.8400 - accuracy: 0.8533\n",
            "Epoch 7616/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9668 - accuracy: 0.8578\n",
            "Epoch 7617/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.7366 - accuracy: 0.8800\n",
            "Epoch 7618/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9268 - accuracy: 0.8667\n",
            "Epoch 7619/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9344 - accuracy: 0.8622\n",
            "Epoch 7620/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.8952 - accuracy: 0.8711\n",
            "Epoch 7621/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9885 - accuracy: 0.8622\n",
            "Epoch 7622/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.8792 - accuracy: 0.8800\n",
            "Epoch 7623/10000\n",
            "225/225 [==============================] - 0s 499us/step - loss: 3.9548 - accuracy: 0.8400\n",
            "Epoch 7624/10000\n",
            "225/225 [==============================] - 0s 532us/step - loss: 3.8716 - accuracy: 0.8489\n",
            "Epoch 7625/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.8480 - accuracy: 0.8667\n",
            "Epoch 7626/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.1182 - accuracy: 0.8356\n",
            "Epoch 7627/10000\n",
            "225/225 [==============================] - 0s 539us/step - loss: 3.9021 - accuracy: 0.8533\n",
            "Epoch 7628/10000\n",
            "225/225 [==============================] - 0s 509us/step - loss: 3.9808 - accuracy: 0.8578\n",
            "Epoch 7629/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.7076 - accuracy: 0.8667\n",
            "Epoch 7630/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9530 - accuracy: 0.8578\n",
            "Epoch 7631/10000\n",
            "225/225 [==============================] - 0s 498us/step - loss: 3.9607 - accuracy: 0.8667\n",
            "Epoch 7632/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.0595 - accuracy: 0.8533\n",
            "Epoch 7633/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.9966 - accuracy: 0.8756\n",
            "Epoch 7634/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9115 - accuracy: 0.8533\n",
            "Epoch 7635/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9775 - accuracy: 0.8711\n",
            "Epoch 7636/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0332 - accuracy: 0.8489\n",
            "Epoch 7637/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 4.0253 - accuracy: 0.8756\n",
            "Epoch 7638/10000\n",
            "225/225 [==============================] - 0s 522us/step - loss: 4.0193 - accuracy: 0.8356\n",
            "Epoch 7639/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9996 - accuracy: 0.8667\n",
            "Epoch 7640/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9826 - accuracy: 0.8444\n",
            "Epoch 7641/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.9500 - accuracy: 0.8444\n",
            "Epoch 7642/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 4.0151 - accuracy: 0.8444\n",
            "Epoch 7643/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 4.0323 - accuracy: 0.8711\n",
            "Epoch 7644/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.8779 - accuracy: 0.8711\n",
            "Epoch 7645/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.8988 - accuracy: 0.8622\n",
            "Epoch 7646/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 4.0394 - accuracy: 0.8667\n",
            "Epoch 7647/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0930 - accuracy: 0.8711\n",
            "Epoch 7648/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.1063 - accuracy: 0.8444\n",
            "Epoch 7649/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.6624 - accuracy: 0.8667\n",
            "Epoch 7650/10000\n",
            "225/225 [==============================] - 0s 528us/step - loss: 3.8713 - accuracy: 0.8444\n",
            "Epoch 7651/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0139 - accuracy: 0.8400\n",
            "Epoch 7652/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 4.0159 - accuracy: 0.8533\n",
            "Epoch 7653/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 4.1363 - accuracy: 0.8400\n",
            "Epoch 7654/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 4.0042 - accuracy: 0.8711\n",
            "Epoch 7655/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0601 - accuracy: 0.8711\n",
            "Epoch 7656/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0094 - accuracy: 0.8622\n",
            "Epoch 7657/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.7196 - accuracy: 0.8578\n",
            "Epoch 7658/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.0896 - accuracy: 0.8356\n",
            "Epoch 7659/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.8212 - accuracy: 0.8844\n",
            "Epoch 7660/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9809 - accuracy: 0.8578\n",
            "Epoch 7661/10000\n",
            "225/225 [==============================] - 0s 524us/step - loss: 4.1181 - accuracy: 0.8622\n",
            "Epoch 7662/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9661 - accuracy: 0.8444\n",
            "Epoch 7663/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0955 - accuracy: 0.8444\n",
            "Epoch 7664/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.9282 - accuracy: 0.8667\n",
            "Epoch 7665/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.8104 - accuracy: 0.8622\n",
            "Epoch 7666/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.8517 - accuracy: 0.8800\n",
            "Epoch 7667/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9445 - accuracy: 0.8800\n",
            "Epoch 7668/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 3.9253 - accuracy: 0.8667\n",
            "Epoch 7669/10000\n",
            "225/225 [==============================] - 0s 514us/step - loss: 3.8626 - accuracy: 0.8311\n",
            "Epoch 7670/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.5028 - accuracy: 0.8622\n",
            "Epoch 7671/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.6232 - accuracy: 0.8933\n",
            "Epoch 7672/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0056 - accuracy: 0.8800\n",
            "Epoch 7673/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 4.0119 - accuracy: 0.8489\n",
            "Epoch 7674/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0206 - accuracy: 0.8489\n",
            "Epoch 7675/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9575 - accuracy: 0.8489\n",
            "Epoch 7676/10000\n",
            "225/225 [==============================] - 0s 517us/step - loss: 4.0310 - accuracy: 0.8578\n",
            "Epoch 7677/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 4.0469 - accuracy: 0.8711\n",
            "Epoch 7678/10000\n",
            "225/225 [==============================] - 0s 504us/step - loss: 3.9124 - accuracy: 0.8667\n",
            "Epoch 7679/10000\n",
            "225/225 [==============================] - 0s 578us/step - loss: 3.9172 - accuracy: 0.8622\n",
            "Epoch 7680/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 3.6539 - accuracy: 0.8444\n",
            "Epoch 7681/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 4.0759 - accuracy: 0.8578\n",
            "Epoch 7682/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9807 - accuracy: 0.8800\n",
            "Epoch 7683/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0339 - accuracy: 0.8356\n",
            "Epoch 7684/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 4.0982 - accuracy: 0.8444\n",
            "Epoch 7685/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9982 - accuracy: 0.8489\n",
            "Epoch 7686/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 3.9789 - accuracy: 0.8400\n",
            "Epoch 7687/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 4.0029 - accuracy: 0.8578\n",
            "Epoch 7688/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9724 - accuracy: 0.8400\n",
            "Epoch 7689/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 4.1146 - accuracy: 0.8356\n",
            "Epoch 7690/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.6654 - accuracy: 0.8356\n",
            "Epoch 7691/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 4.1571 - accuracy: 0.8400\n",
            "Epoch 7692/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.8691 - accuracy: 0.8489\n",
            "Epoch 7693/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.8381 - accuracy: 0.8711\n",
            "Epoch 7694/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 4.1345 - accuracy: 0.8622\n",
            "Epoch 7695/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.8994 - accuracy: 0.8400\n",
            "Epoch 7696/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 4.0534 - accuracy: 0.8756\n",
            "Epoch 7697/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9573 - accuracy: 0.8356\n",
            "Epoch 7698/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.9454 - accuracy: 0.8756\n",
            "Epoch 7699/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9042 - accuracy: 0.8533\n",
            "Epoch 7700/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9258 - accuracy: 0.8533\n",
            "Epoch 7701/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9681 - accuracy: 0.8667\n",
            "Epoch 7702/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9160 - accuracy: 0.8578\n",
            "Epoch 7703/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.8475 - accuracy: 0.8444\n",
            "Epoch 7704/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.8548 - accuracy: 0.8489\n",
            "Epoch 7705/10000\n",
            "225/225 [==============================] - 0s 514us/step - loss: 3.7981 - accuracy: 0.8444\n",
            "Epoch 7706/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.8647 - accuracy: 0.8667\n",
            "Epoch 7707/10000\n",
            "225/225 [==============================] - 0s 534us/step - loss: 4.0423 - accuracy: 0.8489\n",
            "Epoch 7708/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.8699 - accuracy: 0.8622\n",
            "Epoch 7709/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9227 - accuracy: 0.8533\n",
            "Epoch 7710/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.1558 - accuracy: 0.8533\n",
            "Epoch 7711/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.8100 - accuracy: 0.8800\n",
            "Epoch 7712/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 4.0226 - accuracy: 0.8667\n",
            "Epoch 7713/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.8752 - accuracy: 0.8356\n",
            "Epoch 7714/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 4.0115 - accuracy: 0.8711\n",
            "Epoch 7715/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.0156 - accuracy: 0.8133\n",
            "Epoch 7716/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 3.9867 - accuracy: 0.8756\n",
            "Epoch 7717/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9214 - accuracy: 0.8533\n",
            "Epoch 7718/10000\n",
            "225/225 [==============================] - 0s 522us/step - loss: 3.8546 - accuracy: 0.8311\n",
            "Epoch 7719/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.8698 - accuracy: 0.8533\n",
            "Epoch 7720/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9989 - accuracy: 0.8400\n",
            "Epoch 7721/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9769 - accuracy: 0.8533\n",
            "Epoch 7722/10000\n",
            "225/225 [==============================] - 0s 521us/step - loss: 4.0211 - accuracy: 0.8756\n",
            "Epoch 7723/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 4.1302 - accuracy: 0.8533\n",
            "Epoch 7724/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9311 - accuracy: 0.8889\n",
            "Epoch 7725/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 4.0643 - accuracy: 0.8711\n",
            "Epoch 7726/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.1923 - accuracy: 0.8667\n",
            "Epoch 7727/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0514 - accuracy: 0.8533\n",
            "Epoch 7728/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9851 - accuracy: 0.8489\n",
            "Epoch 7729/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9806 - accuracy: 0.8756\n",
            "Epoch 7730/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.8970 - accuracy: 0.8533\n",
            "Epoch 7731/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.9527 - accuracy: 0.8622\n",
            "Epoch 7732/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 3.9468 - accuracy: 0.8667\n",
            "Epoch 7733/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.0024 - accuracy: 0.8667\n",
            "Epoch 7734/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9526 - accuracy: 0.8711\n",
            "Epoch 7735/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9566 - accuracy: 0.8533\n",
            "Epoch 7736/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 4.0832 - accuracy: 0.8489\n",
            "Epoch 7737/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9946 - accuracy: 0.8711\n",
            "Epoch 7738/10000\n",
            "225/225 [==============================] - 0s 504us/step - loss: 4.1142 - accuracy: 0.8533\n",
            "Epoch 7739/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9301 - accuracy: 0.8667\n",
            "Epoch 7740/10000\n",
            "225/225 [==============================] - 0s 494us/step - loss: 3.9542 - accuracy: 0.8489\n",
            "Epoch 7741/10000\n",
            "225/225 [==============================] - 0s 573us/step - loss: 4.0655 - accuracy: 0.8667\n",
            "Epoch 7742/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 4.0175 - accuracy: 0.8622\n",
            "Epoch 7743/10000\n",
            "225/225 [==============================] - 0s 536us/step - loss: 4.0082 - accuracy: 0.8489\n",
            "Epoch 7744/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.8948 - accuracy: 0.8356\n",
            "Epoch 7745/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.8611 - accuracy: 0.8533\n",
            "Epoch 7746/10000\n",
            "225/225 [==============================] - 0s 565us/step - loss: 4.0073 - accuracy: 0.8578\n",
            "Epoch 7747/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.1121 - accuracy: 0.8444\n",
            "Epoch 7748/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.8798 - accuracy: 0.8667\n",
            "Epoch 7749/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9209 - accuracy: 0.8800\n",
            "Epoch 7750/10000\n",
            "225/225 [==============================] - 0s 509us/step - loss: 4.1401 - accuracy: 0.8489\n",
            "Epoch 7751/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0704 - accuracy: 0.8400\n",
            "Epoch 7752/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.0039 - accuracy: 0.8711\n",
            "Epoch 7753/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.8885 - accuracy: 0.8222\n",
            "Epoch 7754/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.8964 - accuracy: 0.8933\n",
            "Epoch 7755/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9268 - accuracy: 0.8356\n",
            "Epoch 7756/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9519 - accuracy: 0.8622\n",
            "Epoch 7757/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.7596 - accuracy: 0.8756\n",
            "Epoch 7758/10000\n",
            "225/225 [==============================] - 0s 542us/step - loss: 3.9606 - accuracy: 0.8489\n",
            "Epoch 7759/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 4.0876 - accuracy: 0.8489\n",
            "Epoch 7760/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 4.0025 - accuracy: 0.8889\n",
            "Epoch 7761/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 4.0293 - accuracy: 0.8444\n",
            "Epoch 7762/10000\n",
            "225/225 [==============================] - 0s 508us/step - loss: 3.9138 - accuracy: 0.8578\n",
            "Epoch 7763/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.9239 - accuracy: 0.8667\n",
            "Epoch 7764/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9965 - accuracy: 0.8622\n",
            "Epoch 7765/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9999 - accuracy: 0.8489\n",
            "Epoch 7766/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0540 - accuracy: 0.8533\n",
            "Epoch 7767/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9810 - accuracy: 0.8844\n",
            "Epoch 7768/10000\n",
            "225/225 [==============================] - 0s 498us/step - loss: 4.1402 - accuracy: 0.8711\n",
            "Epoch 7769/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0383 - accuracy: 0.8622\n",
            "Epoch 7770/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0004 - accuracy: 0.8578\n",
            "Epoch 7771/10000\n",
            "225/225 [==============================] - 0s 498us/step - loss: 3.8269 - accuracy: 0.8800\n",
            "Epoch 7772/10000\n",
            "225/225 [==============================] - 0s 512us/step - loss: 4.0576 - accuracy: 0.8444\n",
            "Epoch 7773/10000\n",
            "225/225 [==============================] - 0s 521us/step - loss: 3.9955 - accuracy: 0.8711\n",
            "Epoch 7774/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9753 - accuracy: 0.8356\n",
            "Epoch 7775/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9796 - accuracy: 0.8711\n",
            "Epoch 7776/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.9773 - accuracy: 0.8489\n",
            "Epoch 7777/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9933 - accuracy: 0.8711\n",
            "Epoch 7778/10000\n",
            "225/225 [==============================] - 0s 525us/step - loss: 3.9889 - accuracy: 0.8578\n",
            "Epoch 7779/10000\n",
            "225/225 [==============================] - 0s 608us/step - loss: 3.8839 - accuracy: 0.8800\n",
            "Epoch 7780/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 3.9327 - accuracy: 0.8756\n",
            "Epoch 7781/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9288 - accuracy: 0.8533\n",
            "Epoch 7782/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9727 - accuracy: 0.8800\n",
            "Epoch 7783/10000\n",
            "225/225 [==============================] - 0s 450us/step - loss: 3.9238 - accuracy: 0.8622\n",
            "Epoch 7784/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0057 - accuracy: 0.8711\n",
            "Epoch 7785/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.0158 - accuracy: 0.8667\n",
            "Epoch 7786/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9769 - accuracy: 0.8444\n",
            "Epoch 7787/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9838 - accuracy: 0.8444\n",
            "Epoch 7788/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9957 - accuracy: 0.8667\n",
            "Epoch 7789/10000\n",
            "225/225 [==============================] - 0s 535us/step - loss: 3.9572 - accuracy: 0.8578\n",
            "Epoch 7790/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9746 - accuracy: 0.8444\n",
            "Epoch 7791/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9809 - accuracy: 0.8889\n",
            "Epoch 7792/10000\n",
            "225/225 [==============================] - 0s 508us/step - loss: 3.9315 - accuracy: 0.8578\n",
            "Epoch 7793/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 4.0127 - accuracy: 0.8267\n",
            "Epoch 7794/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9597 - accuracy: 0.8311\n",
            "Epoch 7795/10000\n",
            "225/225 [==============================] - 0s 592us/step - loss: 4.0517 - accuracy: 0.8489\n",
            "Epoch 7796/10000\n",
            "225/225 [==============================] - 0s 530us/step - loss: 3.9449 - accuracy: 0.8533\n",
            "Epoch 7797/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 3.9639 - accuracy: 0.8533\n",
            "Epoch 7798/10000\n",
            "225/225 [==============================] - 0s 514us/step - loss: 3.8419 - accuracy: 0.8489\n",
            "Epoch 7799/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0375 - accuracy: 0.8844\n",
            "Epoch 7800/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9917 - accuracy: 0.8622\n",
            "Epoch 7801/10000\n",
            "225/225 [==============================] - 0s 447us/step - loss: 3.8868 - accuracy: 0.8844\n",
            "Epoch 7802/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9318 - accuracy: 0.8533\n",
            "Epoch 7803/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.9134 - accuracy: 0.8711\n",
            "Epoch 7804/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 3.9882 - accuracy: 0.8489\n",
            "Epoch 7805/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9283 - accuracy: 0.8800\n",
            "Epoch 7806/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9481 - accuracy: 0.8444\n",
            "Epoch 7807/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9361 - accuracy: 0.8400\n",
            "Epoch 7808/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0314 - accuracy: 0.8578\n",
            "Epoch 7809/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9414 - accuracy: 0.8356\n",
            "Epoch 7810/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.8748 - accuracy: 0.8444\n",
            "Epoch 7811/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9487 - accuracy: 0.8578\n",
            "Epoch 7812/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.8858 - accuracy: 0.8489\n",
            "Epoch 7813/10000\n",
            "225/225 [==============================] - 0s 521us/step - loss: 4.1685 - accuracy: 0.8978\n",
            "Epoch 7814/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9053 - accuracy: 0.8444\n",
            "Epoch 7815/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.8750 - accuracy: 0.8533\n",
            "Epoch 7816/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.7098 - accuracy: 0.8667\n",
            "Epoch 7817/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 4.0233 - accuracy: 0.8622\n",
            "Epoch 7818/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9199 - accuracy: 0.8444\n",
            "Epoch 7819/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 3.8943 - accuracy: 0.8622\n",
            "Epoch 7820/10000\n",
            "225/225 [==============================] - 0s 527us/step - loss: 3.8008 - accuracy: 0.8800\n",
            "Epoch 7821/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9996 - accuracy: 0.8756\n",
            "Epoch 7822/10000\n",
            "225/225 [==============================] - 0s 527us/step - loss: 3.8906 - accuracy: 0.8489\n",
            "Epoch 7823/10000\n",
            "225/225 [==============================] - 0s 515us/step - loss: 3.9573 - accuracy: 0.8578\n",
            "Epoch 7824/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9216 - accuracy: 0.8444\n",
            "Epoch 7825/10000\n",
            "225/225 [==============================] - 0s 544us/step - loss: 3.9510 - accuracy: 0.8800\n",
            "Epoch 7826/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 4.0461 - accuracy: 0.8444\n",
            "Epoch 7827/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9576 - accuracy: 0.8533\n",
            "Epoch 7828/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0429 - accuracy: 0.8578\n",
            "Epoch 7829/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.2755 - accuracy: 0.8711\n",
            "Epoch 7830/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 4.0439 - accuracy: 0.8489\n",
            "Epoch 7831/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9002 - accuracy: 0.8667\n",
            "Epoch 7832/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0534 - accuracy: 0.8533\n",
            "Epoch 7833/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0231 - accuracy: 0.8444\n",
            "Epoch 7834/10000\n",
            "225/225 [==============================] - 0s 537us/step - loss: 3.9861 - accuracy: 0.8622\n",
            "Epoch 7835/10000\n",
            "225/225 [==============================] - 0s 590us/step - loss: 3.6300 - accuracy: 0.8667\n",
            "Epoch 7836/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9915 - accuracy: 0.8311\n",
            "Epoch 7837/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9471 - accuracy: 0.8356\n",
            "Epoch 7838/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8739 - accuracy: 0.8800\n",
            "Epoch 7839/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0055 - accuracy: 0.8400\n",
            "Epoch 7840/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 3.9937 - accuracy: 0.8489\n",
            "Epoch 7841/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 4.0252 - accuracy: 0.8400\n",
            "Epoch 7842/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.8393 - accuracy: 0.8756\n",
            "Epoch 7843/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 4.1408 - accuracy: 0.8444\n",
            "Epoch 7844/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9028 - accuracy: 0.8622\n",
            "Epoch 7845/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9050 - accuracy: 0.8311\n",
            "Epoch 7846/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.8599 - accuracy: 0.8622\n",
            "Epoch 7847/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9068 - accuracy: 0.8311\n",
            "Epoch 7848/10000\n",
            "225/225 [==============================] - 0s 575us/step - loss: 3.7881 - accuracy: 0.8267\n",
            "Epoch 7849/10000\n",
            "225/225 [==============================] - 0s 572us/step - loss: 4.1410 - accuracy: 0.8844\n",
            "Epoch 7850/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 4.1088 - accuracy: 0.8489\n",
            "Epoch 7851/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9740 - accuracy: 0.8578\n",
            "Epoch 7852/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 4.0499 - accuracy: 0.8578\n",
            "Epoch 7853/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9951 - accuracy: 0.8711\n",
            "Epoch 7854/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.7853 - accuracy: 0.8711\n",
            "Epoch 7855/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9810 - accuracy: 0.8622\n",
            "Epoch 7856/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.1529 - accuracy: 0.8667\n",
            "Epoch 7857/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.7834 - accuracy: 0.8578\n",
            "Epoch 7858/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 3.9750 - accuracy: 0.8622\n",
            "Epoch 7859/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.8425 - accuracy: 0.8311\n",
            "Epoch 7860/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0145 - accuracy: 0.8667\n",
            "Epoch 7861/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9961 - accuracy: 0.8622\n",
            "Epoch 7862/10000\n",
            "225/225 [==============================] - 0s 548us/step - loss: 3.9762 - accuracy: 0.8622\n",
            "Epoch 7863/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 4.1286 - accuracy: 0.8578\n",
            "Epoch 7864/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 4.0354 - accuracy: 0.8444\n",
            "Epoch 7865/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9993 - accuracy: 0.8533\n",
            "Epoch 7866/10000\n",
            "225/225 [==============================] - 0s 504us/step - loss: 3.6523 - accuracy: 0.8756\n",
            "Epoch 7867/10000\n",
            "225/225 [==============================] - 0s 501us/step - loss: 3.9631 - accuracy: 0.8578\n",
            "Epoch 7868/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9813 - accuracy: 0.8622\n",
            "Epoch 7869/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0432 - accuracy: 0.8533\n",
            "Epoch 7870/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9822 - accuracy: 0.8533\n",
            "Epoch 7871/10000\n",
            "225/225 [==============================] - 0s 526us/step - loss: 3.8882 - accuracy: 0.8800\n",
            "Epoch 7872/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.8907 - accuracy: 0.8444\n",
            "Epoch 7873/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.5994 - accuracy: 0.8844\n",
            "Epoch 7874/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9432 - accuracy: 0.8800\n",
            "Epoch 7875/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 4.0682 - accuracy: 0.8667\n",
            "Epoch 7876/10000\n",
            "225/225 [==============================] - 0s 551us/step - loss: 4.0192 - accuracy: 0.8622\n",
            "Epoch 7877/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 4.0508 - accuracy: 0.8311\n",
            "Epoch 7878/10000\n",
            "225/225 [==============================] - 0s 522us/step - loss: 3.9881 - accuracy: 0.8800\n",
            "Epoch 7879/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9625 - accuracy: 0.8711\n",
            "Epoch 7880/10000\n",
            "225/225 [==============================] - 0s 521us/step - loss: 3.9143 - accuracy: 0.8667\n",
            "Epoch 7881/10000\n",
            "225/225 [==============================] - 0s 514us/step - loss: 4.1469 - accuracy: 0.8622\n",
            "Epoch 7882/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.9690 - accuracy: 0.8400\n",
            "Epoch 7883/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0320 - accuracy: 0.8400\n",
            "Epoch 7884/10000\n",
            "225/225 [==============================] - 0s 529us/step - loss: 3.8722 - accuracy: 0.8844\n",
            "Epoch 7885/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 3.9703 - accuracy: 0.8533\n",
            "Epoch 7886/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8772 - accuracy: 0.8844\n",
            "Epoch 7887/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9362 - accuracy: 0.8356\n",
            "Epoch 7888/10000\n",
            "225/225 [==============================] - 0s 498us/step - loss: 3.9340 - accuracy: 0.8667\n",
            "Epoch 7889/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.0867 - accuracy: 0.8889\n",
            "Epoch 7890/10000\n",
            "225/225 [==============================] - 0s 507us/step - loss: 3.8677 - accuracy: 0.8489\n",
            "Epoch 7891/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.8769 - accuracy: 0.8622\n",
            "Epoch 7892/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.8753 - accuracy: 0.8756\n",
            "Epoch 7893/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.0403 - accuracy: 0.8444\n",
            "Epoch 7894/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.6452 - accuracy: 0.8578\n",
            "Epoch 7895/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9141 - accuracy: 0.8578\n",
            "Epoch 7896/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.8278 - accuracy: 0.8667\n",
            "Epoch 7897/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 3.8338 - accuracy: 0.8578\n",
            "Epoch 7898/10000\n",
            "225/225 [==============================] - 0s 510us/step - loss: 3.9556 - accuracy: 0.8622\n",
            "Epoch 7899/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.8773 - accuracy: 0.8622\n",
            "Epoch 7900/10000\n",
            "225/225 [==============================] - 0s 498us/step - loss: 3.9010 - accuracy: 0.8489\n",
            "Epoch 7901/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.0172 - accuracy: 0.8356\n",
            "Epoch 7902/10000\n",
            "225/225 [==============================] - 0s 524us/step - loss: 3.9289 - accuracy: 0.8622\n",
            "Epoch 7903/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9175 - accuracy: 0.8711\n",
            "Epoch 7904/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.8077 - accuracy: 0.8533\n",
            "Epoch 7905/10000\n",
            "225/225 [==============================] - 0s 504us/step - loss: 3.8816 - accuracy: 0.8622\n",
            "Epoch 7906/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9177 - accuracy: 0.8622\n",
            "Epoch 7907/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 4.0104 - accuracy: 0.8844\n",
            "Epoch 7908/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0906 - accuracy: 0.8444\n",
            "Epoch 7909/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.1298 - accuracy: 0.8667\n",
            "Epoch 7910/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9245 - accuracy: 0.8844\n",
            "Epoch 7911/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.0506 - accuracy: 0.8578\n",
            "Epoch 7912/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 3.8754 - accuracy: 0.8622\n",
            "Epoch 7913/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.9550 - accuracy: 0.8667\n",
            "Epoch 7914/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.0981 - accuracy: 0.8622\n",
            "Epoch 7915/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.9047 - accuracy: 0.8356\n",
            "Epoch 7916/10000\n",
            "225/225 [==============================] - 0s 521us/step - loss: 3.8603 - accuracy: 0.8667\n",
            "Epoch 7917/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.7847 - accuracy: 0.8622\n",
            "Epoch 7918/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9685 - accuracy: 0.8622\n",
            "Epoch 7919/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.0189 - accuracy: 0.8711\n",
            "Epoch 7920/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.7325 - accuracy: 0.8756\n",
            "Epoch 7921/10000\n",
            "225/225 [==============================] - 0s 524us/step - loss: 3.8151 - accuracy: 0.8756\n",
            "Epoch 7922/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.0043 - accuracy: 0.8622\n",
            "Epoch 7923/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 4.1286 - accuracy: 0.8267\n",
            "Epoch 7924/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9677 - accuracy: 0.8622\n",
            "Epoch 7925/10000\n",
            "225/225 [==============================] - 0s 527us/step - loss: 4.1921 - accuracy: 0.8444\n",
            "Epoch 7926/10000\n",
            "225/225 [==============================] - 0s 556us/step - loss: 3.9086 - accuracy: 0.8800\n",
            "Epoch 7927/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9300 - accuracy: 0.8711\n",
            "Epoch 7928/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 4.0056 - accuracy: 0.8667\n",
            "Epoch 7929/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.8336 - accuracy: 0.8533\n",
            "Epoch 7930/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 3.8662 - accuracy: 0.8444\n",
            "Epoch 7931/10000\n",
            "225/225 [==============================] - 0s 506us/step - loss: 3.9518 - accuracy: 0.8311\n",
            "Epoch 7932/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.9499 - accuracy: 0.8489\n",
            "Epoch 7933/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.8569 - accuracy: 0.8622\n",
            "Epoch 7934/10000\n",
            "225/225 [==============================] - 0s 507us/step - loss: 3.9498 - accuracy: 0.8400\n",
            "Epoch 7935/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9595 - accuracy: 0.8444\n",
            "Epoch 7936/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9256 - accuracy: 0.8444\n",
            "Epoch 7937/10000\n",
            "225/225 [==============================] - 0s 541us/step - loss: 3.9346 - accuracy: 0.8489\n",
            "Epoch 7938/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9537 - accuracy: 0.8533\n",
            "Epoch 7939/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.8578 - accuracy: 0.8800\n",
            "Epoch 7940/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0064 - accuracy: 0.8356\n",
            "Epoch 7941/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.9840 - accuracy: 0.8578\n",
            "Epoch 7942/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9721 - accuracy: 0.8622\n",
            "Epoch 7943/10000\n",
            "225/225 [==============================] - 0s 530us/step - loss: 3.8394 - accuracy: 0.8578\n",
            "Epoch 7944/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9859 - accuracy: 0.8622\n",
            "Epoch 7945/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9333 - accuracy: 0.8489\n",
            "Epoch 7946/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 4.2033 - accuracy: 0.8489\n",
            "Epoch 7947/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.0300 - accuracy: 0.8578\n",
            "Epoch 7948/10000\n",
            "225/225 [==============================] - 0s 550us/step - loss: 3.9998 - accuracy: 0.8578\n",
            "Epoch 7949/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.8778 - accuracy: 0.8978\n",
            "Epoch 7950/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 3.8906 - accuracy: 0.8356\n",
            "Epoch 7951/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9585 - accuracy: 0.8489\n",
            "Epoch 7952/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 4.0685 - accuracy: 0.8756\n",
            "Epoch 7953/10000\n",
            "225/225 [==============================] - 0s 576us/step - loss: 3.8902 - accuracy: 0.8578\n",
            "Epoch 7954/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9160 - accuracy: 0.8667\n",
            "Epoch 7955/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9695 - accuracy: 0.8356\n",
            "Epoch 7956/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.9873 - accuracy: 0.8356\n",
            "Epoch 7957/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 3.8386 - accuracy: 0.8444\n",
            "Epoch 7958/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 4.0636 - accuracy: 0.8533\n",
            "Epoch 7959/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.7027 - accuracy: 0.8444\n",
            "Epoch 7960/10000\n",
            "225/225 [==============================] - 0s 517us/step - loss: 4.0165 - accuracy: 0.8622\n",
            "Epoch 7961/10000\n",
            "225/225 [==============================] - 0s 546us/step - loss: 3.9189 - accuracy: 0.8711\n",
            "Epoch 7962/10000\n",
            "225/225 [==============================] - 0s 536us/step - loss: 3.7011 - accuracy: 0.8356\n",
            "Epoch 7963/10000\n",
            "225/225 [==============================] - 0s 524us/step - loss: 3.9284 - accuracy: 0.8444\n",
            "Epoch 7964/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.9720 - accuracy: 0.8444\n",
            "Epoch 7965/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0475 - accuracy: 0.8756\n",
            "Epoch 7966/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.8856 - accuracy: 0.8711\n",
            "Epoch 7967/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9045 - accuracy: 0.9022\n",
            "Epoch 7968/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9559 - accuracy: 0.8533\n",
            "Epoch 7969/10000\n",
            "225/225 [==============================] - 0s 522us/step - loss: 4.0590 - accuracy: 0.8711\n",
            "Epoch 7970/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 4.0719 - accuracy: 0.8356\n",
            "Epoch 7971/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0562 - accuracy: 0.8578\n",
            "Epoch 7972/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9894 - accuracy: 0.8756\n",
            "Epoch 7973/10000\n",
            "225/225 [==============================] - 0s 544us/step - loss: 3.8377 - accuracy: 0.8489\n",
            "Epoch 7974/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.8908 - accuracy: 0.8800\n",
            "Epoch 7975/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.8667 - accuracy: 0.8356\n",
            "Epoch 7976/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 4.0171 - accuracy: 0.8311\n",
            "Epoch 7977/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0679 - accuracy: 0.8622\n",
            "Epoch 7978/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 4.0013 - accuracy: 0.8622\n",
            "Epoch 7979/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9532 - accuracy: 0.8489\n",
            "Epoch 7980/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 4.0530 - accuracy: 0.8444\n",
            "Epoch 7981/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.8463 - accuracy: 0.9022\n",
            "Epoch 7982/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.0343 - accuracy: 0.8444\n",
            "Epoch 7983/10000\n",
            "225/225 [==============================] - 0s 497us/step - loss: 4.0233 - accuracy: 0.8667\n",
            "Epoch 7984/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9318 - accuracy: 0.8756\n",
            "Epoch 7985/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9319 - accuracy: 0.8933\n",
            "Epoch 7986/10000\n",
            "225/225 [==============================] - 0s 508us/step - loss: 3.9102 - accuracy: 0.8756\n",
            "Epoch 7987/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 4.1009 - accuracy: 0.8711\n",
            "Epoch 7988/10000\n",
            "225/225 [==============================] - 0s 534us/step - loss: 3.5257 - accuracy: 0.8578\n",
            "Epoch 7989/10000\n",
            "225/225 [==============================] - 0s 533us/step - loss: 4.0009 - accuracy: 0.8800\n",
            "Epoch 7990/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.7575 - accuracy: 0.8756\n",
            "Epoch 7991/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0012 - accuracy: 0.8622\n",
            "Epoch 7992/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.2069 - accuracy: 0.8622\n",
            "Epoch 7993/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.0724 - accuracy: 0.8533\n",
            "Epoch 7994/10000\n",
            "225/225 [==============================] - 0s 538us/step - loss: 3.9413 - accuracy: 0.8533\n",
            "Epoch 7995/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9776 - accuracy: 0.8489\n",
            "Epoch 7996/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.8095 - accuracy: 0.8800\n",
            "Epoch 7997/10000\n",
            "225/225 [==============================] - 0s 498us/step - loss: 3.9617 - accuracy: 0.8489\n",
            "Epoch 7998/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9157 - accuracy: 0.8533\n",
            "Epoch 7999/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.8940 - accuracy: 0.8756\n",
            "Epoch 8000/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.0511 - accuracy: 0.8889\n",
            "Epoch 8001/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 4.0218 - accuracy: 0.8356\n",
            "Epoch 8002/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9603 - accuracy: 0.8711\n",
            "Epoch 8003/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 4.1203 - accuracy: 0.8400\n",
            "Epoch 8004/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 4.0500 - accuracy: 0.8667\n",
            "Epoch 8005/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.6806 - accuracy: 0.8622\n",
            "Epoch 8006/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 3.9879 - accuracy: 0.8533\n",
            "Epoch 8007/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0492 - accuracy: 0.8356\n",
            "Epoch 8008/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 4.0854 - accuracy: 0.8844\n",
            "Epoch 8009/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 3.9456 - accuracy: 0.8622\n",
            "Epoch 8010/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 3.9359 - accuracy: 0.8444\n",
            "Epoch 8011/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 4.0069 - accuracy: 0.8667\n",
            "Epoch 8012/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9995 - accuracy: 0.8444\n",
            "Epoch 8013/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9254 - accuracy: 0.8400\n",
            "Epoch 8014/10000\n",
            "225/225 [==============================] - 0s 516us/step - loss: 3.8866 - accuracy: 0.8667\n",
            "Epoch 8015/10000\n",
            "225/225 [==============================] - 0s 512us/step - loss: 4.0581 - accuracy: 0.8800\n",
            "Epoch 8016/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9543 - accuracy: 0.8533\n",
            "Epoch 8017/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9267 - accuracy: 0.8622\n",
            "Epoch 8018/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9841 - accuracy: 0.8578\n",
            "Epoch 8019/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 3.9425 - accuracy: 0.8356\n",
            "Epoch 8020/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.9389 - accuracy: 0.8800\n",
            "Epoch 8021/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9370 - accuracy: 0.8489\n",
            "Epoch 8022/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0837 - accuracy: 0.8711\n",
            "Epoch 8023/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9390 - accuracy: 0.8756\n",
            "Epoch 8024/10000\n",
            "225/225 [==============================] - 0s 528us/step - loss: 4.2096 - accuracy: 0.8444\n",
            "Epoch 8025/10000\n",
            "225/225 [==============================] - 0s 525us/step - loss: 4.0484 - accuracy: 0.8578\n",
            "Epoch 8026/10000\n",
            "225/225 [==============================] - 0s 564us/step - loss: 3.9659 - accuracy: 0.8711\n",
            "Epoch 8027/10000\n",
            "225/225 [==============================] - 0s 567us/step - loss: 4.0074 - accuracy: 0.8533\n",
            "Epoch 8028/10000\n",
            "225/225 [==============================] - 0s 539us/step - loss: 3.8714 - accuracy: 0.8444\n",
            "Epoch 8029/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9181 - accuracy: 0.8578\n",
            "Epoch 8030/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.8886 - accuracy: 0.8622\n",
            "Epoch 8031/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9473 - accuracy: 0.8622\n",
            "Epoch 8032/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 4.0696 - accuracy: 0.8756\n",
            "Epoch 8033/10000\n",
            "225/225 [==============================] - 0s 517us/step - loss: 3.9540 - accuracy: 0.8622\n",
            "Epoch 8034/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9582 - accuracy: 0.8667\n",
            "Epoch 8035/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9031 - accuracy: 0.8533\n",
            "Epoch 8036/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0405 - accuracy: 0.8622\n",
            "Epoch 8037/10000\n",
            "225/225 [==============================] - 0s 494us/step - loss: 3.8931 - accuracy: 0.8444\n",
            "Epoch 8038/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 3.8652 - accuracy: 0.8533\n",
            "Epoch 8039/10000\n",
            "225/225 [==============================] - 0s 501us/step - loss: 3.7984 - accuracy: 0.8533\n",
            "Epoch 8040/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 4.0159 - accuracy: 0.8622\n",
            "Epoch 8041/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9912 - accuracy: 0.8533\n",
            "Epoch 8042/10000\n",
            "225/225 [==============================] - 0s 597us/step - loss: 3.8669 - accuracy: 0.8444\n",
            "Epoch 8043/10000\n",
            "225/225 [==============================] - 0s 552us/step - loss: 3.9345 - accuracy: 0.8578\n",
            "Epoch 8044/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.8646 - accuracy: 0.8622\n",
            "Epoch 8045/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.0999 - accuracy: 0.8578\n",
            "Epoch 8046/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 4.0555 - accuracy: 0.8311\n",
            "Epoch 8047/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9070 - accuracy: 0.8756\n",
            "Epoch 8048/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9602 - accuracy: 0.8400\n",
            "Epoch 8049/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.1387 - accuracy: 0.8489\n",
            "Epoch 8050/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 3.9836 - accuracy: 0.8311\n",
            "Epoch 8051/10000\n",
            "225/225 [==============================] - 0s 529us/step - loss: 3.9522 - accuracy: 0.8711\n",
            "Epoch 8052/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.6681 - accuracy: 0.8489\n",
            "Epoch 8053/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 4.1276 - accuracy: 0.8489\n",
            "Epoch 8054/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9542 - accuracy: 0.8489\n",
            "Epoch 8055/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.8872 - accuracy: 0.8889\n",
            "Epoch 8056/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9408 - accuracy: 0.8489\n",
            "Epoch 8057/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9536 - accuracy: 0.8622\n",
            "Epoch 8058/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 4.0790 - accuracy: 0.8356\n",
            "Epoch 8059/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9361 - accuracy: 0.8711\n",
            "Epoch 8060/10000\n",
            "225/225 [==============================] - 0s 506us/step - loss: 4.0035 - accuracy: 0.8533\n",
            "Epoch 8061/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 3.8302 - accuracy: 0.8489\n",
            "Epoch 8062/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8985 - accuracy: 0.8622\n",
            "Epoch 8063/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9504 - accuracy: 0.8800\n",
            "Epoch 8064/10000\n",
            "225/225 [==============================] - 0s 528us/step - loss: 3.9568 - accuracy: 0.8444\n",
            "Epoch 8065/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0807 - accuracy: 0.8667\n",
            "Epoch 8066/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.9375 - accuracy: 0.8578\n",
            "Epoch 8067/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.9963 - accuracy: 0.8711\n",
            "Epoch 8068/10000\n",
            "225/225 [==============================] - 0s 556us/step - loss: 4.0107 - accuracy: 0.8933\n",
            "Epoch 8069/10000\n",
            "225/225 [==============================] - 0s 515us/step - loss: 3.8601 - accuracy: 0.8311\n",
            "Epoch 8070/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.1155 - accuracy: 0.8667\n",
            "Epoch 8071/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0556 - accuracy: 0.8622\n",
            "Epoch 8072/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9446 - accuracy: 0.8667\n",
            "Epoch 8073/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9550 - accuracy: 0.8444\n",
            "Epoch 8074/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9603 - accuracy: 0.8844\n",
            "Epoch 8075/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0890 - accuracy: 0.8444\n",
            "Epoch 8076/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0224 - accuracy: 0.8667\n",
            "Epoch 8077/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9990 - accuracy: 0.8311\n",
            "Epoch 8078/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 3.9672 - accuracy: 0.8667\n",
            "Epoch 8079/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.8860 - accuracy: 0.8489\n",
            "Epoch 8080/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 4.0552 - accuracy: 0.8489\n",
            "Epoch 8081/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9743 - accuracy: 0.8533\n",
            "Epoch 8082/10000\n",
            "225/225 [==============================] - 0s 520us/step - loss: 4.0549 - accuracy: 0.8756\n",
            "Epoch 8083/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9267 - accuracy: 0.8444\n",
            "Epoch 8084/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.8891 - accuracy: 0.8444\n",
            "Epoch 8085/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9410 - accuracy: 0.8400\n",
            "Epoch 8086/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9488 - accuracy: 0.8356\n",
            "Epoch 8087/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 3.8960 - accuracy: 0.8578\n",
            "Epoch 8088/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9634 - accuracy: 0.8756\n",
            "Epoch 8089/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.9346 - accuracy: 0.8578\n",
            "Epoch 8090/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.8449 - accuracy: 0.8622\n",
            "Epoch 8091/10000\n",
            "225/225 [==============================] - 0s 502us/step - loss: 3.8951 - accuracy: 0.8533\n",
            "Epoch 8092/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9122 - accuracy: 0.8489\n",
            "Epoch 8093/10000\n",
            "225/225 [==============================] - 0s 514us/step - loss: 3.8491 - accuracy: 0.8667\n",
            "Epoch 8094/10000\n",
            "225/225 [==============================] - 0s 504us/step - loss: 3.9541 - accuracy: 0.8533\n",
            "Epoch 8095/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9407 - accuracy: 0.8667\n",
            "Epoch 8096/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.9459 - accuracy: 0.8489\n",
            "Epoch 8097/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 3.8154 - accuracy: 0.8622\n",
            "Epoch 8098/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9823 - accuracy: 0.8578\n",
            "Epoch 8099/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9646 - accuracy: 0.8711\n",
            "Epoch 8100/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 3.9646 - accuracy: 0.8400\n",
            "Epoch 8101/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9533 - accuracy: 0.8222\n",
            "Epoch 8102/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.1182 - accuracy: 0.8578\n",
            "Epoch 8103/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9392 - accuracy: 0.8533\n",
            "Epoch 8104/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9317 - accuracy: 0.8800\n",
            "Epoch 8105/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 3.7903 - accuracy: 0.8711\n",
            "Epoch 8106/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 3.8490 - accuracy: 0.8578\n",
            "Epoch 8107/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9263 - accuracy: 0.8622\n",
            "Epoch 8108/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9322 - accuracy: 0.8622\n",
            "Epoch 8109/10000\n",
            "225/225 [==============================] - 0s 527us/step - loss: 3.9920 - accuracy: 0.8578\n",
            "Epoch 8110/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9872 - accuracy: 0.8444\n",
            "Epoch 8111/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0129 - accuracy: 0.8756\n",
            "Epoch 8112/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 4.0010 - accuracy: 0.8667\n",
            "Epoch 8113/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9285 - accuracy: 0.8756\n",
            "Epoch 8114/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 4.1313 - accuracy: 0.8356\n",
            "Epoch 8115/10000\n",
            "225/225 [==============================] - 0s 510us/step - loss: 3.8887 - accuracy: 0.8844\n",
            "Epoch 8116/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.9739 - accuracy: 0.8444\n",
            "Epoch 8117/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0121 - accuracy: 0.8533\n",
            "Epoch 8118/10000\n",
            "225/225 [==============================] - 0s 520us/step - loss: 4.0200 - accuracy: 0.8622\n",
            "Epoch 8119/10000\n",
            "225/225 [==============================] - 0s 516us/step - loss: 3.9853 - accuracy: 0.8711\n",
            "Epoch 8120/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.6571 - accuracy: 0.8533\n",
            "Epoch 8121/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9514 - accuracy: 0.8711\n",
            "Epoch 8122/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.8970 - accuracy: 0.8400\n",
            "Epoch 8123/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 4.0441 - accuracy: 0.8533\n",
            "Epoch 8124/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 3.8528 - accuracy: 0.8667\n",
            "Epoch 8125/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9553 - accuracy: 0.8489\n",
            "Epoch 8126/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.8840 - accuracy: 0.8933\n",
            "Epoch 8127/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 4.0625 - accuracy: 0.8533\n",
            "Epoch 8128/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9666 - accuracy: 0.8533\n",
            "Epoch 8129/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0644 - accuracy: 0.8311\n",
            "Epoch 8130/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.9576 - accuracy: 0.8578\n",
            "Epoch 8131/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.8897 - accuracy: 0.8756\n",
            "Epoch 8132/10000\n",
            "225/225 [==============================] - 0s 578us/step - loss: 3.9326 - accuracy: 0.8622\n",
            "Epoch 8133/10000\n",
            "225/225 [==============================] - 0s 522us/step - loss: 3.8768 - accuracy: 0.8622\n",
            "Epoch 8134/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0034 - accuracy: 0.8533\n",
            "Epoch 8135/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.1703 - accuracy: 0.8667\n",
            "Epoch 8136/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 4.1062 - accuracy: 0.8800\n",
            "Epoch 8137/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9266 - accuracy: 0.8578\n",
            "Epoch 8138/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9642 - accuracy: 0.8489\n",
            "Epoch 8139/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9536 - accuracy: 0.8667\n",
            "Epoch 8140/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.8327 - accuracy: 0.8756\n",
            "Epoch 8141/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.8614 - accuracy: 0.8578\n",
            "Epoch 8142/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 4.1732 - accuracy: 0.8400\n",
            "Epoch 8143/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.8874 - accuracy: 0.8711\n",
            "Epoch 8144/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0071 - accuracy: 0.8533\n",
            "Epoch 8145/10000\n",
            "225/225 [==============================] - 0s 558us/step - loss: 3.9831 - accuracy: 0.8667\n",
            "Epoch 8146/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9490 - accuracy: 0.8756\n",
            "Epoch 8147/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9267 - accuracy: 0.8356\n",
            "Epoch 8148/10000\n",
            "225/225 [==============================] - 0s 540us/step - loss: 4.0156 - accuracy: 0.8489\n",
            "Epoch 8149/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9935 - accuracy: 0.8711\n",
            "Epoch 8150/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9963 - accuracy: 0.8622\n",
            "Epoch 8151/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 3.9794 - accuracy: 0.8578\n",
            "Epoch 8152/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9283 - accuracy: 0.8578\n",
            "Epoch 8153/10000\n",
            "225/225 [==============================] - 0s 507us/step - loss: 3.9268 - accuracy: 0.8667\n",
            "Epoch 8154/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.6852 - accuracy: 0.8444\n",
            "Epoch 8155/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.8516 - accuracy: 0.8622\n",
            "Epoch 8156/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9281 - accuracy: 0.8489\n",
            "Epoch 8157/10000\n",
            "225/225 [==============================] - 0s 497us/step - loss: 3.6666 - accuracy: 0.8533\n",
            "Epoch 8158/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9247 - accuracy: 0.8400\n",
            "Epoch 8159/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0754 - accuracy: 0.8489\n",
            "Epoch 8160/10000\n",
            "225/225 [==============================] - 0s 509us/step - loss: 3.9118 - accuracy: 0.8444\n",
            "Epoch 8161/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9098 - accuracy: 0.8400\n",
            "Epoch 8162/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9285 - accuracy: 0.8622\n",
            "Epoch 8163/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 4.0125 - accuracy: 0.8622\n",
            "Epoch 8164/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 4.1262 - accuracy: 0.8622\n",
            "Epoch 8165/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0725 - accuracy: 0.8356\n",
            "Epoch 8166/10000\n",
            "225/225 [==============================] - 0s 543us/step - loss: 3.9996 - accuracy: 0.8667\n",
            "Epoch 8167/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.0109 - accuracy: 0.8444\n",
            "Epoch 8168/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 3.9693 - accuracy: 0.8667\n",
            "Epoch 8169/10000\n",
            "225/225 [==============================] - 0s 529us/step - loss: 4.0103 - accuracy: 0.8756\n",
            "Epoch 8170/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.0853 - accuracy: 0.8800\n",
            "Epoch 8171/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 4.1066 - accuracy: 0.8533\n",
            "Epoch 8172/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 3.9852 - accuracy: 0.8444\n",
            "Epoch 8173/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 3.8894 - accuracy: 0.8356\n",
            "Epoch 8174/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9070 - accuracy: 0.8578\n",
            "Epoch 8175/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9835 - accuracy: 0.8667\n",
            "Epoch 8176/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 4.0482 - accuracy: 0.8267\n",
            "Epoch 8177/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.6794 - accuracy: 0.8533\n",
            "Epoch 8178/10000\n",
            "225/225 [==============================] - 0s 514us/step - loss: 3.9041 - accuracy: 0.8622\n",
            "Epoch 8179/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 4.0038 - accuracy: 0.8711\n",
            "Epoch 8180/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 4.0116 - accuracy: 0.8222\n",
            "Epoch 8181/10000\n",
            "225/225 [==============================] - 0s 502us/step - loss: 3.9550 - accuracy: 0.8756\n",
            "Epoch 8182/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9774 - accuracy: 0.8667\n",
            "Epoch 8183/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 3.9734 - accuracy: 0.8578\n",
            "Epoch 8184/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 3.9346 - accuracy: 0.8578\n",
            "Epoch 8185/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.0047 - accuracy: 0.8667\n",
            "Epoch 8186/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0075 - accuracy: 0.8578\n",
            "Epoch 8187/10000\n",
            "225/225 [==============================] - 0s 526us/step - loss: 3.6445 - accuracy: 0.8489\n",
            "Epoch 8188/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.0373 - accuracy: 0.8667\n",
            "Epoch 8189/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 4.0523 - accuracy: 0.8311\n",
            "Epoch 8190/10000\n",
            "225/225 [==============================] - 0s 507us/step - loss: 3.9662 - accuracy: 0.8667\n",
            "Epoch 8191/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9794 - accuracy: 0.8533\n",
            "Epoch 8192/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 4.0238 - accuracy: 0.8444\n",
            "Epoch 8193/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9390 - accuracy: 0.8667\n",
            "Epoch 8194/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9922 - accuracy: 0.8578\n",
            "Epoch 8195/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9845 - accuracy: 0.8667\n",
            "Epoch 8196/10000\n",
            "225/225 [==============================] - 0s 494us/step - loss: 3.9240 - accuracy: 0.8578\n",
            "Epoch 8197/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9338 - accuracy: 0.8533\n",
            "Epoch 8198/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.0955 - accuracy: 0.8622\n",
            "Epoch 8199/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 3.8728 - accuracy: 0.8400\n",
            "Epoch 8200/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9778 - accuracy: 0.8311\n",
            "Epoch 8201/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9708 - accuracy: 0.8489\n",
            "Epoch 8202/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9231 - accuracy: 0.8444\n",
            "Epoch 8203/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.9085 - accuracy: 0.8578\n",
            "Epoch 8204/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.8977 - accuracy: 0.8889\n",
            "Epoch 8205/10000\n",
            "225/225 [==============================] - 0s 451us/step - loss: 4.1486 - accuracy: 0.8533\n",
            "Epoch 8206/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.0927 - accuracy: 0.8667\n",
            "Epoch 8207/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 4.0308 - accuracy: 0.8711\n",
            "Epoch 8208/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.8293 - accuracy: 0.8400\n",
            "Epoch 8209/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 3.8815 - accuracy: 0.8356\n",
            "Epoch 8210/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 4.0012 - accuracy: 0.8578\n",
            "Epoch 8211/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9444 - accuracy: 0.8622\n",
            "Epoch 8212/10000\n",
            "225/225 [==============================] - 0s 531us/step - loss: 4.0276 - accuracy: 0.8578\n",
            "Epoch 8213/10000\n",
            "225/225 [==============================] - 0s 533us/step - loss: 4.0148 - accuracy: 0.8444\n",
            "Epoch 8214/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 3.9027 - accuracy: 0.8800\n",
            "Epoch 8215/10000\n",
            "225/225 [==============================] - 0s 538us/step - loss: 3.9855 - accuracy: 0.8489\n",
            "Epoch 8216/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9262 - accuracy: 0.8578\n",
            "Epoch 8217/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9415 - accuracy: 0.8400\n",
            "Epoch 8218/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.8504 - accuracy: 0.8533\n",
            "Epoch 8219/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 4.0175 - accuracy: 0.8533\n",
            "Epoch 8220/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 4.1165 - accuracy: 0.8622\n",
            "Epoch 8221/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.8804 - accuracy: 0.8844\n",
            "Epoch 8222/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.0310 - accuracy: 0.8400\n",
            "Epoch 8223/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9126 - accuracy: 0.8667\n",
            "Epoch 8224/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.8938 - accuracy: 0.8622\n",
            "Epoch 8225/10000\n",
            "225/225 [==============================] - 0s 531us/step - loss: 4.0057 - accuracy: 0.8533\n",
            "Epoch 8226/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0043 - accuracy: 0.8533\n",
            "Epoch 8227/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 4.0465 - accuracy: 0.8489\n",
            "Epoch 8228/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9995 - accuracy: 0.8756\n",
            "Epoch 8229/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 3.8892 - accuracy: 0.8444\n",
            "Epoch 8230/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.9465 - accuracy: 0.8578\n",
            "Epoch 8231/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 4.0256 - accuracy: 0.8489\n",
            "Epoch 8232/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 4.0410 - accuracy: 0.8178\n",
            "Epoch 8233/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.8975 - accuracy: 0.8844\n",
            "Epoch 8234/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 4.0415 - accuracy: 0.8533\n",
            "Epoch 8235/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0527 - accuracy: 0.8400\n",
            "Epoch 8236/10000\n",
            "225/225 [==============================] - 0s 534us/step - loss: 3.8913 - accuracy: 0.8578\n",
            "Epoch 8237/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.6575 - accuracy: 0.8489\n",
            "Epoch 8238/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.7582 - accuracy: 0.8667\n",
            "Epoch 8239/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.8517 - accuracy: 0.8711\n",
            "Epoch 8240/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.0041 - accuracy: 0.8533\n",
            "Epoch 8241/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9137 - accuracy: 0.8578\n",
            "Epoch 8242/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.7902 - accuracy: 0.8978\n",
            "Epoch 8243/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 4.0585 - accuracy: 0.8667\n",
            "Epoch 8244/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0372 - accuracy: 0.8800\n",
            "Epoch 8245/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 4.0233 - accuracy: 0.8489\n",
            "Epoch 8246/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9832 - accuracy: 0.8533\n",
            "Epoch 8247/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9551 - accuracy: 0.8533\n",
            "Epoch 8248/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.8978 - accuracy: 0.8667\n",
            "Epoch 8249/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 4.0234 - accuracy: 0.8489\n",
            "Epoch 8250/10000\n",
            "225/225 [==============================] - 0s 561us/step - loss: 3.8886 - accuracy: 0.8444\n",
            "Epoch 8251/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.8745 - accuracy: 0.8889\n",
            "Epoch 8252/10000\n",
            "225/225 [==============================] - 0s 534us/step - loss: 4.0769 - accuracy: 0.8489\n",
            "Epoch 8253/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9168 - accuracy: 0.8578\n",
            "Epoch 8254/10000\n",
            "225/225 [==============================] - 0s 526us/step - loss: 3.9148 - accuracy: 0.8622\n",
            "Epoch 8255/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.8878 - accuracy: 0.8400\n",
            "Epoch 8256/10000\n",
            "225/225 [==============================] - 0s 559us/step - loss: 3.9619 - accuracy: 0.8533\n",
            "Epoch 8257/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.7863 - accuracy: 0.8489\n",
            "Epoch 8258/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9403 - accuracy: 0.8711\n",
            "Epoch 8259/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.8163 - accuracy: 0.8444\n",
            "Epoch 8260/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.9157 - accuracy: 0.8400\n",
            "Epoch 8261/10000\n",
            "225/225 [==============================] - 0s 500us/step - loss: 3.8625 - accuracy: 0.8578\n",
            "Epoch 8262/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9456 - accuracy: 0.8400\n",
            "Epoch 8263/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 4.0021 - accuracy: 0.8578\n",
            "Epoch 8264/10000\n",
            "225/225 [==============================] - 0s 504us/step - loss: 3.9634 - accuracy: 0.8578\n",
            "Epoch 8265/10000\n",
            "225/225 [==============================] - 0s 580us/step - loss: 3.8734 - accuracy: 0.8667\n",
            "Epoch 8266/10000\n",
            "225/225 [==============================] - 0s 531us/step - loss: 4.0205 - accuracy: 0.8844\n",
            "Epoch 8267/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 4.0052 - accuracy: 0.8756\n",
            "Epoch 8268/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.1105 - accuracy: 0.8800\n",
            "Epoch 8269/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 3.8256 - accuracy: 0.8800\n",
            "Epoch 8270/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9485 - accuracy: 0.8578\n",
            "Epoch 8271/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0190 - accuracy: 0.8622\n",
            "Epoch 8272/10000\n",
            "225/225 [==============================] - 0s 516us/step - loss: 4.0699 - accuracy: 0.8533\n",
            "Epoch 8273/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.0474 - accuracy: 0.8489\n",
            "Epoch 8274/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 4.0046 - accuracy: 0.8311\n",
            "Epoch 8275/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8631 - accuracy: 0.8444\n",
            "Epoch 8276/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.8381 - accuracy: 0.8711\n",
            "Epoch 8277/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9240 - accuracy: 0.8400\n",
            "Epoch 8278/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.8809 - accuracy: 0.8622\n",
            "Epoch 8279/10000\n",
            "225/225 [==============================] - 0s 527us/step - loss: 3.9610 - accuracy: 0.8489\n",
            "Epoch 8280/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9995 - accuracy: 0.8400\n",
            "Epoch 8281/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 4.0295 - accuracy: 0.8578\n",
            "Epoch 8282/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.8686 - accuracy: 0.8889\n",
            "Epoch 8283/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 4.0883 - accuracy: 0.8933\n",
            "Epoch 8284/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9116 - accuracy: 0.8489\n",
            "Epoch 8285/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9291 - accuracy: 0.8489\n",
            "Epoch 8286/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.6256 - accuracy: 0.8400\n",
            "Epoch 8287/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 4.1075 - accuracy: 0.8533\n",
            "Epoch 8288/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 4.0543 - accuracy: 0.8667\n",
            "Epoch 8289/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 4.0211 - accuracy: 0.8444\n",
            "Epoch 8290/10000\n",
            "225/225 [==============================] - 0s 514us/step - loss: 4.2550 - accuracy: 0.8578\n",
            "Epoch 8291/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.8527 - accuracy: 0.8400\n",
            "Epoch 8292/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 4.0204 - accuracy: 0.8489\n",
            "Epoch 8293/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0260 - accuracy: 0.8578\n",
            "Epoch 8294/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.0102 - accuracy: 0.8533\n",
            "Epoch 8295/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 4.0939 - accuracy: 0.8533\n",
            "Epoch 8296/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0641 - accuracy: 0.8756\n",
            "Epoch 8297/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 4.0261 - accuracy: 0.8578\n",
            "Epoch 8298/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.0132 - accuracy: 0.8844\n",
            "Epoch 8299/10000\n",
            "225/225 [==============================] - 0s 521us/step - loss: 3.8827 - accuracy: 0.8444\n",
            "Epoch 8300/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9940 - accuracy: 0.8978\n",
            "Epoch 8301/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0813 - accuracy: 0.8800\n",
            "Epoch 8302/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9461 - accuracy: 0.8667\n",
            "Epoch 8303/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.6444 - accuracy: 0.8489\n",
            "Epoch 8304/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9024 - accuracy: 0.8622\n",
            "Epoch 8305/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 4.0179 - accuracy: 0.8533\n",
            "Epoch 8306/10000\n",
            "225/225 [==============================] - 0s 591us/step - loss: 4.0529 - accuracy: 0.8489\n",
            "Epoch 8307/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9677 - accuracy: 0.8356\n",
            "Epoch 8308/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 3.9239 - accuracy: 0.8667\n",
            "Epoch 8309/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.9601 - accuracy: 0.8489\n",
            "Epoch 8310/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 4.0735 - accuracy: 0.8578\n",
            "Epoch 8311/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9431 - accuracy: 0.8578\n",
            "Epoch 8312/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9260 - accuracy: 0.8667\n",
            "Epoch 8313/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0202 - accuracy: 0.8400\n",
            "Epoch 8314/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0875 - accuracy: 0.8400\n",
            "Epoch 8315/10000\n",
            "225/225 [==============================] - 0s 539us/step - loss: 3.9116 - accuracy: 0.8667\n",
            "Epoch 8316/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9660 - accuracy: 0.8178\n",
            "Epoch 8317/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 4.0169 - accuracy: 0.8711\n",
            "Epoch 8318/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 4.0105 - accuracy: 0.8622\n",
            "Epoch 8319/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.8132 - accuracy: 0.8711\n",
            "Epoch 8320/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.7594 - accuracy: 0.8667\n",
            "Epoch 8321/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9261 - accuracy: 0.8400\n",
            "Epoch 8322/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9867 - accuracy: 0.8311\n",
            "Epoch 8323/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.9988 - accuracy: 0.8622\n",
            "Epoch 8324/10000\n",
            "225/225 [==============================] - 0s 538us/step - loss: 4.0524 - accuracy: 0.8756\n",
            "Epoch 8325/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9187 - accuracy: 0.8711\n",
            "Epoch 8326/10000\n",
            "225/225 [==============================] - 0s 563us/step - loss: 3.8750 - accuracy: 0.8667\n",
            "Epoch 8327/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9592 - accuracy: 0.8489\n",
            "Epoch 8328/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.8540 - accuracy: 0.8711\n",
            "Epoch 8329/10000\n",
            "225/225 [==============================] - 0s 554us/step - loss: 3.9307 - accuracy: 0.8844\n",
            "Epoch 8330/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 3.8263 - accuracy: 0.8667\n",
            "Epoch 8331/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8218 - accuracy: 0.8489\n",
            "Epoch 8332/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9940 - accuracy: 0.8356\n",
            "Epoch 8333/10000\n",
            "225/225 [==============================] - 0s 523us/step - loss: 3.8694 - accuracy: 0.8711\n",
            "Epoch 8334/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.8994 - accuracy: 0.8489\n",
            "Epoch 8335/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 4.0271 - accuracy: 0.8356\n",
            "Epoch 8336/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9421 - accuracy: 0.8533\n",
            "Epoch 8337/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9299 - accuracy: 0.8622\n",
            "Epoch 8338/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.1025 - accuracy: 0.8356\n",
            "Epoch 8339/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.8179 - accuracy: 0.8489\n",
            "Epoch 8340/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 4.1136 - accuracy: 0.8356\n",
            "Epoch 8341/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9886 - accuracy: 0.8578\n",
            "Epoch 8342/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.8941 - accuracy: 0.8356\n",
            "Epoch 8343/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.9956 - accuracy: 0.8311\n",
            "Epoch 8344/10000\n",
            "225/225 [==============================] - 0s 512us/step - loss: 3.8718 - accuracy: 0.8578\n",
            "Epoch 8345/10000\n",
            "225/225 [==============================] - 0s 540us/step - loss: 3.9466 - accuracy: 0.8622\n",
            "Epoch 8346/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.9807 - accuracy: 0.8356\n",
            "Epoch 8347/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 4.0181 - accuracy: 0.8667\n",
            "Epoch 8348/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0159 - accuracy: 0.8578\n",
            "Epoch 8349/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0045 - accuracy: 0.8711\n",
            "Epoch 8350/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9007 - accuracy: 0.8400\n",
            "Epoch 8351/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.7008 - accuracy: 0.8267\n",
            "Epoch 8352/10000\n",
            "225/225 [==============================] - 0s 514us/step - loss: 3.9908 - accuracy: 0.8711\n",
            "Epoch 8353/10000\n",
            "225/225 [==============================] - 0s 528us/step - loss: 3.8906 - accuracy: 0.8356\n",
            "Epoch 8354/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 4.0997 - accuracy: 0.8622\n",
            "Epoch 8355/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0131 - accuracy: 0.8578\n",
            "Epoch 8356/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.8937 - accuracy: 0.8667\n",
            "Epoch 8357/10000\n",
            "225/225 [==============================] - 0s 506us/step - loss: 3.9067 - accuracy: 0.8400\n",
            "Epoch 8358/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.8351 - accuracy: 0.8578\n",
            "Epoch 8359/10000\n",
            "225/225 [==============================] - 0s 524us/step - loss: 4.0670 - accuracy: 0.8578\n",
            "Epoch 8360/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.7870 - accuracy: 0.8489\n",
            "Epoch 8361/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.9544 - accuracy: 0.8444\n",
            "Epoch 8362/10000\n",
            "225/225 [==============================] - 0s 553us/step - loss: 4.0318 - accuracy: 0.8222\n",
            "Epoch 8363/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9299 - accuracy: 0.8889\n",
            "Epoch 8364/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9835 - accuracy: 0.8711\n",
            "Epoch 8365/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.8773 - accuracy: 0.8800\n",
            "Epoch 8366/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9979 - accuracy: 0.8622\n",
            "Epoch 8367/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9929 - accuracy: 0.8489\n",
            "Epoch 8368/10000\n",
            "225/225 [==============================] - 0s 501us/step - loss: 3.8928 - accuracy: 0.8400\n",
            "Epoch 8369/10000\n",
            "225/225 [==============================] - 0s 504us/step - loss: 3.7283 - accuracy: 0.8533\n",
            "Epoch 8370/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.9441 - accuracy: 0.8711\n",
            "Epoch 8371/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 4.0033 - accuracy: 0.8356\n",
            "Epoch 8372/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 4.1440 - accuracy: 0.8533\n",
            "Epoch 8373/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9309 - accuracy: 0.8622\n",
            "Epoch 8374/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0010 - accuracy: 0.8489\n",
            "Epoch 8375/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0323 - accuracy: 0.8533\n",
            "Epoch 8376/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 4.0742 - accuracy: 0.8311\n",
            "Epoch 8377/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9944 - accuracy: 0.8533\n",
            "Epoch 8378/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9756 - accuracy: 0.8578\n",
            "Epoch 8379/10000\n",
            "225/225 [==============================] - 0s 504us/step - loss: 4.1612 - accuracy: 0.8444\n",
            "Epoch 8380/10000\n",
            "225/225 [==============================] - 0s 552us/step - loss: 3.9650 - accuracy: 0.8667\n",
            "Epoch 8381/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.0000 - accuracy: 0.8578\n",
            "Epoch 8382/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0316 - accuracy: 0.8578\n",
            "Epoch 8383/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.8896 - accuracy: 0.8756\n",
            "Epoch 8384/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9990 - accuracy: 0.8400\n",
            "Epoch 8385/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 3.9518 - accuracy: 0.8533\n",
            "Epoch 8386/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.8640 - accuracy: 0.8667\n",
            "Epoch 8387/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.8852 - accuracy: 0.8800\n",
            "Epoch 8388/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 4.0140 - accuracy: 0.8267\n",
            "Epoch 8389/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.8807 - accuracy: 0.8533\n",
            "Epoch 8390/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.1478 - accuracy: 0.8400\n",
            "Epoch 8391/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9633 - accuracy: 0.8400\n",
            "Epoch 8392/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0033 - accuracy: 0.8533\n",
            "Epoch 8393/10000\n",
            "225/225 [==============================] - 0s 501us/step - loss: 4.0624 - accuracy: 0.8578\n",
            "Epoch 8394/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9071 - accuracy: 0.8489\n",
            "Epoch 8395/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.1179 - accuracy: 0.8578\n",
            "Epoch 8396/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.7631 - accuracy: 0.8756\n",
            "Epoch 8397/10000\n",
            "225/225 [==============================] - 0s 525us/step - loss: 4.1085 - accuracy: 0.8667\n",
            "Epoch 8398/10000\n",
            "225/225 [==============================] - 0s 539us/step - loss: 3.8996 - accuracy: 0.8711\n",
            "Epoch 8399/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.8865 - accuracy: 0.8489\n",
            "Epoch 8400/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9042 - accuracy: 0.8667\n",
            "Epoch 8401/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 4.0771 - accuracy: 0.8400\n",
            "Epoch 8402/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0881 - accuracy: 0.8533\n",
            "Epoch 8403/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 4.0136 - accuracy: 0.8400\n",
            "Epoch 8404/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.0455 - accuracy: 0.8711\n",
            "Epoch 8405/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9731 - accuracy: 0.8489\n",
            "Epoch 8406/10000\n",
            "225/225 [==============================] - 0s 528us/step - loss: 3.9215 - accuracy: 0.8533\n",
            "Epoch 8407/10000\n",
            "225/225 [==============================] - 0s 506us/step - loss: 4.0262 - accuracy: 0.8844\n",
            "Epoch 8408/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9634 - accuracy: 0.8756\n",
            "Epoch 8409/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.1028 - accuracy: 0.8489\n",
            "Epoch 8410/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 4.0678 - accuracy: 0.8667\n",
            "Epoch 8411/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9375 - accuracy: 0.8533\n",
            "Epoch 8412/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9328 - accuracy: 0.8533\n",
            "Epoch 8413/10000\n",
            "225/225 [==============================] - 0s 521us/step - loss: 4.0131 - accuracy: 0.8533\n",
            "Epoch 8414/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.1497 - accuracy: 0.8667\n",
            "Epoch 8415/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 4.1010 - accuracy: 0.8578\n",
            "Epoch 8416/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 3.8761 - accuracy: 0.8356\n",
            "Epoch 8417/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.5853 - accuracy: 0.8622\n",
            "Epoch 8418/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9114 - accuracy: 0.8533\n",
            "Epoch 8419/10000\n",
            "225/225 [==============================] - 0s 520us/step - loss: 3.9420 - accuracy: 0.8667\n",
            "Epoch 8420/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.8884 - accuracy: 0.8444\n",
            "Epoch 8421/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9552 - accuracy: 0.8311\n",
            "Epoch 8422/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.8904 - accuracy: 0.8489\n",
            "Epoch 8423/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.8391 - accuracy: 0.8800\n",
            "Epoch 8424/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 3.9080 - accuracy: 0.8622\n",
            "Epoch 8425/10000\n",
            "225/225 [==============================] - 0s 494us/step - loss: 3.8541 - accuracy: 0.8578\n",
            "Epoch 8426/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 4.0341 - accuracy: 0.8533\n",
            "Epoch 8427/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 4.0459 - accuracy: 0.8400\n",
            "Epoch 8428/10000\n",
            "225/225 [==============================] - 0s 568us/step - loss: 4.0352 - accuracy: 0.8667\n",
            "Epoch 8429/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9518 - accuracy: 0.8622\n",
            "Epoch 8430/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.5909 - accuracy: 0.8711\n",
            "Epoch 8431/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9991 - accuracy: 0.8622\n",
            "Epoch 8432/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.8568 - accuracy: 0.8489\n",
            "Epoch 8433/10000\n",
            "225/225 [==============================] - 0s 512us/step - loss: 3.9664 - accuracy: 0.8622\n",
            "Epoch 8434/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 3.9295 - accuracy: 0.8578\n",
            "Epoch 8435/10000\n",
            "225/225 [==============================] - 0s 517us/step - loss: 4.0211 - accuracy: 0.8844\n",
            "Epoch 8436/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.9686 - accuracy: 0.8622\n",
            "Epoch 8437/10000\n",
            "225/225 [==============================] - 0s 557us/step - loss: 3.9704 - accuracy: 0.8444\n",
            "Epoch 8438/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 4.0129 - accuracy: 0.8711\n",
            "Epoch 8439/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.8406 - accuracy: 0.8933\n",
            "Epoch 8440/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0123 - accuracy: 0.8533\n",
            "Epoch 8441/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0627 - accuracy: 0.8578\n",
            "Epoch 8442/10000\n",
            "225/225 [==============================] - 0s 510us/step - loss: 3.8833 - accuracy: 0.8711\n",
            "Epoch 8443/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 3.6979 - accuracy: 0.8889\n",
            "Epoch 8444/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9267 - accuracy: 0.8533\n",
            "Epoch 8445/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9111 - accuracy: 0.8711\n",
            "Epoch 8446/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9966 - accuracy: 0.8667\n",
            "Epoch 8447/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.5591 - accuracy: 0.8667\n",
            "Epoch 8448/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.8978 - accuracy: 0.8400\n",
            "Epoch 8449/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.1848 - accuracy: 0.8578\n",
            "Epoch 8450/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.7186 - accuracy: 0.8489\n",
            "Epoch 8451/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 3.9876 - accuracy: 0.8489\n",
            "Epoch 8452/10000\n",
            "225/225 [==============================] - 0s 522us/step - loss: 3.9100 - accuracy: 0.8578\n",
            "Epoch 8453/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.1899 - accuracy: 0.8800\n",
            "Epoch 8454/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.1760 - accuracy: 0.8756\n",
            "Epoch 8455/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0495 - accuracy: 0.8311\n",
            "Epoch 8456/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9161 - accuracy: 0.8622\n",
            "Epoch 8457/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0302 - accuracy: 0.8622\n",
            "Epoch 8458/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.9932 - accuracy: 0.8533\n",
            "Epoch 8459/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9814 - accuracy: 0.8444\n",
            "Epoch 8460/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 3.9324 - accuracy: 0.8533\n",
            "Epoch 8461/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 4.0062 - accuracy: 0.8889\n",
            "Epoch 8462/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.9667 - accuracy: 0.8578\n",
            "Epoch 8463/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9236 - accuracy: 0.8578\n",
            "Epoch 8464/10000\n",
            "225/225 [==============================] - 0s 535us/step - loss: 3.9984 - accuracy: 0.8578\n",
            "Epoch 8465/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9221 - accuracy: 0.8444\n",
            "Epoch 8466/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 4.0119 - accuracy: 0.8489\n",
            "Epoch 8467/10000\n",
            "225/225 [==============================] - 0s 499us/step - loss: 3.8683 - accuracy: 0.8578\n",
            "Epoch 8468/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9795 - accuracy: 0.8489\n",
            "Epoch 8469/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.5875 - accuracy: 0.8533\n",
            "Epoch 8470/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 4.0089 - accuracy: 0.8933\n",
            "Epoch 8471/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 4.0111 - accuracy: 0.8533\n",
            "Epoch 8472/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9535 - accuracy: 0.8622\n",
            "Epoch 8473/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 4.0479 - accuracy: 0.8667\n",
            "Epoch 8474/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.8237 - accuracy: 0.8622\n",
            "Epoch 8475/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9062 - accuracy: 0.8622\n",
            "Epoch 8476/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0534 - accuracy: 0.8533\n",
            "Epoch 8477/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 3.9597 - accuracy: 0.8622\n",
            "Epoch 8478/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 3.9261 - accuracy: 0.8178\n",
            "Epoch 8479/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 4.0068 - accuracy: 0.8711\n",
            "Epoch 8480/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.8967 - accuracy: 0.8800\n",
            "Epoch 8481/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9689 - accuracy: 0.8400\n",
            "Epoch 8482/10000\n",
            "225/225 [==============================] - 0s 531us/step - loss: 4.0231 - accuracy: 0.8489\n",
            "Epoch 8483/10000\n",
            "225/225 [==============================] - 0s 510us/step - loss: 4.0392 - accuracy: 0.8267\n",
            "Epoch 8484/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9062 - accuracy: 0.8622\n",
            "Epoch 8485/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.7527 - accuracy: 0.8667\n",
            "Epoch 8486/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.7642 - accuracy: 0.8667\n",
            "Epoch 8487/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9616 - accuracy: 0.8622\n",
            "Epoch 8488/10000\n",
            "225/225 [==============================] - 0s 530us/step - loss: 3.9616 - accuracy: 0.8489\n",
            "Epoch 8489/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0121 - accuracy: 0.8400\n",
            "Epoch 8490/10000\n",
            "225/225 [==============================] - 0s 526us/step - loss: 4.1840 - accuracy: 0.8489\n",
            "Epoch 8491/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.1373 - accuracy: 0.8489\n",
            "Epoch 8492/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9166 - accuracy: 0.9022\n",
            "Epoch 8493/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 4.0388 - accuracy: 0.8267\n",
            "Epoch 8494/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9923 - accuracy: 0.8356\n",
            "Epoch 8495/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 4.0125 - accuracy: 0.8756\n",
            "Epoch 8496/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9879 - accuracy: 0.8489\n",
            "Epoch 8497/10000\n",
            "225/225 [==============================] - 0s 538us/step - loss: 3.9697 - accuracy: 0.8711\n",
            "Epoch 8498/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9238 - accuracy: 0.8400\n",
            "Epoch 8499/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9961 - accuracy: 0.8489\n",
            "Epoch 8500/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 3.9345 - accuracy: 0.8489\n",
            "Epoch 8501/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9891 - accuracy: 0.8622\n",
            "Epoch 8502/10000\n",
            "225/225 [==============================] - 0s 501us/step - loss: 3.9887 - accuracy: 0.8400\n",
            "Epoch 8503/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0164 - accuracy: 0.8578\n",
            "Epoch 8504/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9640 - accuracy: 0.8400\n",
            "Epoch 8505/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9674 - accuracy: 0.8578\n",
            "Epoch 8506/10000\n",
            "225/225 [==============================] - 0s 556us/step - loss: 3.9555 - accuracy: 0.8756\n",
            "Epoch 8507/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0885 - accuracy: 0.9022\n",
            "Epoch 8508/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.8745 - accuracy: 0.8400\n",
            "Epoch 8509/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 4.0402 - accuracy: 0.8489\n",
            "Epoch 8510/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0031 - accuracy: 0.8844\n",
            "Epoch 8511/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9582 - accuracy: 0.8667\n",
            "Epoch 8512/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0065 - accuracy: 0.8533\n",
            "Epoch 8513/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.9093 - accuracy: 0.8578\n",
            "Epoch 8514/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 4.0842 - accuracy: 0.8533\n",
            "Epoch 8515/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 4.0722 - accuracy: 0.8444\n",
            "Epoch 8516/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.6035 - accuracy: 0.8578\n",
            "Epoch 8517/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0548 - accuracy: 0.8578\n",
            "Epoch 8518/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.8654 - accuracy: 0.8578\n",
            "Epoch 8519/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.9176 - accuracy: 0.8400\n",
            "Epoch 8520/10000\n",
            "225/225 [==============================] - 0s 502us/step - loss: 3.9694 - accuracy: 0.8267\n",
            "Epoch 8521/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 4.0347 - accuracy: 0.8400\n",
            "Epoch 8522/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 4.1535 - accuracy: 0.8533\n",
            "Epoch 8523/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 4.0236 - accuracy: 0.8622\n",
            "Epoch 8524/10000\n",
            "225/225 [==============================] - 0s 553us/step - loss: 3.9743 - accuracy: 0.8622\n",
            "Epoch 8525/10000\n",
            "225/225 [==============================] - 0s 515us/step - loss: 4.0845 - accuracy: 0.8578\n",
            "Epoch 8526/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9260 - accuracy: 0.8622\n",
            "Epoch 8527/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 4.0159 - accuracy: 0.8622\n",
            "Epoch 8528/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9447 - accuracy: 0.8889\n",
            "Epoch 8529/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.0648 - accuracy: 0.8622\n",
            "Epoch 8530/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 4.0105 - accuracy: 0.8578\n",
            "Epoch 8531/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.5933 - accuracy: 0.8711\n",
            "Epoch 8532/10000\n",
            "225/225 [==============================] - 0s 500us/step - loss: 3.9736 - accuracy: 0.8844\n",
            "Epoch 8533/10000\n",
            "225/225 [==============================] - 0s 522us/step - loss: 4.0986 - accuracy: 0.8444\n",
            "Epoch 8534/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9352 - accuracy: 0.8800\n",
            "Epoch 8535/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9486 - accuracy: 0.8533\n",
            "Epoch 8536/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9847 - accuracy: 0.8756\n",
            "Epoch 8537/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 3.8858 - accuracy: 0.8711\n",
            "Epoch 8538/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0121 - accuracy: 0.8489\n",
            "Epoch 8539/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0293 - accuracy: 0.8489\n",
            "Epoch 8540/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.1453 - accuracy: 0.8356\n",
            "Epoch 8541/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9625 - accuracy: 0.8400\n",
            "Epoch 8542/10000\n",
            "225/225 [==============================] - 0s 562us/step - loss: 3.9056 - accuracy: 0.8578\n",
            "Epoch 8543/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 4.0258 - accuracy: 0.8489\n",
            "Epoch 8544/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0642 - accuracy: 0.8533\n",
            "Epoch 8545/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.0368 - accuracy: 0.8489\n",
            "Epoch 8546/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.7316 - accuracy: 0.8400\n",
            "Epoch 8547/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 3.9233 - accuracy: 0.8489\n",
            "Epoch 8548/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9836 - accuracy: 0.8667\n",
            "Epoch 8549/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9390 - accuracy: 0.8711\n",
            "Epoch 8550/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.9406 - accuracy: 0.8622\n",
            "Epoch 8551/10000\n",
            "225/225 [==============================] - 0s 527us/step - loss: 4.0105 - accuracy: 0.8711\n",
            "Epoch 8552/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9543 - accuracy: 0.8578\n",
            "Epoch 8553/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.8510 - accuracy: 0.8800\n",
            "Epoch 8554/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9413 - accuracy: 0.8356\n",
            "Epoch 8555/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9727 - accuracy: 0.8444\n",
            "Epoch 8556/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.8890 - accuracy: 0.8444\n",
            "Epoch 8557/10000\n",
            "225/225 [==============================] - 0s 447us/step - loss: 3.9679 - accuracy: 0.8622\n",
            "Epoch 8558/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9144 - accuracy: 0.8444\n",
            "Epoch 8559/10000\n",
            "225/225 [==============================] - 0s 516us/step - loss: 3.9368 - accuracy: 0.8178\n",
            "Epoch 8560/10000\n",
            "225/225 [==============================] - 0s 563us/step - loss: 3.9221 - accuracy: 0.8489\n",
            "Epoch 8561/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.1014 - accuracy: 0.8578\n",
            "Epoch 8562/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0712 - accuracy: 0.8756\n",
            "Epoch 8563/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 3.9497 - accuracy: 0.8622\n",
            "Epoch 8564/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9037 - accuracy: 0.8311\n",
            "Epoch 8565/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 4.1930 - accuracy: 0.8533\n",
            "Epoch 8566/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.0120 - accuracy: 0.8756\n",
            "Epoch 8567/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 4.0844 - accuracy: 0.8622\n",
            "Epoch 8568/10000\n",
            "225/225 [==============================] - 0s 514us/step - loss: 3.9710 - accuracy: 0.8844\n",
            "Epoch 8569/10000\n",
            "225/225 [==============================] - 0s 548us/step - loss: 3.9861 - accuracy: 0.8711\n",
            "Epoch 8570/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.1006 - accuracy: 0.8622\n",
            "Epoch 8571/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.6033 - accuracy: 0.8444\n",
            "Epoch 8572/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 3.9718 - accuracy: 0.8578\n",
            "Epoch 8573/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9000 - accuracy: 0.8356\n",
            "Epoch 8574/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 3.9794 - accuracy: 0.8578\n",
            "Epoch 8575/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.5965 - accuracy: 0.8311\n",
            "Epoch 8576/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 4.0542 - accuracy: 0.8489\n",
            "Epoch 8577/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9121 - accuracy: 0.8711\n",
            "Epoch 8578/10000\n",
            "225/225 [==============================] - 0s 562us/step - loss: 4.0955 - accuracy: 0.8578\n",
            "Epoch 8579/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 4.0822 - accuracy: 0.8667\n",
            "Epoch 8580/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9472 - accuracy: 0.8533\n",
            "Epoch 8581/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9613 - accuracy: 0.8578\n",
            "Epoch 8582/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9691 - accuracy: 0.8622\n",
            "Epoch 8583/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9855 - accuracy: 0.8533\n",
            "Epoch 8584/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9769 - accuracy: 0.8578\n",
            "Epoch 8585/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9502 - accuracy: 0.8800\n",
            "Epoch 8586/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.9963 - accuracy: 0.8311\n",
            "Epoch 8587/10000\n",
            "225/225 [==============================] - 0s 543us/step - loss: 4.0049 - accuracy: 0.8800\n",
            "Epoch 8588/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0013 - accuracy: 0.8489\n",
            "Epoch 8589/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.9257 - accuracy: 0.8400\n",
            "Epoch 8590/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9281 - accuracy: 0.8444\n",
            "Epoch 8591/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.6310 - accuracy: 0.8578\n",
            "Epoch 8592/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9982 - accuracy: 0.8889\n",
            "Epoch 8593/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.8487 - accuracy: 0.8578\n",
            "Epoch 8594/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.9794 - accuracy: 0.8400\n",
            "Epoch 8595/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.8287 - accuracy: 0.8800\n",
            "Epoch 8596/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 3.9905 - accuracy: 0.8533\n",
            "Epoch 8597/10000\n",
            "225/225 [==============================] - 0s 594us/step - loss: 3.9412 - accuracy: 0.8756\n",
            "Epoch 8598/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9997 - accuracy: 0.8622\n",
            "Epoch 8599/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 3.8695 - accuracy: 0.8622\n",
            "Epoch 8600/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9553 - accuracy: 0.8578\n",
            "Epoch 8601/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.1340 - accuracy: 0.8578\n",
            "Epoch 8602/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.1379 - accuracy: 0.8711\n",
            "Epoch 8603/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9288 - accuracy: 0.8489\n",
            "Epoch 8604/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0575 - accuracy: 0.8489\n",
            "Epoch 8605/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.9326 - accuracy: 0.8533\n",
            "Epoch 8606/10000\n",
            "225/225 [==============================] - 0s 516us/step - loss: 3.8014 - accuracy: 0.8756\n",
            "Epoch 8607/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9708 - accuracy: 0.8756\n",
            "Epoch 8608/10000\n",
            "225/225 [==============================] - 0s 497us/step - loss: 3.9812 - accuracy: 0.8711\n",
            "Epoch 8609/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 3.6587 - accuracy: 0.8533\n",
            "Epoch 8610/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 4.0772 - accuracy: 0.8489\n",
            "Epoch 8611/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9844 - accuracy: 0.8533\n",
            "Epoch 8612/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.5480 - accuracy: 0.8533\n",
            "Epoch 8613/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.8702 - accuracy: 0.8311\n",
            "Epoch 8614/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 4.0574 - accuracy: 0.8489\n",
            "Epoch 8615/10000\n",
            "225/225 [==============================] - 0s 538us/step - loss: 4.0693 - accuracy: 0.8533\n",
            "Epoch 8616/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 4.0041 - accuracy: 0.8844\n",
            "Epoch 8617/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.0194 - accuracy: 0.8267\n",
            "Epoch 8618/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9822 - accuracy: 0.8667\n",
            "Epoch 8619/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9367 - accuracy: 0.8444\n",
            "Epoch 8620/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9592 - accuracy: 0.8489\n",
            "Epoch 8621/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 4.0852 - accuracy: 0.8711\n",
            "Epoch 8622/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 4.0509 - accuracy: 0.8667\n",
            "Epoch 8623/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9697 - accuracy: 0.8711\n",
            "Epoch 8624/10000\n",
            "225/225 [==============================] - 0s 554us/step - loss: 3.9923 - accuracy: 0.8533\n",
            "Epoch 8625/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.8181 - accuracy: 0.8578\n",
            "Epoch 8626/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.7647 - accuracy: 0.8444\n",
            "Epoch 8627/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 3.9517 - accuracy: 0.8622\n",
            "Epoch 8628/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9820 - accuracy: 0.8667\n",
            "Epoch 8629/10000\n",
            "225/225 [==============================] - 0s 541us/step - loss: 3.9578 - accuracy: 0.8578\n",
            "Epoch 8630/10000\n",
            "225/225 [==============================] - 0s 516us/step - loss: 3.6592 - accuracy: 0.8667\n",
            "Epoch 8631/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9326 - accuracy: 0.8756\n",
            "Epoch 8632/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.0583 - accuracy: 0.8356\n",
            "Epoch 8633/10000\n",
            "225/225 [==============================] - 0s 546us/step - loss: 4.0491 - accuracy: 0.8756\n",
            "Epoch 8634/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9463 - accuracy: 0.8444\n",
            "Epoch 8635/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.8450 - accuracy: 0.8400\n",
            "Epoch 8636/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 4.0155 - accuracy: 0.8889\n",
            "Epoch 8637/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9166 - accuracy: 0.8711\n",
            "Epoch 8638/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 4.1693 - accuracy: 0.8622\n",
            "Epoch 8639/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 3.9824 - accuracy: 0.8622\n",
            "Epoch 8640/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9658 - accuracy: 0.8400\n",
            "Epoch 8641/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.6459 - accuracy: 0.8622\n",
            "Epoch 8642/10000\n",
            "225/225 [==============================] - 0s 545us/step - loss: 3.9165 - accuracy: 0.8800\n",
            "Epoch 8643/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.8124 - accuracy: 0.8533\n",
            "Epoch 8644/10000\n",
            "225/225 [==============================] - 0s 504us/step - loss: 3.7744 - accuracy: 0.8667\n",
            "Epoch 8645/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9214 - accuracy: 0.8489\n",
            "Epoch 8646/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 3.9996 - accuracy: 0.8622\n",
            "Epoch 8647/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9015 - accuracy: 0.8756\n",
            "Epoch 8648/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9986 - accuracy: 0.8578\n",
            "Epoch 8649/10000\n",
            "225/225 [==============================] - 0s 540us/step - loss: 3.9116 - accuracy: 0.8622\n",
            "Epoch 8650/10000\n",
            "225/225 [==============================] - 0s 494us/step - loss: 3.9394 - accuracy: 0.8444\n",
            "Epoch 8651/10000\n",
            "225/225 [==============================] - 0s 541us/step - loss: 3.7998 - accuracy: 0.8400\n",
            "Epoch 8652/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.8907 - accuracy: 0.8711\n",
            "Epoch 8653/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.0939 - accuracy: 0.8622\n",
            "Epoch 8654/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.7175 - accuracy: 0.8711\n",
            "Epoch 8655/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.1328 - accuracy: 0.8489\n",
            "Epoch 8656/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9695 - accuracy: 0.8489\n",
            "Epoch 8657/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9527 - accuracy: 0.8578\n",
            "Epoch 8658/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 4.0203 - accuracy: 0.8444\n",
            "Epoch 8659/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 4.0102 - accuracy: 0.8578\n",
            "Epoch 8660/10000\n",
            "225/225 [==============================] - 0s 517us/step - loss: 3.6976 - accuracy: 0.8578\n",
            "Epoch 8661/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.8713 - accuracy: 0.8267\n",
            "Epoch 8662/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0507 - accuracy: 0.8489\n",
            "Epoch 8663/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.8787 - accuracy: 0.8622\n",
            "Epoch 8664/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.8996 - accuracy: 0.8756\n",
            "Epoch 8665/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.8908 - accuracy: 0.8622\n",
            "Epoch 8666/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.8775 - accuracy: 0.8444\n",
            "Epoch 8667/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0160 - accuracy: 0.8622\n",
            "Epoch 8668/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 3.8803 - accuracy: 0.8533\n",
            "Epoch 8669/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9507 - accuracy: 0.8711\n",
            "Epoch 8670/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 4.0231 - accuracy: 0.8533\n",
            "Epoch 8671/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.8928 - accuracy: 0.8889\n",
            "Epoch 8672/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0134 - accuracy: 0.8622\n",
            "Epoch 8673/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9479 - accuracy: 0.8444\n",
            "Epoch 8674/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.9289 - accuracy: 0.8622\n",
            "Epoch 8675/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.8774 - accuracy: 0.8400\n",
            "Epoch 8676/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9644 - accuracy: 0.8711\n",
            "Epoch 8677/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.8385 - accuracy: 0.8667\n",
            "Epoch 8678/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9293 - accuracy: 0.8356\n",
            "Epoch 8679/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 4.0756 - accuracy: 0.8400\n",
            "Epoch 8680/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9940 - accuracy: 0.8800\n",
            "Epoch 8681/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.7796 - accuracy: 0.8533\n",
            "Epoch 8682/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9069 - accuracy: 0.8711\n",
            "Epoch 8683/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 4.0457 - accuracy: 0.8578\n",
            "Epoch 8684/10000\n",
            "225/225 [==============================] - 0s 512us/step - loss: 3.9842 - accuracy: 0.8444\n",
            "Epoch 8685/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9349 - accuracy: 0.8622\n",
            "Epoch 8686/10000\n",
            "225/225 [==============================] - 0s 506us/step - loss: 3.9778 - accuracy: 0.8667\n",
            "Epoch 8687/10000\n",
            "225/225 [==============================] - 0s 531us/step - loss: 3.9392 - accuracy: 0.8622\n",
            "Epoch 8688/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 3.9977 - accuracy: 0.8489\n",
            "Epoch 8689/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0152 - accuracy: 0.8711\n",
            "Epoch 8690/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.7817 - accuracy: 0.8578\n",
            "Epoch 8691/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0301 - accuracy: 0.8533\n",
            "Epoch 8692/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9370 - accuracy: 0.8533\n",
            "Epoch 8693/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 3.9284 - accuracy: 0.8622\n",
            "Epoch 8694/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 4.0555 - accuracy: 0.8444\n",
            "Epoch 8695/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 3.8943 - accuracy: 0.8400\n",
            "Epoch 8696/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0659 - accuracy: 0.8311\n",
            "Epoch 8697/10000\n",
            "225/225 [==============================] - 0s 522us/step - loss: 3.9312 - accuracy: 0.8578\n",
            "Epoch 8698/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9021 - accuracy: 0.8400\n",
            "Epoch 8699/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.7019 - accuracy: 0.8800\n",
            "Epoch 8700/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 3.9057 - accuracy: 0.8800\n",
            "Epoch 8701/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 4.0199 - accuracy: 0.8578\n",
            "Epoch 8702/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.0272 - accuracy: 0.8400\n",
            "Epoch 8703/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9238 - accuracy: 0.8400\n",
            "Epoch 8704/10000\n",
            "225/225 [==============================] - 0s 502us/step - loss: 3.9517 - accuracy: 0.8711\n",
            "Epoch 8705/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.9130 - accuracy: 0.8667\n",
            "Epoch 8706/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 4.0315 - accuracy: 0.8756\n",
            "Epoch 8707/10000\n",
            "225/225 [==============================] - 0s 512us/step - loss: 3.9217 - accuracy: 0.8711\n",
            "Epoch 8708/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 4.0063 - accuracy: 0.8489\n",
            "Epoch 8709/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9764 - accuracy: 0.8844\n",
            "Epoch 8710/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9366 - accuracy: 0.8667\n",
            "Epoch 8711/10000\n",
            "225/225 [==============================] - 0s 494us/step - loss: 4.0379 - accuracy: 0.8622\n",
            "Epoch 8712/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9718 - accuracy: 0.8444\n",
            "Epoch 8713/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9849 - accuracy: 0.8489\n",
            "Epoch 8714/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.0591 - accuracy: 0.8800\n",
            "Epoch 8715/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.7271 - accuracy: 0.8356\n",
            "Epoch 8716/10000\n",
            "225/225 [==============================] - 0s 529us/step - loss: 3.8643 - accuracy: 0.8622\n",
            "Epoch 8717/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.7533 - accuracy: 0.8756\n",
            "Epoch 8718/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.8034 - accuracy: 0.8489\n",
            "Epoch 8719/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9526 - accuracy: 0.8178\n",
            "Epoch 8720/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.0532 - accuracy: 0.8756\n",
            "Epoch 8721/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9842 - accuracy: 0.8533\n",
            "Epoch 8722/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8967 - accuracy: 0.8533\n",
            "Epoch 8723/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9597 - accuracy: 0.8400\n",
            "Epoch 8724/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 4.0959 - accuracy: 0.8578\n",
            "Epoch 8725/10000\n",
            "225/225 [==============================] - 0s 509us/step - loss: 4.1942 - accuracy: 0.8533\n",
            "Epoch 8726/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9584 - accuracy: 0.8622\n",
            "Epoch 8727/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 4.0608 - accuracy: 0.8444\n",
            "Epoch 8728/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9970 - accuracy: 0.8489\n",
            "Epoch 8729/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9844 - accuracy: 0.8622\n",
            "Epoch 8730/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9861 - accuracy: 0.8667\n",
            "Epoch 8731/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0082 - accuracy: 0.8667\n",
            "Epoch 8732/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9489 - accuracy: 0.8222\n",
            "Epoch 8733/10000\n",
            "225/225 [==============================] - 0s 526us/step - loss: 4.0162 - accuracy: 0.8667\n",
            "Epoch 8734/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 3.9822 - accuracy: 0.8489\n",
            "Epoch 8735/10000\n",
            "225/225 [==============================] - 0s 520us/step - loss: 3.9961 - accuracy: 0.8933\n",
            "Epoch 8736/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.7531 - accuracy: 0.8667\n",
            "Epoch 8737/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9780 - accuracy: 0.8311\n",
            "Epoch 8738/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0717 - accuracy: 0.8489\n",
            "Epoch 8739/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.8288 - accuracy: 0.8489\n",
            "Epoch 8740/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8895 - accuracy: 0.8622\n",
            "Epoch 8741/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9862 - accuracy: 0.8667\n",
            "Epoch 8742/10000\n",
            "225/225 [==============================] - 0s 507us/step - loss: 3.9242 - accuracy: 0.8400\n",
            "Epoch 8743/10000\n",
            "225/225 [==============================] - 0s 509us/step - loss: 3.9692 - accuracy: 0.8933\n",
            "Epoch 8744/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.7313 - accuracy: 0.8622\n",
            "Epoch 8745/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.9424 - accuracy: 0.8667\n",
            "Epoch 8746/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.8325 - accuracy: 0.8889\n",
            "Epoch 8747/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9842 - accuracy: 0.8533\n",
            "Epoch 8748/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9658 - accuracy: 0.8356\n",
            "Epoch 8749/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.1394 - accuracy: 0.8667\n",
            "Epoch 8750/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.9302 - accuracy: 0.8622\n",
            "Epoch 8751/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 4.1122 - accuracy: 0.8533\n",
            "Epoch 8752/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0044 - accuracy: 0.8489\n",
            "Epoch 8753/10000\n",
            "225/225 [==============================] - 0s 522us/step - loss: 3.9997 - accuracy: 0.8711\n",
            "Epoch 8754/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0132 - accuracy: 0.8400\n",
            "Epoch 8755/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9259 - accuracy: 0.8533\n",
            "Epoch 8756/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0794 - accuracy: 0.8711\n",
            "Epoch 8757/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0454 - accuracy: 0.8400\n",
            "Epoch 8758/10000\n",
            "225/225 [==============================] - 0s 524us/step - loss: 3.8324 - accuracy: 0.8667\n",
            "Epoch 8759/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9345 - accuracy: 0.8267\n",
            "Epoch 8760/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 4.0784 - accuracy: 0.8622\n",
            "Epoch 8761/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 3.7606 - accuracy: 0.8400\n",
            "Epoch 8762/10000\n",
            "225/225 [==============================] - 0s 522us/step - loss: 3.9902 - accuracy: 0.8533\n",
            "Epoch 8763/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 4.0146 - accuracy: 0.8356\n",
            "Epoch 8764/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0561 - accuracy: 0.8800\n",
            "Epoch 8765/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 4.0141 - accuracy: 0.8667\n",
            "Epoch 8766/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9158 - accuracy: 0.8844\n",
            "Epoch 8767/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.8451 - accuracy: 0.8578\n",
            "Epoch 8768/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.8825 - accuracy: 0.8444\n",
            "Epoch 8769/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.9315 - accuracy: 0.8578\n",
            "Epoch 8770/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9395 - accuracy: 0.8489\n",
            "Epoch 8771/10000\n",
            "225/225 [==============================] - 0s 509us/step - loss: 4.0180 - accuracy: 0.8489\n",
            "Epoch 8772/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.9794 - accuracy: 0.8533\n",
            "Epoch 8773/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0835 - accuracy: 0.8578\n",
            "Epoch 8774/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9095 - accuracy: 0.8489\n",
            "Epoch 8775/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8004 - accuracy: 0.8444\n",
            "Epoch 8776/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.8815 - accuracy: 0.8756\n",
            "Epoch 8777/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 4.0309 - accuracy: 0.8444\n",
            "Epoch 8778/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9980 - accuracy: 0.8667\n",
            "Epoch 8779/10000\n",
            "225/225 [==============================] - 0s 498us/step - loss: 3.9224 - accuracy: 0.8667\n",
            "Epoch 8780/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.9847 - accuracy: 0.8756\n",
            "Epoch 8781/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0095 - accuracy: 0.8444\n",
            "Epoch 8782/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 3.9016 - accuracy: 0.8622\n",
            "Epoch 8783/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9429 - accuracy: 0.8444\n",
            "Epoch 8784/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.8609 - accuracy: 0.8578\n",
            "Epoch 8785/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.0197 - accuracy: 0.8489\n",
            "Epoch 8786/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9292 - accuracy: 0.8578\n",
            "Epoch 8787/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.1305 - accuracy: 0.8489\n",
            "Epoch 8788/10000\n",
            "225/225 [==============================] - 0s 499us/step - loss: 3.9348 - accuracy: 0.8400\n",
            "Epoch 8789/10000\n",
            "225/225 [==============================] - 0s 521us/step - loss: 3.9246 - accuracy: 0.8444\n",
            "Epoch 8790/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9108 - accuracy: 0.8578\n",
            "Epoch 8791/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.9677 - accuracy: 0.8711\n",
            "Epoch 8792/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.8223 - accuracy: 0.8267\n",
            "Epoch 8793/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.8352 - accuracy: 0.8933\n",
            "Epoch 8794/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9613 - accuracy: 0.8667\n",
            "Epoch 8795/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0130 - accuracy: 0.8711\n",
            "Epoch 8796/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.8977 - accuracy: 0.8400\n",
            "Epoch 8797/10000\n",
            "225/225 [==============================] - 0s 529us/step - loss: 3.8846 - accuracy: 0.8533\n",
            "Epoch 8798/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9547 - accuracy: 0.8667\n",
            "Epoch 8799/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9465 - accuracy: 0.8444\n",
            "Epoch 8800/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.9521 - accuracy: 0.8444\n",
            "Epoch 8801/10000\n",
            "225/225 [==============================] - 0s 535us/step - loss: 3.9060 - accuracy: 0.8844\n",
            "Epoch 8802/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.7279 - accuracy: 0.8578\n",
            "Epoch 8803/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.1062 - accuracy: 0.8578\n",
            "Epoch 8804/10000\n",
            "225/225 [==============================] - 0s 525us/step - loss: 3.9513 - accuracy: 0.8444\n",
            "Epoch 8805/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 4.0305 - accuracy: 0.8578\n",
            "Epoch 8806/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 3.9623 - accuracy: 0.8667\n",
            "Epoch 8807/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9539 - accuracy: 0.8622\n",
            "Epoch 8808/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9451 - accuracy: 0.8578\n",
            "Epoch 8809/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9842 - accuracy: 0.8444\n",
            "Epoch 8810/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 4.0408 - accuracy: 0.8444\n",
            "Epoch 8811/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 4.0380 - accuracy: 0.8844\n",
            "Epoch 8812/10000\n",
            "225/225 [==============================] - 0s 522us/step - loss: 3.9465 - accuracy: 0.8533\n",
            "Epoch 8813/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 4.0726 - accuracy: 0.8756\n",
            "Epoch 8814/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9897 - accuracy: 0.8844\n",
            "Epoch 8815/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9396 - accuracy: 0.8444\n",
            "Epoch 8816/10000\n",
            "225/225 [==============================] - 0s 499us/step - loss: 3.9788 - accuracy: 0.8578\n",
            "Epoch 8817/10000\n",
            "225/225 [==============================] - 0s 529us/step - loss: 3.9357 - accuracy: 0.8444\n",
            "Epoch 8818/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0845 - accuracy: 0.8578\n",
            "Epoch 8819/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 4.0637 - accuracy: 0.8711\n",
            "Epoch 8820/10000\n",
            "225/225 [==============================] - 0s 498us/step - loss: 3.8875 - accuracy: 0.8622\n",
            "Epoch 8821/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9671 - accuracy: 0.8533\n",
            "Epoch 8822/10000\n",
            "225/225 [==============================] - 0s 535us/step - loss: 4.1728 - accuracy: 0.8489\n",
            "Epoch 8823/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 4.0981 - accuracy: 0.8667\n",
            "Epoch 8824/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.0022 - accuracy: 0.8667\n",
            "Epoch 8825/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 4.0896 - accuracy: 0.8311\n",
            "Epoch 8826/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 4.0868 - accuracy: 0.8489\n",
            "Epoch 8827/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9262 - accuracy: 0.8800\n",
            "Epoch 8828/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0124 - accuracy: 0.8311\n",
            "Epoch 8829/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 3.9201 - accuracy: 0.8311\n",
            "Epoch 8830/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 3.9701 - accuracy: 0.8489\n",
            "Epoch 8831/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 4.0042 - accuracy: 0.8756\n",
            "Epoch 8832/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9951 - accuracy: 0.8889\n",
            "Epoch 8833/10000\n",
            "225/225 [==============================] - 0s 515us/step - loss: 3.9739 - accuracy: 0.8533\n",
            "Epoch 8834/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9462 - accuracy: 0.8311\n",
            "Epoch 8835/10000\n",
            "225/225 [==============================] - 0s 539us/step - loss: 3.6982 - accuracy: 0.8756\n",
            "Epoch 8836/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0073 - accuracy: 0.8489\n",
            "Epoch 8837/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9455 - accuracy: 0.8489\n",
            "Epoch 8838/10000\n",
            "225/225 [==============================] - 0s 500us/step - loss: 4.0794 - accuracy: 0.8400\n",
            "Epoch 8839/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0770 - accuracy: 0.8622\n",
            "Epoch 8840/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9121 - accuracy: 0.8533\n",
            "Epoch 8841/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.0221 - accuracy: 0.8444\n",
            "Epoch 8842/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9480 - accuracy: 0.8756\n",
            "Epoch 8843/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.7835 - accuracy: 0.8622\n",
            "Epoch 8844/10000\n",
            "225/225 [==============================] - 0s 514us/step - loss: 3.9477 - accuracy: 0.8622\n",
            "Epoch 8845/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9632 - accuracy: 0.8311\n",
            "Epoch 8846/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 3.8957 - accuracy: 0.8444\n",
            "Epoch 8847/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.5950 - accuracy: 0.8400\n",
            "Epoch 8848/10000\n",
            "225/225 [==============================] - 0s 605us/step - loss: 3.8713 - accuracy: 0.8311\n",
            "Epoch 8849/10000\n",
            "225/225 [==============================] - 0s 566us/step - loss: 3.7849 - accuracy: 0.8667\n",
            "Epoch 8850/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.6983 - accuracy: 0.8444\n",
            "Epoch 8851/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.9961 - accuracy: 0.8756\n",
            "Epoch 8852/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9728 - accuracy: 0.8578\n",
            "Epoch 8853/10000\n",
            "225/225 [==============================] - 0s 517us/step - loss: 3.6693 - accuracy: 0.8489\n",
            "Epoch 8854/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.8680 - accuracy: 0.8356\n",
            "Epoch 8855/10000\n",
            "225/225 [==============================] - 0s 537us/step - loss: 3.9445 - accuracy: 0.8489\n",
            "Epoch 8856/10000\n",
            "225/225 [==============================] - 0s 536us/step - loss: 4.1034 - accuracy: 0.8267\n",
            "Epoch 8857/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9440 - accuracy: 0.8533\n",
            "Epoch 8858/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 4.0932 - accuracy: 0.8578\n",
            "Epoch 8859/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 4.0141 - accuracy: 0.8533\n",
            "Epoch 8860/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 4.0972 - accuracy: 0.8622\n",
            "Epoch 8861/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.6093 - accuracy: 0.8356\n",
            "Epoch 8862/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 4.1534 - accuracy: 0.8578\n",
            "Epoch 8863/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9618 - accuracy: 0.8578\n",
            "Epoch 8864/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9739 - accuracy: 0.8667\n",
            "Epoch 8865/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.6711 - accuracy: 0.8578\n",
            "Epoch 8866/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9314 - accuracy: 0.8667\n",
            "Epoch 8867/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9519 - accuracy: 0.8400\n",
            "Epoch 8868/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9763 - accuracy: 0.8489\n",
            "Epoch 8869/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 4.0022 - accuracy: 0.8622\n",
            "Epoch 8870/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.7988 - accuracy: 0.8578\n",
            "Epoch 8871/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9704 - accuracy: 0.8578\n",
            "Epoch 8872/10000\n",
            "225/225 [==============================] - 0s 545us/step - loss: 3.9657 - accuracy: 0.8667\n",
            "Epoch 8873/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 4.0974 - accuracy: 0.8578\n",
            "Epoch 8874/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9632 - accuracy: 0.8400\n",
            "Epoch 8875/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9173 - accuracy: 0.8356\n",
            "Epoch 8876/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9274 - accuracy: 0.8756\n",
            "Epoch 8877/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.8996 - accuracy: 0.8489\n",
            "Epoch 8878/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9416 - accuracy: 0.8844\n",
            "Epoch 8879/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0549 - accuracy: 0.8356\n",
            "Epoch 8880/10000\n",
            "225/225 [==============================] - 0s 497us/step - loss: 4.0833 - accuracy: 0.8667\n",
            "Epoch 8881/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.7552 - accuracy: 0.8756\n",
            "Epoch 8882/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 4.1329 - accuracy: 0.8578\n",
            "Epoch 8883/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9225 - accuracy: 0.8667\n",
            "Epoch 8884/10000\n",
            "225/225 [==============================] - 0s 451us/step - loss: 4.0215 - accuracy: 0.8400\n",
            "Epoch 8885/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9862 - accuracy: 0.8800\n",
            "Epoch 8886/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.7181 - accuracy: 0.8622\n",
            "Epoch 8887/10000\n",
            "225/225 [==============================] - 0s 502us/step - loss: 3.9797 - accuracy: 0.8311\n",
            "Epoch 8888/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0727 - accuracy: 0.8578\n",
            "Epoch 8889/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.0327 - accuracy: 0.8933\n",
            "Epoch 8890/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 4.0200 - accuracy: 0.8711\n",
            "Epoch 8891/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 4.0312 - accuracy: 0.8489\n",
            "Epoch 8892/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9026 - accuracy: 0.8578\n",
            "Epoch 8893/10000\n",
            "225/225 [==============================] - 0s 494us/step - loss: 3.8897 - accuracy: 0.8222\n",
            "Epoch 8894/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9132 - accuracy: 0.8711\n",
            "Epoch 8895/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9283 - accuracy: 0.8533\n",
            "Epoch 8896/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9708 - accuracy: 0.8444\n",
            "Epoch 8897/10000\n",
            "225/225 [==============================] - 0s 497us/step - loss: 4.0305 - accuracy: 0.8800\n",
            "Epoch 8898/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.1133 - accuracy: 0.8356\n",
            "Epoch 8899/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.8981 - accuracy: 0.8800\n",
            "Epoch 8900/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.5958 - accuracy: 0.8622\n",
            "Epoch 8901/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 3.9102 - accuracy: 0.8533\n",
            "Epoch 8902/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.8348 - accuracy: 0.8444\n",
            "Epoch 8903/10000\n",
            "225/225 [==============================] - 0s 521us/step - loss: 3.9146 - accuracy: 0.8267\n",
            "Epoch 8904/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9822 - accuracy: 0.8400\n",
            "Epoch 8905/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9628 - accuracy: 0.8533\n",
            "Epoch 8906/10000\n",
            "225/225 [==============================] - 0s 538us/step - loss: 3.8835 - accuracy: 0.8622\n",
            "Epoch 8907/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0218 - accuracy: 0.8400\n",
            "Epoch 8908/10000\n",
            "225/225 [==============================] - 0s 507us/step - loss: 3.9709 - accuracy: 0.8533\n",
            "Epoch 8909/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9308 - accuracy: 0.8800\n",
            "Epoch 8910/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9298 - accuracy: 0.8489\n",
            "Epoch 8911/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.8924 - accuracy: 0.8756\n",
            "Epoch 8912/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9564 - accuracy: 0.8622\n",
            "Epoch 8913/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.8148 - accuracy: 0.8578\n",
            "Epoch 8914/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9056 - accuracy: 0.8800\n",
            "Epoch 8915/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 4.0156 - accuracy: 0.8489\n",
            "Epoch 8916/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9937 - accuracy: 0.8578\n",
            "Epoch 8917/10000\n",
            "225/225 [==============================] - 0s 581us/step - loss: 4.0309 - accuracy: 0.8889\n",
            "Epoch 8918/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.8904 - accuracy: 0.8400\n",
            "Epoch 8919/10000\n",
            "225/225 [==============================] - 0s 526us/step - loss: 3.9604 - accuracy: 0.8311\n",
            "Epoch 8920/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 3.9094 - accuracy: 0.8933\n",
            "Epoch 8921/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9956 - accuracy: 0.8578\n",
            "Epoch 8922/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 4.0918 - accuracy: 0.8578\n",
            "Epoch 8923/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9700 - accuracy: 0.8667\n",
            "Epoch 8924/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9929 - accuracy: 0.8622\n",
            "Epoch 8925/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0347 - accuracy: 0.8533\n",
            "Epoch 8926/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9476 - accuracy: 0.8667\n",
            "Epoch 8927/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.9498 - accuracy: 0.8578\n",
            "Epoch 8928/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9915 - accuracy: 0.8444\n",
            "Epoch 8929/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9230 - accuracy: 0.8711\n",
            "Epoch 8930/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9524 - accuracy: 0.8667\n",
            "Epoch 8931/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9662 - accuracy: 0.8711\n",
            "Epoch 8932/10000\n",
            "225/225 [==============================] - 0s 449us/step - loss: 3.8885 - accuracy: 0.8356\n",
            "Epoch 8933/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9764 - accuracy: 0.8533\n",
            "Epoch 8934/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.8304 - accuracy: 0.8756\n",
            "Epoch 8935/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9166 - accuracy: 0.8356\n",
            "Epoch 8936/10000\n",
            "225/225 [==============================] - 0s 509us/step - loss: 3.9209 - accuracy: 0.8756\n",
            "Epoch 8937/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9908 - accuracy: 0.8622\n",
            "Epoch 8938/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9262 - accuracy: 0.8533\n",
            "Epoch 8939/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9219 - accuracy: 0.8622\n",
            "Epoch 8940/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.8439 - accuracy: 0.8356\n",
            "Epoch 8941/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9346 - accuracy: 0.8711\n",
            "Epoch 8942/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.7717 - accuracy: 0.8711\n",
            "Epoch 8943/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9917 - accuracy: 0.8889\n",
            "Epoch 8944/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9501 - accuracy: 0.8533\n",
            "Epoch 8945/10000\n",
            "225/225 [==============================] - 0s 540us/step - loss: 3.9221 - accuracy: 0.8800\n",
            "Epoch 8946/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 4.0168 - accuracy: 0.8622\n",
            "Epoch 8947/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9567 - accuracy: 0.8444\n",
            "Epoch 8948/10000\n",
            "225/225 [==============================] - 0s 546us/step - loss: 3.9653 - accuracy: 0.8533\n",
            "Epoch 8949/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.6690 - accuracy: 0.8222\n",
            "Epoch 8950/10000\n",
            "225/225 [==============================] - 0s 526us/step - loss: 3.8396 - accuracy: 0.8533\n",
            "Epoch 8951/10000\n",
            "225/225 [==============================] - 0s 515us/step - loss: 4.1293 - accuracy: 0.8622\n",
            "Epoch 8952/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 4.2514 - accuracy: 0.8533\n",
            "Epoch 8953/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9034 - accuracy: 0.8667\n",
            "Epoch 8954/10000\n",
            "225/225 [==============================] - 0s 506us/step - loss: 3.9632 - accuracy: 0.8667\n",
            "Epoch 8955/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9403 - accuracy: 0.8622\n",
            "Epoch 8956/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9207 - accuracy: 0.8667\n",
            "Epoch 8957/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9708 - accuracy: 0.8578\n",
            "Epoch 8958/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 4.0117 - accuracy: 0.8489\n",
            "Epoch 8959/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9991 - accuracy: 0.8533\n",
            "Epoch 8960/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 4.0388 - accuracy: 0.8489\n",
            "Epoch 8961/10000\n",
            "225/225 [==============================] - 0s 451us/step - loss: 3.9540 - accuracy: 0.8622\n",
            "Epoch 8962/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 4.0940 - accuracy: 0.8622\n",
            "Epoch 8963/10000\n",
            "225/225 [==============================] - 0s 506us/step - loss: 4.0038 - accuracy: 0.8489\n",
            "Epoch 8964/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9215 - accuracy: 0.8489\n",
            "Epoch 8965/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.0264 - accuracy: 0.8533\n",
            "Epoch 8966/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 3.7826 - accuracy: 0.8356\n",
            "Epoch 8967/10000\n",
            "225/225 [==============================] - 0s 512us/step - loss: 4.0232 - accuracy: 0.8711\n",
            "Epoch 8968/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9099 - accuracy: 0.8400\n",
            "Epoch 8969/10000\n",
            "225/225 [==============================] - 0s 534us/step - loss: 3.9545 - accuracy: 0.8667\n",
            "Epoch 8970/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0501 - accuracy: 0.8578\n",
            "Epoch 8971/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.9588 - accuracy: 0.8622\n",
            "Epoch 8972/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 4.0012 - accuracy: 0.8444\n",
            "Epoch 8973/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.8975 - accuracy: 0.8756\n",
            "Epoch 8974/10000\n",
            "225/225 [==============================] - 0s 555us/step - loss: 3.8277 - accuracy: 0.8356\n",
            "Epoch 8975/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.7726 - accuracy: 0.8489\n",
            "Epoch 8976/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.8723 - accuracy: 0.8667\n",
            "Epoch 8977/10000\n",
            "225/225 [==============================] - 0s 451us/step - loss: 3.7928 - accuracy: 0.8356\n",
            "Epoch 8978/10000\n",
            "225/225 [==============================] - 0s 517us/step - loss: 3.8746 - accuracy: 0.8489\n",
            "Epoch 8979/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 4.0498 - accuracy: 0.8844\n",
            "Epoch 8980/10000\n",
            "225/225 [==============================] - 0s 507us/step - loss: 3.9200 - accuracy: 0.8400\n",
            "Epoch 8981/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 3.8787 - accuracy: 0.8711\n",
            "Epoch 8982/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.2273 - accuracy: 0.8356\n",
            "Epoch 8983/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0231 - accuracy: 0.8444\n",
            "Epoch 8984/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.0013 - accuracy: 0.8756\n",
            "Epoch 8985/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0613 - accuracy: 0.8667\n",
            "Epoch 8986/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.8826 - accuracy: 0.8578\n",
            "Epoch 8987/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 3.9465 - accuracy: 0.8533\n",
            "Epoch 8988/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9801 - accuracy: 0.8711\n",
            "Epoch 8989/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0433 - accuracy: 0.8356\n",
            "Epoch 8990/10000\n",
            "225/225 [==============================] - 0s 510us/step - loss: 3.8675 - accuracy: 0.8578\n",
            "Epoch 8991/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.9861 - accuracy: 0.8711\n",
            "Epoch 8992/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.8817 - accuracy: 0.8356\n",
            "Epoch 8993/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 4.0065 - accuracy: 0.8800\n",
            "Epoch 8994/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 3.8548 - accuracy: 0.8444\n",
            "Epoch 8995/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.8930 - accuracy: 0.8667\n",
            "Epoch 8996/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8473 - accuracy: 0.8622\n",
            "Epoch 8997/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9920 - accuracy: 0.8311\n",
            "Epoch 8998/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.5910 - accuracy: 0.8622\n",
            "Epoch 8999/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 3.8679 - accuracy: 0.8533\n",
            "Epoch 9000/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.8603 - accuracy: 0.8622\n",
            "Epoch 9001/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9765 - accuracy: 0.8533\n",
            "Epoch 9002/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 4.0485 - accuracy: 0.8444\n",
            "Epoch 9003/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9287 - accuracy: 0.8400\n",
            "Epoch 9004/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9386 - accuracy: 0.8667\n",
            "Epoch 9005/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.6059 - accuracy: 0.8622\n",
            "Epoch 9006/10000\n",
            "225/225 [==============================] - 0s 538us/step - loss: 3.9704 - accuracy: 0.8711\n",
            "Epoch 9007/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.8705 - accuracy: 0.8889\n",
            "Epoch 9008/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9876 - accuracy: 0.8756\n",
            "Epoch 9009/10000\n",
            "225/225 [==============================] - 0s 509us/step - loss: 4.0507 - accuracy: 0.8489\n",
            "Epoch 9010/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9404 - accuracy: 0.8533\n",
            "Epoch 9011/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.0978 - accuracy: 0.8667\n",
            "Epoch 9012/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 4.0058 - accuracy: 0.8622\n",
            "Epoch 9013/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9026 - accuracy: 0.8444\n",
            "Epoch 9014/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9955 - accuracy: 0.8578\n",
            "Epoch 9015/10000\n",
            "225/225 [==============================] - 0s 534us/step - loss: 3.9453 - accuracy: 0.8622\n",
            "Epoch 9016/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9894 - accuracy: 0.8400\n",
            "Epoch 9017/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9763 - accuracy: 0.8267\n",
            "Epoch 9018/10000\n",
            "225/225 [==============================] - 0s 494us/step - loss: 3.9967 - accuracy: 0.8667\n",
            "Epoch 9019/10000\n",
            "225/225 [==============================] - 0s 502us/step - loss: 3.7959 - accuracy: 0.8222\n",
            "Epoch 9020/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9436 - accuracy: 0.8711\n",
            "Epoch 9021/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0219 - accuracy: 0.8311\n",
            "Epoch 9022/10000\n",
            "225/225 [==============================] - 0s 569us/step - loss: 3.9252 - accuracy: 0.8756\n",
            "Epoch 9023/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.9512 - accuracy: 0.8356\n",
            "Epoch 9024/10000\n",
            "225/225 [==============================] - 0s 514us/step - loss: 3.8070 - accuracy: 0.8578\n",
            "Epoch 9025/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 4.0128 - accuracy: 0.8444\n",
            "Epoch 9026/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9533 - accuracy: 0.8800\n",
            "Epoch 9027/10000\n",
            "225/225 [==============================] - 0s 564us/step - loss: 3.9315 - accuracy: 0.8578\n",
            "Epoch 9028/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 4.0127 - accuracy: 0.8578\n",
            "Epoch 9029/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9890 - accuracy: 0.8578\n",
            "Epoch 9030/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0629 - accuracy: 0.8578\n",
            "Epoch 9031/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9190 - accuracy: 0.8533\n",
            "Epoch 9032/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 4.1565 - accuracy: 0.8489\n",
            "Epoch 9033/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 3.9551 - accuracy: 0.8622\n",
            "Epoch 9034/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.0330 - accuracy: 0.8711\n",
            "Epoch 9035/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.8310 - accuracy: 0.8578\n",
            "Epoch 9036/10000\n",
            "225/225 [==============================] - 0s 515us/step - loss: 4.0765 - accuracy: 0.8578\n",
            "Epoch 9037/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 4.0374 - accuracy: 0.8578\n",
            "Epoch 9038/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8554 - accuracy: 0.8844\n",
            "Epoch 9039/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 4.0318 - accuracy: 0.8489\n",
            "Epoch 9040/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 4.0587 - accuracy: 0.8578\n",
            "Epoch 9041/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9687 - accuracy: 0.8844\n",
            "Epoch 9042/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.8992 - accuracy: 0.8444\n",
            "Epoch 9043/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.0118 - accuracy: 0.8667\n",
            "Epoch 9044/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9303 - accuracy: 0.8311\n",
            "Epoch 9045/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 3.9392 - accuracy: 0.8489\n",
            "Epoch 9046/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.7968 - accuracy: 0.8800\n",
            "Epoch 9047/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9076 - accuracy: 0.8267\n",
            "Epoch 9048/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9739 - accuracy: 0.8400\n",
            "Epoch 9049/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.0417 - accuracy: 0.8489\n",
            "Epoch 9050/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9481 - accuracy: 0.8711\n",
            "Epoch 9051/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 3.9318 - accuracy: 0.8533\n",
            "Epoch 9052/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 4.0257 - accuracy: 0.8667\n",
            "Epoch 9053/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0322 - accuracy: 0.8533\n",
            "Epoch 9054/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9448 - accuracy: 0.8578\n",
            "Epoch 9055/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.8967 - accuracy: 0.8711\n",
            "Epoch 9056/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.8395 - accuracy: 0.8533\n",
            "Epoch 9057/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0124 - accuracy: 0.8711\n",
            "Epoch 9058/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 3.9203 - accuracy: 0.8711\n",
            "Epoch 9059/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9128 - accuracy: 0.8489\n",
            "Epoch 9060/10000\n",
            "225/225 [==============================] - 0s 538us/step - loss: 3.9969 - accuracy: 0.8489\n",
            "Epoch 9061/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9183 - accuracy: 0.8667\n",
            "Epoch 9062/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9078 - accuracy: 0.8533\n",
            "Epoch 9063/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0360 - accuracy: 0.8711\n",
            "Epoch 9064/10000\n",
            "225/225 [==============================] - 0s 517us/step - loss: 3.8900 - accuracy: 0.8667\n",
            "Epoch 9065/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9041 - accuracy: 0.8444\n",
            "Epoch 9066/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9268 - accuracy: 0.8622\n",
            "Epoch 9067/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.8764 - accuracy: 0.8356\n",
            "Epoch 9068/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 4.0298 - accuracy: 0.8711\n",
            "Epoch 9069/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9005 - accuracy: 0.8622\n",
            "Epoch 9070/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9727 - accuracy: 0.8489\n",
            "Epoch 9071/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.1189 - accuracy: 0.8444\n",
            "Epoch 9072/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.0081 - accuracy: 0.8667\n",
            "Epoch 9073/10000\n",
            "225/225 [==============================] - 0s 551us/step - loss: 3.9683 - accuracy: 0.8578\n",
            "Epoch 9074/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.8914 - accuracy: 0.8444\n",
            "Epoch 9075/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.8800 - accuracy: 0.8311\n",
            "Epoch 9076/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0271 - accuracy: 0.8667\n",
            "Epoch 9077/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9295 - accuracy: 0.8622\n",
            "Epoch 9078/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 4.0305 - accuracy: 0.8622\n",
            "Epoch 9079/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.9278 - accuracy: 0.8444\n",
            "Epoch 9080/10000\n",
            "225/225 [==============================] - 0s 531us/step - loss: 3.9779 - accuracy: 0.8622\n",
            "Epoch 9081/10000\n",
            "225/225 [==============================] - 0s 550us/step - loss: 3.9774 - accuracy: 0.8533\n",
            "Epoch 9082/10000\n",
            "225/225 [==============================] - 0s 576us/step - loss: 3.8927 - accuracy: 0.8622\n",
            "Epoch 9083/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9432 - accuracy: 0.8667\n",
            "Epoch 9084/10000\n",
            "225/225 [==============================] - 0s 516us/step - loss: 3.8985 - accuracy: 0.8444\n",
            "Epoch 9085/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.9253 - accuracy: 0.8578\n",
            "Epoch 9086/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9971 - accuracy: 0.8622\n",
            "Epoch 9087/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.5545 - accuracy: 0.8711\n",
            "Epoch 9088/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9211 - accuracy: 0.8756\n",
            "Epoch 9089/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.8829 - accuracy: 0.8756\n",
            "Epoch 9090/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.9418 - accuracy: 0.8889\n",
            "Epoch 9091/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 3.7299 - accuracy: 0.8533\n",
            "Epoch 9092/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.8543 - accuracy: 0.8311\n",
            "Epoch 9093/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0391 - accuracy: 0.8444\n",
            "Epoch 9094/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 4.0150 - accuracy: 0.8267\n",
            "Epoch 9095/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.8870 - accuracy: 0.8578\n",
            "Epoch 9096/10000\n",
            "225/225 [==============================] - 0s 531us/step - loss: 3.9586 - accuracy: 0.8400\n",
            "Epoch 9097/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9895 - accuracy: 0.8711\n",
            "Epoch 9098/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9887 - accuracy: 0.8756\n",
            "Epoch 9099/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9859 - accuracy: 0.8622\n",
            "Epoch 9100/10000\n",
            "225/225 [==============================] - 0s 506us/step - loss: 4.0489 - accuracy: 0.8533\n",
            "Epoch 9101/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.0597 - accuracy: 0.8622\n",
            "Epoch 9102/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 3.7539 - accuracy: 0.8622\n",
            "Epoch 9103/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.7411 - accuracy: 0.8622\n",
            "Epoch 9104/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9301 - accuracy: 0.8622\n",
            "Epoch 9105/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 4.0238 - accuracy: 0.8578\n",
            "Epoch 9106/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9177 - accuracy: 0.8622\n",
            "Epoch 9107/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9149 - accuracy: 0.8756\n",
            "Epoch 9108/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9082 - accuracy: 0.8400\n",
            "Epoch 9109/10000\n",
            "225/225 [==============================] - 0s 504us/step - loss: 3.9358 - accuracy: 0.8800\n",
            "Epoch 9110/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9339 - accuracy: 0.8578\n",
            "Epoch 9111/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 4.0344 - accuracy: 0.8622\n",
            "Epoch 9112/10000\n",
            "225/225 [==============================] - 0s 497us/step - loss: 3.9758 - accuracy: 0.8578\n",
            "Epoch 9113/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0224 - accuracy: 0.8533\n",
            "Epoch 9114/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.8852 - accuracy: 0.8533\n",
            "Epoch 9115/10000\n",
            "225/225 [==============================] - 0s 546us/step - loss: 4.1023 - accuracy: 0.8489\n",
            "Epoch 9116/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 4.0914 - accuracy: 0.8400\n",
            "Epoch 9117/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.8516 - accuracy: 0.8533\n",
            "Epoch 9118/10000\n",
            "225/225 [==============================] - 0s 521us/step - loss: 3.9001 - accuracy: 0.8667\n",
            "Epoch 9119/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 4.0084 - accuracy: 0.8844\n",
            "Epoch 9120/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 3.9444 - accuracy: 0.8444\n",
            "Epoch 9121/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0301 - accuracy: 0.8622\n",
            "Epoch 9122/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.8203 - accuracy: 0.8533\n",
            "Epoch 9123/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9887 - accuracy: 0.8844\n",
            "Epoch 9124/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0718 - accuracy: 0.8444\n",
            "Epoch 9125/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.9593 - accuracy: 0.8756\n",
            "Epoch 9126/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9623 - accuracy: 0.8756\n",
            "Epoch 9127/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.9333 - accuracy: 0.8667\n",
            "Epoch 9128/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.1408 - accuracy: 0.8356\n",
            "Epoch 9129/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0395 - accuracy: 0.8578\n",
            "Epoch 9130/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 4.0360 - accuracy: 0.8356\n",
            "Epoch 9131/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.0432 - accuracy: 0.8444\n",
            "Epoch 9132/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 3.9618 - accuracy: 0.8667\n",
            "Epoch 9133/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9670 - accuracy: 0.8400\n",
            "Epoch 9134/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0821 - accuracy: 0.8533\n",
            "Epoch 9135/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9429 - accuracy: 0.8489\n",
            "Epoch 9136/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9163 - accuracy: 0.8489\n",
            "Epoch 9137/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 3.6140 - accuracy: 0.8489\n",
            "Epoch 9138/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9966 - accuracy: 0.8578\n",
            "Epoch 9139/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9255 - accuracy: 0.8489\n",
            "Epoch 9140/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 4.0147 - accuracy: 0.8356\n",
            "Epoch 9141/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 4.0335 - accuracy: 0.8622\n",
            "Epoch 9142/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 4.0040 - accuracy: 0.8711\n",
            "Epoch 9143/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 4.0523 - accuracy: 0.8400\n",
            "Epoch 9144/10000\n",
            "225/225 [==============================] - 0s 527us/step - loss: 3.8399 - accuracy: 0.8444\n",
            "Epoch 9145/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.9998 - accuracy: 0.8622\n",
            "Epoch 9146/10000\n",
            "225/225 [==============================] - 0s 516us/step - loss: 4.0343 - accuracy: 0.8711\n",
            "Epoch 9147/10000\n",
            "225/225 [==============================] - 0s 449us/step - loss: 4.0968 - accuracy: 0.8400\n",
            "Epoch 9148/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 3.8105 - accuracy: 0.8667\n",
            "Epoch 9149/10000\n",
            "225/225 [==============================] - 0s 536us/step - loss: 3.8813 - accuracy: 0.8667\n",
            "Epoch 9150/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0334 - accuracy: 0.8711\n",
            "Epoch 9151/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.8871 - accuracy: 0.8622\n",
            "Epoch 9152/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9429 - accuracy: 0.8533\n",
            "Epoch 9153/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.6430 - accuracy: 0.8444\n",
            "Epoch 9154/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9557 - accuracy: 0.8667\n",
            "Epoch 9155/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 3.9424 - accuracy: 0.8533\n",
            "Epoch 9156/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9374 - accuracy: 0.8578\n",
            "Epoch 9157/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.7892 - accuracy: 0.8756\n",
            "Epoch 9158/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.8812 - accuracy: 0.8711\n",
            "Epoch 9159/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0238 - accuracy: 0.8311\n",
            "Epoch 9160/10000\n",
            "225/225 [==============================] - 0s 524us/step - loss: 3.9870 - accuracy: 0.8444\n",
            "Epoch 9161/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.8637 - accuracy: 0.8711\n",
            "Epoch 9162/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9714 - accuracy: 0.8622\n",
            "Epoch 9163/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9664 - accuracy: 0.8622\n",
            "Epoch 9164/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 4.1091 - accuracy: 0.8578\n",
            "Epoch 9165/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9718 - accuracy: 0.8622\n",
            "Epoch 9166/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9224 - accuracy: 0.8444\n",
            "Epoch 9167/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 4.0308 - accuracy: 0.8756\n",
            "Epoch 9168/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.8851 - accuracy: 0.8533\n",
            "Epoch 9169/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9530 - accuracy: 0.8756\n",
            "Epoch 9170/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 4.0774 - accuracy: 0.8711\n",
            "Epoch 9171/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.8155 - accuracy: 0.8089\n",
            "Epoch 9172/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 3.5946 - accuracy: 0.8622\n",
            "Epoch 9173/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8931 - accuracy: 0.8311\n",
            "Epoch 9174/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 4.0494 - accuracy: 0.8533\n",
            "Epoch 9175/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.8846 - accuracy: 0.8489\n",
            "Epoch 9176/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.8583 - accuracy: 0.8400\n",
            "Epoch 9177/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.0083 - accuracy: 0.8400\n",
            "Epoch 9178/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.8445 - accuracy: 0.8844\n",
            "Epoch 9179/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9247 - accuracy: 0.8622\n",
            "Epoch 9180/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 3.9359 - accuracy: 0.8444\n",
            "Epoch 9181/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9758 - accuracy: 0.8533\n",
            "Epoch 9182/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9067 - accuracy: 0.8933\n",
            "Epoch 9183/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 4.0136 - accuracy: 0.8489\n",
            "Epoch 9184/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9422 - accuracy: 0.8400\n",
            "Epoch 9185/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9528 - accuracy: 0.8667\n",
            "Epoch 9186/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9141 - accuracy: 0.8622\n",
            "Epoch 9187/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.9114 - accuracy: 0.8622\n",
            "Epoch 9188/10000\n",
            "225/225 [==============================] - 0s 544us/step - loss: 3.9026 - accuracy: 0.8533\n",
            "Epoch 9189/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9772 - accuracy: 0.8622\n",
            "Epoch 9190/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.8946 - accuracy: 0.9022\n",
            "Epoch 9191/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9121 - accuracy: 0.8711\n",
            "Epoch 9192/10000\n",
            "225/225 [==============================] - 0s 506us/step - loss: 3.9802 - accuracy: 0.8667\n",
            "Epoch 9193/10000\n",
            "225/225 [==============================] - 0s 559us/step - loss: 3.9590 - accuracy: 0.8667\n",
            "Epoch 9194/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.8694 - accuracy: 0.8578\n",
            "Epoch 9195/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 4.0710 - accuracy: 0.8578\n",
            "Epoch 9196/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9594 - accuracy: 0.8400\n",
            "Epoch 9197/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.0240 - accuracy: 0.8533\n",
            "Epoch 9198/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.8513 - accuracy: 0.8667\n",
            "Epoch 9199/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9357 - accuracy: 0.8578\n",
            "Epoch 9200/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.8977 - accuracy: 0.8889\n",
            "Epoch 9201/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9122 - accuracy: 0.8400\n",
            "Epoch 9202/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9605 - accuracy: 0.8311\n",
            "Epoch 9203/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 4.0397 - accuracy: 0.8578\n",
            "Epoch 9204/10000\n",
            "225/225 [==============================] - 0s 514us/step - loss: 3.9318 - accuracy: 0.8622\n",
            "Epoch 9205/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9173 - accuracy: 0.8711\n",
            "Epoch 9206/10000\n",
            "225/225 [==============================] - 0s 498us/step - loss: 3.9693 - accuracy: 0.8800\n",
            "Epoch 9207/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9116 - accuracy: 0.8400\n",
            "Epoch 9208/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.8601 - accuracy: 0.8533\n",
            "Epoch 9209/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9248 - accuracy: 0.8622\n",
            "Epoch 9210/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9671 - accuracy: 0.8711\n",
            "Epoch 9211/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9951 - accuracy: 0.8622\n",
            "Epoch 9212/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0823 - accuracy: 0.8578\n",
            "Epoch 9213/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9712 - accuracy: 0.8578\n",
            "Epoch 9214/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.8372 - accuracy: 0.8356\n",
            "Epoch 9215/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.9717 - accuracy: 0.8578\n",
            "Epoch 9216/10000\n",
            "225/225 [==============================] - 0s 523us/step - loss: 3.8918 - accuracy: 0.8756\n",
            "Epoch 9217/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.7851 - accuracy: 0.8489\n",
            "Epoch 9218/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.8729 - accuracy: 0.8667\n",
            "Epoch 9219/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9944 - accuracy: 0.8978\n",
            "Epoch 9220/10000\n",
            "225/225 [==============================] - 0s 536us/step - loss: 4.0205 - accuracy: 0.8667\n",
            "Epoch 9221/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9567 - accuracy: 0.8489\n",
            "Epoch 9222/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.8911 - accuracy: 0.8622\n",
            "Epoch 9223/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 4.0581 - accuracy: 0.8489\n",
            "Epoch 9224/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9307 - accuracy: 0.8578\n",
            "Epoch 9225/10000\n",
            "225/225 [==============================] - 0s 508us/step - loss: 4.0576 - accuracy: 0.8356\n",
            "Epoch 9226/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9323 - accuracy: 0.8533\n",
            "Epoch 9227/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 3.9362 - accuracy: 0.8622\n",
            "Epoch 9228/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0617 - accuracy: 0.8400\n",
            "Epoch 9229/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 3.9166 - accuracy: 0.8622\n",
            "Epoch 9230/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9836 - accuracy: 0.8889\n",
            "Epoch 9231/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0139 - accuracy: 0.8444\n",
            "Epoch 9232/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0910 - accuracy: 0.8400\n",
            "Epoch 9233/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.8808 - accuracy: 0.8578\n",
            "Epoch 9234/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 4.0134 - accuracy: 0.8667\n",
            "Epoch 9235/10000\n",
            "225/225 [==============================] - 0s 494us/step - loss: 4.0809 - accuracy: 0.8800\n",
            "Epoch 9236/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.7874 - accuracy: 0.8400\n",
            "Epoch 9237/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9572 - accuracy: 0.8756\n",
            "Epoch 9238/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.8813 - accuracy: 0.8800\n",
            "Epoch 9239/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 4.0416 - accuracy: 0.8578\n",
            "Epoch 9240/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.8784 - accuracy: 0.8578\n",
            "Epoch 9241/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 4.0269 - accuracy: 0.8578\n",
            "Epoch 9242/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.8649 - accuracy: 0.8533\n",
            "Epoch 9243/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 4.0733 - accuracy: 0.8444\n",
            "Epoch 9244/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9299 - accuracy: 0.8667\n",
            "Epoch 9245/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9227 - accuracy: 0.8444\n",
            "Epoch 9246/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9261 - accuracy: 0.8311\n",
            "Epoch 9247/10000\n",
            "225/225 [==============================] - 0s 587us/step - loss: 3.3863 - accuracy: 0.8756\n",
            "Epoch 9248/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.7510 - accuracy: 0.8489\n",
            "Epoch 9249/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.8712 - accuracy: 0.8711\n",
            "Epoch 9250/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9743 - accuracy: 0.8400\n",
            "Epoch 9251/10000\n",
            "225/225 [==============================] - 0s 532us/step - loss: 3.8328 - accuracy: 0.8889\n",
            "Epoch 9252/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.8426 - accuracy: 0.8844\n",
            "Epoch 9253/10000\n",
            "225/225 [==============================] - 0s 500us/step - loss: 3.9664 - accuracy: 0.8756\n",
            "Epoch 9254/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 4.0993 - accuracy: 0.8356\n",
            "Epoch 9255/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9058 - accuracy: 0.8533\n",
            "Epoch 9256/10000\n",
            "225/225 [==============================] - 0s 494us/step - loss: 3.9942 - accuracy: 0.8889\n",
            "Epoch 9257/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9336 - accuracy: 0.8578\n",
            "Epoch 9258/10000\n",
            "225/225 [==============================] - 0s 523us/step - loss: 3.7936 - accuracy: 0.8667\n",
            "Epoch 9259/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.9380 - accuracy: 0.8356\n",
            "Epoch 9260/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.7772 - accuracy: 0.8400\n",
            "Epoch 9261/10000\n",
            "225/225 [==============================] - 0s 516us/step - loss: 3.9490 - accuracy: 0.8578\n",
            "Epoch 9262/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9783 - accuracy: 0.8889\n",
            "Epoch 9263/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9629 - accuracy: 0.8489\n",
            "Epoch 9264/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0861 - accuracy: 0.8533\n",
            "Epoch 9265/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 4.0064 - accuracy: 0.8400\n",
            "Epoch 9266/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.7532 - accuracy: 0.8800\n",
            "Epoch 9267/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.8188 - accuracy: 0.8533\n",
            "Epoch 9268/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9522 - accuracy: 0.8444\n",
            "Epoch 9269/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 3.8890 - accuracy: 0.8356\n",
            "Epoch 9270/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 4.0455 - accuracy: 0.8711\n",
            "Epoch 9271/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0112 - accuracy: 0.8578\n",
            "Epoch 9272/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.0638 - accuracy: 0.8756\n",
            "Epoch 9273/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9352 - accuracy: 0.8489\n",
            "Epoch 9274/10000\n",
            "225/225 [==============================] - 0s 508us/step - loss: 3.9772 - accuracy: 0.8667\n",
            "Epoch 9275/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9415 - accuracy: 0.8356\n",
            "Epoch 9276/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 4.0111 - accuracy: 0.8711\n",
            "Epoch 9277/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9500 - accuracy: 0.8844\n",
            "Epoch 9278/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9197 - accuracy: 0.8711\n",
            "Epoch 9279/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 3.5942 - accuracy: 0.8622\n",
            "Epoch 9280/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.8172 - accuracy: 0.8489\n",
            "Epoch 9281/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9884 - accuracy: 0.8578\n",
            "Epoch 9282/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0751 - accuracy: 0.8400\n",
            "Epoch 9283/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.8423 - accuracy: 0.8711\n",
            "Epoch 9284/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 3.9538 - accuracy: 0.8578\n",
            "Epoch 9285/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.7720 - accuracy: 0.8222\n",
            "Epoch 9286/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.8882 - accuracy: 0.8889\n",
            "Epoch 9287/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.0593 - accuracy: 0.8578\n",
            "Epoch 9288/10000\n",
            "225/225 [==============================] - 0s 494us/step - loss: 3.9683 - accuracy: 0.8622\n",
            "Epoch 9289/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 3.8810 - accuracy: 0.8622\n",
            "Epoch 9290/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0602 - accuracy: 0.8533\n",
            "Epoch 9291/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9695 - accuracy: 0.8400\n",
            "Epoch 9292/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9107 - accuracy: 0.8533\n",
            "Epoch 9293/10000\n",
            "225/225 [==============================] - 0s 515us/step - loss: 3.9877 - accuracy: 0.8533\n",
            "Epoch 9294/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.7826 - accuracy: 0.8622\n",
            "Epoch 9295/10000\n",
            "225/225 [==============================] - 0s 542us/step - loss: 3.9972 - accuracy: 0.8578\n",
            "Epoch 9296/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.9843 - accuracy: 0.8756\n",
            "Epoch 9297/10000\n",
            "225/225 [==============================] - 0s 516us/step - loss: 4.0254 - accuracy: 0.8400\n",
            "Epoch 9298/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9333 - accuracy: 0.8356\n",
            "Epoch 9299/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9032 - accuracy: 0.8711\n",
            "Epoch 9300/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9560 - accuracy: 0.8533\n",
            "Epoch 9301/10000\n",
            "225/225 [==============================] - 0s 512us/step - loss: 4.0470 - accuracy: 0.8356\n",
            "Epoch 9302/10000\n",
            "225/225 [==============================] - 0s 542us/step - loss: 3.9504 - accuracy: 0.8622\n",
            "Epoch 9303/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8235 - accuracy: 0.8489\n",
            "Epoch 9304/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.8814 - accuracy: 0.8622\n",
            "Epoch 9305/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.8044 - accuracy: 0.8533\n",
            "Epoch 9306/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 4.1071 - accuracy: 0.8356\n",
            "Epoch 9307/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 4.0606 - accuracy: 0.8889\n",
            "Epoch 9308/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.8286 - accuracy: 0.8756\n",
            "Epoch 9309/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9046 - accuracy: 0.8578\n",
            "Epoch 9310/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.8243 - accuracy: 0.8756\n",
            "Epoch 9311/10000\n",
            "225/225 [==============================] - 0s 515us/step - loss: 3.9571 - accuracy: 0.8489\n",
            "Epoch 9312/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.3983 - accuracy: 0.8756\n",
            "Epoch 9313/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.7991 - accuracy: 0.8756\n",
            "Epoch 9314/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.5949 - accuracy: 0.8978\n",
            "Epoch 9315/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 4.0269 - accuracy: 0.8489\n",
            "Epoch 9316/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9669 - accuracy: 0.8889\n",
            "Epoch 9317/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.0115 - accuracy: 0.8533\n",
            "Epoch 9318/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0668 - accuracy: 0.8756\n",
            "Epoch 9319/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.9483 - accuracy: 0.8578\n",
            "Epoch 9320/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.9631 - accuracy: 0.8533\n",
            "Epoch 9321/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 4.0144 - accuracy: 0.8578\n",
            "Epoch 9322/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9344 - accuracy: 0.8444\n",
            "Epoch 9323/10000\n",
            "225/225 [==============================] - 0s 568us/step - loss: 3.9218 - accuracy: 0.8489\n",
            "Epoch 9324/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 4.0527 - accuracy: 0.8311\n",
            "Epoch 9325/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.6859 - accuracy: 0.8444\n",
            "Epoch 9326/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.0136 - accuracy: 0.8578\n",
            "Epoch 9327/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9083 - accuracy: 0.8756\n",
            "Epoch 9328/10000\n",
            "225/225 [==============================] - 0s 502us/step - loss: 4.0623 - accuracy: 0.8356\n",
            "Epoch 9329/10000\n",
            "225/225 [==============================] - 0s 575us/step - loss: 3.9005 - accuracy: 0.8489\n",
            "Epoch 9330/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.8722 - accuracy: 0.8667\n",
            "Epoch 9331/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.0319 - accuracy: 0.8578\n",
            "Epoch 9332/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9200 - accuracy: 0.8756\n",
            "Epoch 9333/10000\n",
            "225/225 [==============================] - 0s 517us/step - loss: 3.7156 - accuracy: 0.8356\n",
            "Epoch 9334/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9644 - accuracy: 0.8667\n",
            "Epoch 9335/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9885 - accuracy: 0.8578\n",
            "Epoch 9336/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.3422 - accuracy: 0.8711\n",
            "Epoch 9337/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9882 - accuracy: 0.8622\n",
            "Epoch 9338/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9878 - accuracy: 0.8667\n",
            "Epoch 9339/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 4.0048 - accuracy: 0.8667\n",
            "Epoch 9340/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9293 - accuracy: 0.8711\n",
            "Epoch 9341/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.9812 - accuracy: 0.8800\n",
            "Epoch 9342/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9757 - accuracy: 0.8667\n",
            "Epoch 9343/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9816 - accuracy: 0.8711\n",
            "Epoch 9344/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9533 - accuracy: 0.8667\n",
            "Epoch 9345/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.9083 - accuracy: 0.8489\n",
            "Epoch 9346/10000\n",
            "225/225 [==============================] - 0s 524us/step - loss: 3.9054 - accuracy: 0.8622\n",
            "Epoch 9347/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9771 - accuracy: 0.8178\n",
            "Epoch 9348/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.8295 - accuracy: 0.8711\n",
            "Epoch 9349/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 4.0359 - accuracy: 0.8533\n",
            "Epoch 9350/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.4816 - accuracy: 0.8133\n",
            "Epoch 9351/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 3.8526 - accuracy: 0.8578\n",
            "Epoch 9352/10000\n",
            "225/225 [==============================] - 0s 520us/step - loss: 3.9876 - accuracy: 0.8578\n",
            "Epoch 9353/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9687 - accuracy: 0.8711\n",
            "Epoch 9354/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9715 - accuracy: 0.8533\n",
            "Epoch 9355/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.8504 - accuracy: 0.8578\n",
            "Epoch 9356/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0254 - accuracy: 0.8622\n",
            "Epoch 9357/10000\n",
            "225/225 [==============================] - 0s 532us/step - loss: 4.1001 - accuracy: 0.8578\n",
            "Epoch 9358/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0753 - accuracy: 0.8533\n",
            "Epoch 9359/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.8851 - accuracy: 0.8800\n",
            "Epoch 9360/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.8298 - accuracy: 0.8667\n",
            "Epoch 9361/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.0644 - accuracy: 0.8400\n",
            "Epoch 9362/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0385 - accuracy: 0.8489\n",
            "Epoch 9363/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.9601 - accuracy: 0.8533\n",
            "Epoch 9364/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.7859 - accuracy: 0.8844\n",
            "Epoch 9365/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9616 - accuracy: 0.8622\n",
            "Epoch 9366/10000\n",
            "225/225 [==============================] - 0s 512us/step - loss: 4.0171 - accuracy: 0.8622\n",
            "Epoch 9367/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9799 - accuracy: 0.8756\n",
            "Epoch 9368/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9901 - accuracy: 0.8444\n",
            "Epoch 9369/10000\n",
            "225/225 [==============================] - 0s 508us/step - loss: 4.0413 - accuracy: 0.8533\n",
            "Epoch 9370/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9309 - accuracy: 0.8400\n",
            "Epoch 9371/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.9223 - accuracy: 0.8444\n",
            "Epoch 9372/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9922 - accuracy: 0.8400\n",
            "Epoch 9373/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9548 - accuracy: 0.8844\n",
            "Epoch 9374/10000\n",
            "225/225 [==============================] - 0s 499us/step - loss: 3.9350 - accuracy: 0.8756\n",
            "Epoch 9375/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.7467 - accuracy: 0.8578\n",
            "Epoch 9376/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 4.0034 - accuracy: 0.8533\n",
            "Epoch 9377/10000\n",
            "225/225 [==============================] - 0s 529us/step - loss: 4.0339 - accuracy: 0.8489\n",
            "Epoch 9378/10000\n",
            "225/225 [==============================] - 0s 541us/step - loss: 4.0721 - accuracy: 0.8533\n",
            "Epoch 9379/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0692 - accuracy: 0.8622\n",
            "Epoch 9380/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0148 - accuracy: 0.8356\n",
            "Epoch 9381/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9632 - accuracy: 0.8444\n",
            "Epoch 9382/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 4.0572 - accuracy: 0.8356\n",
            "Epoch 9383/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.8440 - accuracy: 0.8622\n",
            "Epoch 9384/10000\n",
            "225/225 [==============================] - 0s 509us/step - loss: 3.8765 - accuracy: 0.8578\n",
            "Epoch 9385/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.6686 - accuracy: 0.8756\n",
            "Epoch 9386/10000\n",
            "225/225 [==============================] - 0s 533us/step - loss: 3.9254 - accuracy: 0.8844\n",
            "Epoch 9387/10000\n",
            "225/225 [==============================] - 0s 610us/step - loss: 3.9683 - accuracy: 0.8444\n",
            "Epoch 9388/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.7892 - accuracy: 0.8444\n",
            "Epoch 9389/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9465 - accuracy: 0.8400\n",
            "Epoch 9390/10000\n",
            "225/225 [==============================] - 0s 528us/step - loss: 4.0129 - accuracy: 0.8622\n",
            "Epoch 9391/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 3.9417 - accuracy: 0.8622\n",
            "Epoch 9392/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.7168 - accuracy: 0.8711\n",
            "Epoch 9393/10000\n",
            "225/225 [==============================] - 0s 512us/step - loss: 3.7587 - accuracy: 0.8756\n",
            "Epoch 9394/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.8937 - accuracy: 0.8756\n",
            "Epoch 9395/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.8875 - accuracy: 0.8889\n",
            "Epoch 9396/10000\n",
            "225/225 [==============================] - 0s 498us/step - loss: 3.7599 - accuracy: 0.8622\n",
            "Epoch 9397/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.8997 - accuracy: 0.8711\n",
            "Epoch 9398/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0264 - accuracy: 0.8533\n",
            "Epoch 9399/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9405 - accuracy: 0.8622\n",
            "Epoch 9400/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9787 - accuracy: 0.8667\n",
            "Epoch 9401/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 4.0035 - accuracy: 0.8356\n",
            "Epoch 9402/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 4.0098 - accuracy: 0.8578\n",
            "Epoch 9403/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 4.0734 - accuracy: 0.8489\n",
            "Epoch 9404/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9279 - accuracy: 0.8533\n",
            "Epoch 9405/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 4.0353 - accuracy: 0.8667\n",
            "Epoch 9406/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 4.0299 - accuracy: 0.8400\n",
            "Epoch 9407/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.9711 - accuracy: 0.8622\n",
            "Epoch 9408/10000\n",
            "225/225 [==============================] - 0s 541us/step - loss: 3.7985 - accuracy: 0.8800\n",
            "Epoch 9409/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9453 - accuracy: 0.8667\n",
            "Epoch 9410/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.9330 - accuracy: 0.8844\n",
            "Epoch 9411/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.8860 - accuracy: 0.8311\n",
            "Epoch 9412/10000\n",
            "225/225 [==============================] - 0s 517us/step - loss: 3.7194 - accuracy: 0.8489\n",
            "Epoch 9413/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.8025 - accuracy: 0.8489\n",
            "Epoch 9414/10000\n",
            "225/225 [==============================] - 0s 510us/step - loss: 3.8510 - accuracy: 0.8489\n",
            "Epoch 9415/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.8994 - accuracy: 0.8444\n",
            "Epoch 9416/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.8220 - accuracy: 0.8533\n",
            "Epoch 9417/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.7926 - accuracy: 0.8489\n",
            "Epoch 9418/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9228 - accuracy: 0.8533\n",
            "Epoch 9419/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9994 - accuracy: 0.8444\n",
            "Epoch 9420/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 4.0290 - accuracy: 0.8622\n",
            "Epoch 9421/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 3.9301 - accuracy: 0.8800\n",
            "Epoch 9422/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 4.0680 - accuracy: 0.8489\n",
            "Epoch 9423/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9034 - accuracy: 0.8578\n",
            "Epoch 9424/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0139 - accuracy: 0.8444\n",
            "Epoch 9425/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.8374 - accuracy: 0.8711\n",
            "Epoch 9426/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9174 - accuracy: 0.8578\n",
            "Epoch 9427/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.7774 - accuracy: 0.8800\n",
            "Epoch 9428/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8313 - accuracy: 0.8622\n",
            "Epoch 9429/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9636 - accuracy: 0.8533\n",
            "Epoch 9430/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 4.0424 - accuracy: 0.8711\n",
            "Epoch 9431/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.8323 - accuracy: 0.8667\n",
            "Epoch 9432/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.7129 - accuracy: 0.8578\n",
            "Epoch 9433/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9573 - accuracy: 0.8756\n",
            "Epoch 9434/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9919 - accuracy: 0.8622\n",
            "Epoch 9435/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 4.0199 - accuracy: 0.8622\n",
            "Epoch 9436/10000\n",
            "225/225 [==============================] - 0s 528us/step - loss: 3.7868 - accuracy: 0.8844\n",
            "Epoch 9437/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9281 - accuracy: 0.8444\n",
            "Epoch 9438/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.9230 - accuracy: 0.8444\n",
            "Epoch 9439/10000\n",
            "225/225 [==============================] - 0s 538us/step - loss: 3.9169 - accuracy: 0.8622\n",
            "Epoch 9440/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9582 - accuracy: 0.8578\n",
            "Epoch 9441/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9166 - accuracy: 0.8622\n",
            "Epoch 9442/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.8954 - accuracy: 0.8711\n",
            "Epoch 9443/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9274 - accuracy: 0.8622\n",
            "Epoch 9444/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9309 - accuracy: 0.8533\n",
            "Epoch 9445/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.7588 - accuracy: 0.8400\n",
            "Epoch 9446/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9828 - accuracy: 0.8756\n",
            "Epoch 9447/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 4.1529 - accuracy: 0.8489\n",
            "Epoch 9448/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 4.0942 - accuracy: 0.8800\n",
            "Epoch 9449/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.0106 - accuracy: 0.8844\n",
            "Epoch 9450/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.9161 - accuracy: 0.8667\n",
            "Epoch 9451/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.8648 - accuracy: 0.8444\n",
            "Epoch 9452/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0816 - accuracy: 0.8756\n",
            "Epoch 9453/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9451 - accuracy: 0.8578\n",
            "Epoch 9454/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 4.0214 - accuracy: 0.8533\n",
            "Epoch 9455/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.9856 - accuracy: 0.8400\n",
            "Epoch 9456/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9684 - accuracy: 0.8444\n",
            "Epoch 9457/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9336 - accuracy: 0.8533\n",
            "Epoch 9458/10000\n",
            "225/225 [==============================] - 0s 530us/step - loss: 3.9308 - accuracy: 0.8711\n",
            "Epoch 9459/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.7859 - accuracy: 0.8667\n",
            "Epoch 9460/10000\n",
            "225/225 [==============================] - 0s 494us/step - loss: 4.0420 - accuracy: 0.8711\n",
            "Epoch 9461/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.8937 - accuracy: 0.8622\n",
            "Epoch 9462/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.8600 - accuracy: 0.8578\n",
            "Epoch 9463/10000\n",
            "225/225 [==============================] - 0s 499us/step - loss: 3.9534 - accuracy: 0.8667\n",
            "Epoch 9464/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.8218 - accuracy: 0.8622\n",
            "Epoch 9465/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 4.0743 - accuracy: 0.8533\n",
            "Epoch 9466/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.0290 - accuracy: 0.8444\n",
            "Epoch 9467/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 3.9286 - accuracy: 0.8578\n",
            "Epoch 9468/10000\n",
            "225/225 [==============================] - 0s 510us/step - loss: 4.0643 - accuracy: 0.8756\n",
            "Epoch 9469/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 3.9258 - accuracy: 0.8400\n",
            "Epoch 9470/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 4.0655 - accuracy: 0.8667\n",
            "Epoch 9471/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.8997 - accuracy: 0.8400\n",
            "Epoch 9472/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9372 - accuracy: 0.8489\n",
            "Epoch 9473/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 4.1261 - accuracy: 0.8756\n",
            "Epoch 9474/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9421 - accuracy: 0.8444\n",
            "Epoch 9475/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9590 - accuracy: 0.8622\n",
            "Epoch 9476/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 4.1343 - accuracy: 0.8578\n",
            "Epoch 9477/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 3.8004 - accuracy: 0.8533\n",
            "Epoch 9478/10000\n",
            "225/225 [==============================] - 0s 500us/step - loss: 4.0512 - accuracy: 0.8889\n",
            "Epoch 9479/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.8019 - accuracy: 0.8756\n",
            "Epoch 9480/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9774 - accuracy: 0.8622\n",
            "Epoch 9481/10000\n",
            "225/225 [==============================] - 0s 531us/step - loss: 3.8320 - accuracy: 0.8533\n",
            "Epoch 9482/10000\n",
            "225/225 [==============================] - 0s 529us/step - loss: 3.9095 - accuracy: 0.8578\n",
            "Epoch 9483/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9525 - accuracy: 0.8756\n",
            "Epoch 9484/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.8205 - accuracy: 0.8578\n",
            "Epoch 9485/10000\n",
            "225/225 [==============================] - 0s 540us/step - loss: 3.8403 - accuracy: 0.8933\n",
            "Epoch 9486/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.8189 - accuracy: 0.8311\n",
            "Epoch 9487/10000\n",
            "225/225 [==============================] - 0s 543us/step - loss: 3.7039 - accuracy: 0.8356\n",
            "Epoch 9488/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.9933 - accuracy: 0.8667\n",
            "Epoch 9489/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.9328 - accuracy: 0.8933\n",
            "Epoch 9490/10000\n",
            "225/225 [==============================] - 0s 563us/step - loss: 4.0841 - accuracy: 0.8444\n",
            "Epoch 9491/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 4.0923 - accuracy: 0.8578\n",
            "Epoch 9492/10000\n",
            "225/225 [==============================] - 0s 520us/step - loss: 3.8929 - accuracy: 0.8622\n",
            "Epoch 9493/10000\n",
            "225/225 [==============================] - 0s 596us/step - loss: 4.1206 - accuracy: 0.8711\n",
            "Epoch 9494/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.8927 - accuracy: 0.8444\n",
            "Epoch 9495/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.8619 - accuracy: 0.8711\n",
            "Epoch 9496/10000\n",
            "225/225 [==============================] - 0s 532us/step - loss: 3.9047 - accuracy: 0.8444\n",
            "Epoch 9497/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.8544 - accuracy: 0.8622\n",
            "Epoch 9498/10000\n",
            "225/225 [==============================] - 0s 499us/step - loss: 3.8658 - accuracy: 0.8756\n",
            "Epoch 9499/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9621 - accuracy: 0.8622\n",
            "Epoch 9500/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.9057 - accuracy: 0.8444\n",
            "Epoch 9501/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.9461 - accuracy: 0.8267\n",
            "Epoch 9502/10000\n",
            "225/225 [==============================] - 0s 526us/step - loss: 3.9125 - accuracy: 0.8444\n",
            "Epoch 9503/10000\n",
            "225/225 [==============================] - 0s 502us/step - loss: 4.0300 - accuracy: 0.8489\n",
            "Epoch 9504/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 4.0487 - accuracy: 0.8489\n",
            "Epoch 9505/10000\n",
            "225/225 [==============================] - 0s 506us/step - loss: 4.1999 - accuracy: 0.8622\n",
            "Epoch 9506/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 3.9166 - accuracy: 0.8578\n",
            "Epoch 9507/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 4.0049 - accuracy: 0.8489\n",
            "Epoch 9508/10000\n",
            "225/225 [==============================] - 0s 521us/step - loss: 3.9582 - accuracy: 0.8622\n",
            "Epoch 9509/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.6937 - accuracy: 0.8533\n",
            "Epoch 9510/10000\n",
            "225/225 [==============================] - 0s 577us/step - loss: 3.9179 - accuracy: 0.8400\n",
            "Epoch 9511/10000\n",
            "225/225 [==============================] - 0s 532us/step - loss: 3.6112 - accuracy: 0.8444\n",
            "Epoch 9512/10000\n",
            "225/225 [==============================] - 0s 523us/step - loss: 4.0593 - accuracy: 0.8400\n",
            "Epoch 9513/10000\n",
            "225/225 [==============================] - 0s 537us/step - loss: 3.9455 - accuracy: 0.8800\n",
            "Epoch 9514/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9831 - accuracy: 0.8444\n",
            "Epoch 9515/10000\n",
            "225/225 [==============================] - 0s 553us/step - loss: 4.0133 - accuracy: 0.8356\n",
            "Epoch 9516/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 4.0816 - accuracy: 0.8756\n",
            "Epoch 9517/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 4.0053 - accuracy: 0.8622\n",
            "Epoch 9518/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9039 - accuracy: 0.8667\n",
            "Epoch 9519/10000\n",
            "225/225 [==============================] - 0s 522us/step - loss: 3.9683 - accuracy: 0.8622\n",
            "Epoch 9520/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 4.0086 - accuracy: 0.8578\n",
            "Epoch 9521/10000\n",
            "225/225 [==============================] - 0s 587us/step - loss: 3.9153 - accuracy: 0.8622\n",
            "Epoch 9522/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 4.0435 - accuracy: 0.8444\n",
            "Epoch 9523/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.8705 - accuracy: 0.8756\n",
            "Epoch 9524/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 4.0563 - accuracy: 0.8533\n",
            "Epoch 9525/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9641 - accuracy: 0.8578\n",
            "Epoch 9526/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.8817 - accuracy: 0.8711\n",
            "Epoch 9527/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9559 - accuracy: 0.8711\n",
            "Epoch 9528/10000\n",
            "225/225 [==============================] - 0s 532us/step - loss: 3.9098 - accuracy: 0.8711\n",
            "Epoch 9529/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 4.0390 - accuracy: 0.8444\n",
            "Epoch 9530/10000\n",
            "225/225 [==============================] - 0s 523us/step - loss: 3.8444 - accuracy: 0.8356\n",
            "Epoch 9531/10000\n",
            "225/225 [==============================] - 0s 547us/step - loss: 3.8580 - accuracy: 0.8533\n",
            "Epoch 9532/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 4.0508 - accuracy: 0.8444\n",
            "Epoch 9533/10000\n",
            "225/225 [==============================] - 0s 523us/step - loss: 3.9094 - accuracy: 0.8711\n",
            "Epoch 9534/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9222 - accuracy: 0.8667\n",
            "Epoch 9535/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9817 - accuracy: 0.8489\n",
            "Epoch 9536/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 4.0455 - accuracy: 0.8756\n",
            "Epoch 9537/10000\n",
            "225/225 [==============================] - 0s 538us/step - loss: 4.2030 - accuracy: 0.8489\n",
            "Epoch 9538/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 4.0414 - accuracy: 0.8400\n",
            "Epoch 9539/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.8521 - accuracy: 0.8311\n",
            "Epoch 9540/10000\n",
            "225/225 [==============================] - 0s 558us/step - loss: 4.0497 - accuracy: 0.8489\n",
            "Epoch 9541/10000\n",
            "225/225 [==============================] - 0s 523us/step - loss: 3.8946 - accuracy: 0.8533\n",
            "Epoch 9542/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.8853 - accuracy: 0.8667\n",
            "Epoch 9543/10000\n",
            "225/225 [==============================] - 0s 497us/step - loss: 3.8929 - accuracy: 0.8933\n",
            "Epoch 9544/10000\n",
            "225/225 [==============================] - 0s 535us/step - loss: 4.0244 - accuracy: 0.8622\n",
            "Epoch 9545/10000\n",
            "225/225 [==============================] - 0s 556us/step - loss: 3.8743 - accuracy: 0.8311\n",
            "Epoch 9546/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 3.9707 - accuracy: 0.8756\n",
            "Epoch 9547/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 3.8660 - accuracy: 0.8756\n",
            "Epoch 9548/10000\n",
            "225/225 [==============================] - 0s 508us/step - loss: 3.9697 - accuracy: 0.8800\n",
            "Epoch 9549/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.7667 - accuracy: 0.8444\n",
            "Epoch 9550/10000\n",
            "225/225 [==============================] - 0s 497us/step - loss: 3.9426 - accuracy: 0.8356\n",
            "Epoch 9551/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.8550 - accuracy: 0.8444\n",
            "Epoch 9552/10000\n",
            "225/225 [==============================] - 0s 525us/step - loss: 3.9776 - accuracy: 0.8400\n",
            "Epoch 9553/10000\n",
            "225/225 [==============================] - 0s 507us/step - loss: 4.0823 - accuracy: 0.8489\n",
            "Epoch 9554/10000\n",
            "225/225 [==============================] - 0s 532us/step - loss: 3.9382 - accuracy: 0.8533\n",
            "Epoch 9555/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 4.0487 - accuracy: 0.8622\n",
            "Epoch 9556/10000\n",
            "225/225 [==============================] - 0s 512us/step - loss: 3.9785 - accuracy: 0.8889\n",
            "Epoch 9557/10000\n",
            "225/225 [==============================] - 0s 517us/step - loss: 3.9896 - accuracy: 0.8489\n",
            "Epoch 9558/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 3.9124 - accuracy: 0.8711\n",
            "Epoch 9559/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 3.6356 - accuracy: 0.8711\n",
            "Epoch 9560/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 4.0156 - accuracy: 0.8578\n",
            "Epoch 9561/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 3.9374 - accuracy: 0.8489\n",
            "Epoch 9562/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 4.0843 - accuracy: 0.8578\n",
            "Epoch 9563/10000\n",
            "225/225 [==============================] - 0s 557us/step - loss: 3.8090 - accuracy: 0.8756\n",
            "Epoch 9564/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.7057 - accuracy: 0.8622\n",
            "Epoch 9565/10000\n",
            "225/225 [==============================] - 0s 521us/step - loss: 3.9967 - accuracy: 0.8533\n",
            "Epoch 9566/10000\n",
            "225/225 [==============================] - 0s 563us/step - loss: 3.8831 - accuracy: 0.8622\n",
            "Epoch 9567/10000\n",
            "225/225 [==============================] - 0s 527us/step - loss: 3.9933 - accuracy: 0.8756\n",
            "Epoch 9568/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9517 - accuracy: 0.8578\n",
            "Epoch 9569/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9163 - accuracy: 0.8533\n",
            "Epoch 9570/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.9250 - accuracy: 0.8667\n",
            "Epoch 9571/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 4.0595 - accuracy: 0.8489\n",
            "Epoch 9572/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.8867 - accuracy: 0.8444\n",
            "Epoch 9573/10000\n",
            "225/225 [==============================] - 0s 451us/step - loss: 4.0165 - accuracy: 0.8489\n",
            "Epoch 9574/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0573 - accuracy: 0.8267\n",
            "Epoch 9575/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 3.9902 - accuracy: 0.8489\n",
            "Epoch 9576/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 4.0269 - accuracy: 0.8622\n",
            "Epoch 9577/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 3.9198 - accuracy: 0.8489\n",
            "Epoch 9578/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.2266 - accuracy: 0.8622\n",
            "Epoch 9579/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.7435 - accuracy: 0.8622\n",
            "Epoch 9580/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.9411 - accuracy: 0.8444\n",
            "Epoch 9581/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.9097 - accuracy: 0.7956\n",
            "Epoch 9582/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9171 - accuracy: 0.8444\n",
            "Epoch 9583/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9605 - accuracy: 0.8444\n",
            "Epoch 9584/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.0078 - accuracy: 0.8622\n",
            "Epoch 9585/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 3.9517 - accuracy: 0.8711\n",
            "Epoch 9586/10000\n",
            "225/225 [==============================] - 0s 527us/step - loss: 3.9579 - accuracy: 0.8578\n",
            "Epoch 9587/10000\n",
            "225/225 [==============================] - 0s 504us/step - loss: 3.8386 - accuracy: 0.8533\n",
            "Epoch 9588/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 4.0118 - accuracy: 0.8711\n",
            "Epoch 9589/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.8627 - accuracy: 0.8444\n",
            "Epoch 9590/10000\n",
            "225/225 [==============================] - 0s 548us/step - loss: 3.8671 - accuracy: 0.8400\n",
            "Epoch 9591/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9976 - accuracy: 0.8444\n",
            "Epoch 9592/10000\n",
            "225/225 [==============================] - 0s 517us/step - loss: 3.9749 - accuracy: 0.8622\n",
            "Epoch 9593/10000\n",
            "225/225 [==============================] - 0s 526us/step - loss: 3.9990 - accuracy: 0.8667\n",
            "Epoch 9594/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9467 - accuracy: 0.8578\n",
            "Epoch 9595/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 3.8710 - accuracy: 0.8667\n",
            "Epoch 9596/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 3.9362 - accuracy: 0.8711\n",
            "Epoch 9597/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9972 - accuracy: 0.8533\n",
            "Epoch 9598/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.7417 - accuracy: 0.8489\n",
            "Epoch 9599/10000\n",
            "225/225 [==============================] - 0s 543us/step - loss: 3.8746 - accuracy: 0.8756\n",
            "Epoch 9600/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.9515 - accuracy: 0.8489\n",
            "Epoch 9601/10000\n",
            "225/225 [==============================] - 0s 515us/step - loss: 3.9956 - accuracy: 0.8178\n",
            "Epoch 9602/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9604 - accuracy: 0.8533\n",
            "Epoch 9603/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.9246 - accuracy: 0.8622\n",
            "Epoch 9604/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.7416 - accuracy: 0.8444\n",
            "Epoch 9605/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 4.0014 - accuracy: 0.8533\n",
            "Epoch 9606/10000\n",
            "225/225 [==============================] - 0s 485us/step - loss: 4.0081 - accuracy: 0.8578\n",
            "Epoch 9607/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 4.0317 - accuracy: 0.8622\n",
            "Epoch 9608/10000\n",
            "225/225 [==============================] - 0s 525us/step - loss: 3.9702 - accuracy: 0.8311\n",
            "Epoch 9609/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9266 - accuracy: 0.8667\n",
            "Epoch 9610/10000\n",
            "225/225 [==============================] - 0s 516us/step - loss: 3.9443 - accuracy: 0.8400\n",
            "Epoch 9611/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.6251 - accuracy: 0.8622\n",
            "Epoch 9612/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9397 - accuracy: 0.8622\n",
            "Epoch 9613/10000\n",
            "225/225 [==============================] - 0s 508us/step - loss: 3.9612 - accuracy: 0.8756\n",
            "Epoch 9614/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 4.0310 - accuracy: 0.8756\n",
            "Epoch 9615/10000\n",
            "225/225 [==============================] - 0s 528us/step - loss: 3.9115 - accuracy: 0.8622\n",
            "Epoch 9616/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.6570 - accuracy: 0.8622\n",
            "Epoch 9617/10000\n",
            "225/225 [==============================] - 0s 529us/step - loss: 3.9940 - accuracy: 0.8533\n",
            "Epoch 9618/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 3.9466 - accuracy: 0.8444\n",
            "Epoch 9619/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 3.9516 - accuracy: 0.8711\n",
            "Epoch 9620/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.7516 - accuracy: 0.8578\n",
            "Epoch 9621/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9524 - accuracy: 0.8622\n",
            "Epoch 9622/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 4.0075 - accuracy: 0.8489\n",
            "Epoch 9623/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9890 - accuracy: 0.8533\n",
            "Epoch 9624/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9632 - accuracy: 0.8311\n",
            "Epoch 9625/10000\n",
            "225/225 [==============================] - 0s 546us/step - loss: 4.0222 - accuracy: 0.8667\n",
            "Epoch 9626/10000\n",
            "225/225 [==============================] - 0s 494us/step - loss: 3.9727 - accuracy: 0.8667\n",
            "Epoch 9627/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0762 - accuracy: 0.8489\n",
            "Epoch 9628/10000\n",
            "225/225 [==============================] - 0s 510us/step - loss: 3.8510 - accuracy: 0.8533\n",
            "Epoch 9629/10000\n",
            "225/225 [==============================] - 0s 529us/step - loss: 3.9679 - accuracy: 0.8533\n",
            "Epoch 9630/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.8983 - accuracy: 0.8489\n",
            "Epoch 9631/10000\n",
            "225/225 [==============================] - 0s 523us/step - loss: 4.0922 - accuracy: 0.8711\n",
            "Epoch 9632/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0527 - accuracy: 0.8311\n",
            "Epoch 9633/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9139 - accuracy: 0.8800\n",
            "Epoch 9634/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 3.8326 - accuracy: 0.8800\n",
            "Epoch 9635/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9702 - accuracy: 0.8489\n",
            "Epoch 9636/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9421 - accuracy: 0.8667\n",
            "Epoch 9637/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.8931 - accuracy: 0.8622\n",
            "Epoch 9638/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.7400 - accuracy: 0.8489\n",
            "Epoch 9639/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.8448 - accuracy: 0.8489\n",
            "Epoch 9640/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 4.0590 - accuracy: 0.8667\n",
            "Epoch 9641/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9626 - accuracy: 0.8489\n",
            "Epoch 9642/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9618 - accuracy: 0.8667\n",
            "Epoch 9643/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9675 - accuracy: 0.8444\n",
            "Epoch 9644/10000\n",
            "225/225 [==============================] - 0s 499us/step - loss: 4.1704 - accuracy: 0.8533\n",
            "Epoch 9645/10000\n",
            "225/225 [==============================] - 0s 542us/step - loss: 3.9459 - accuracy: 0.8667\n",
            "Epoch 9646/10000\n",
            "225/225 [==============================] - 0s 524us/step - loss: 3.9458 - accuracy: 0.8622\n",
            "Epoch 9647/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9081 - accuracy: 0.8711\n",
            "Epoch 9648/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9289 - accuracy: 0.8489\n",
            "Epoch 9649/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.0126 - accuracy: 0.8533\n",
            "Epoch 9650/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9665 - accuracy: 0.8622\n",
            "Epoch 9651/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0005 - accuracy: 0.8444\n",
            "Epoch 9652/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.8129 - accuracy: 0.8667\n",
            "Epoch 9653/10000\n",
            "225/225 [==============================] - 0s 532us/step - loss: 3.9315 - accuracy: 0.8356\n",
            "Epoch 9654/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.7774 - accuracy: 0.8533\n",
            "Epoch 9655/10000\n",
            "225/225 [==============================] - 0s 494us/step - loss: 4.0716 - accuracy: 0.8400\n",
            "Epoch 9656/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 4.0441 - accuracy: 0.8222\n",
            "Epoch 9657/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9135 - accuracy: 0.8356\n",
            "Epoch 9658/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9620 - accuracy: 0.8844\n",
            "Epoch 9659/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.8256 - accuracy: 0.8578\n",
            "Epoch 9660/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.8020 - accuracy: 0.8489\n",
            "Epoch 9661/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 4.0610 - accuracy: 0.8622\n",
            "Epoch 9662/10000\n",
            "225/225 [==============================] - 0s 516us/step - loss: 3.8993 - accuracy: 0.8889\n",
            "Epoch 9663/10000\n",
            "225/225 [==============================] - 0s 514us/step - loss: 3.9128 - accuracy: 0.8267\n",
            "Epoch 9664/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 3.8944 - accuracy: 0.8844\n",
            "Epoch 9665/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9285 - accuracy: 0.8533\n",
            "Epoch 9666/10000\n",
            "225/225 [==============================] - 0s 528us/step - loss: 4.0628 - accuracy: 0.8533\n",
            "Epoch 9667/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9762 - accuracy: 0.8400\n",
            "Epoch 9668/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 4.0257 - accuracy: 0.8622\n",
            "Epoch 9669/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.8618 - accuracy: 0.8667\n",
            "Epoch 9670/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.8928 - accuracy: 0.8844\n",
            "Epoch 9671/10000\n",
            "225/225 [==============================] - 0s 522us/step - loss: 3.9095 - accuracy: 0.8311\n",
            "Epoch 9672/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9758 - accuracy: 0.8444\n",
            "Epoch 9673/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 4.0682 - accuracy: 0.8356\n",
            "Epoch 9674/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.0184 - accuracy: 0.8444\n",
            "Epoch 9675/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9370 - accuracy: 0.8489\n",
            "Epoch 9676/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.7087 - accuracy: 0.8356\n",
            "Epoch 9677/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.8851 - accuracy: 0.8667\n",
            "Epoch 9678/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 3.8790 - accuracy: 0.8356\n",
            "Epoch 9679/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.8503 - accuracy: 0.8667\n",
            "Epoch 9680/10000\n",
            "225/225 [==============================] - 0s 516us/step - loss: 3.9373 - accuracy: 0.8222\n",
            "Epoch 9681/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.8991 - accuracy: 0.8756\n",
            "Epoch 9682/10000\n",
            "225/225 [==============================] - 0s 558us/step - loss: 4.0853 - accuracy: 0.8578\n",
            "Epoch 9683/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 4.0494 - accuracy: 0.8444\n",
            "Epoch 9684/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.6203 - accuracy: 0.8533\n",
            "Epoch 9685/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 4.0103 - accuracy: 0.8533\n",
            "Epoch 9686/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9610 - accuracy: 0.8667\n",
            "Epoch 9687/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.9908 - accuracy: 0.8444\n",
            "Epoch 9688/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9666 - accuracy: 0.8622\n",
            "Epoch 9689/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.6423 - accuracy: 0.8667\n",
            "Epoch 9690/10000\n",
            "225/225 [==============================] - 0s 497us/step - loss: 3.8866 - accuracy: 0.8622\n",
            "Epoch 9691/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.8976 - accuracy: 0.8356\n",
            "Epoch 9692/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.1114 - accuracy: 0.8444\n",
            "Epoch 9693/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 4.0494 - accuracy: 0.8444\n",
            "Epoch 9694/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 4.1398 - accuracy: 0.8311\n",
            "Epoch 9695/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9849 - accuracy: 0.8622\n",
            "Epoch 9696/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.8013 - accuracy: 0.8400\n",
            "Epoch 9697/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 4.0023 - accuracy: 0.8578\n",
            "Epoch 9698/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9532 - accuracy: 0.8578\n",
            "Epoch 9699/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.8195 - accuracy: 0.8311\n",
            "Epoch 9700/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 4.0437 - accuracy: 0.8444\n",
            "Epoch 9701/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.8650 - accuracy: 0.8711\n",
            "Epoch 9702/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9395 - accuracy: 0.8444\n",
            "Epoch 9703/10000\n",
            "225/225 [==============================] - 0s 521us/step - loss: 3.9715 - accuracy: 0.8756\n",
            "Epoch 9704/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0025 - accuracy: 0.8178\n",
            "Epoch 9705/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0635 - accuracy: 0.8667\n",
            "Epoch 9706/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.1114 - accuracy: 0.8533\n",
            "Epoch 9707/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.6510 - accuracy: 0.8444\n",
            "Epoch 9708/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 3.9346 - accuracy: 0.8578\n",
            "Epoch 9709/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.8791 - accuracy: 0.8267\n",
            "Epoch 9710/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.9225 - accuracy: 0.8578\n",
            "Epoch 9711/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.8491 - accuracy: 0.8756\n",
            "Epoch 9712/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 4.0051 - accuracy: 0.8356\n",
            "Epoch 9713/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 4.0029 - accuracy: 0.8711\n",
            "Epoch 9714/10000\n",
            "225/225 [==============================] - 0s 535us/step - loss: 3.9391 - accuracy: 0.8667\n",
            "Epoch 9715/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.4441 - accuracy: 0.8578\n",
            "Epoch 9716/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 4.0980 - accuracy: 0.8356\n",
            "Epoch 9717/10000\n",
            "225/225 [==============================] - 0s 505us/step - loss: 4.0890 - accuracy: 0.8533\n",
            "Epoch 9718/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0226 - accuracy: 0.8578\n",
            "Epoch 9719/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0751 - accuracy: 0.8533\n",
            "Epoch 9720/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.9653 - accuracy: 0.8978\n",
            "Epoch 9721/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.8977 - accuracy: 0.8578\n",
            "Epoch 9722/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9808 - accuracy: 0.8489\n",
            "Epoch 9723/10000\n",
            "225/225 [==============================] - 0s 528us/step - loss: 3.9093 - accuracy: 0.8667\n",
            "Epoch 9724/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.9425 - accuracy: 0.8667\n",
            "Epoch 9725/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0423 - accuracy: 0.8400\n",
            "Epoch 9726/10000\n",
            "225/225 [==============================] - 0s 511us/step - loss: 4.0682 - accuracy: 0.8578\n",
            "Epoch 9727/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9781 - accuracy: 0.8356\n",
            "Epoch 9728/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 4.0787 - accuracy: 0.8578\n",
            "Epoch 9729/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.9162 - accuracy: 0.8889\n",
            "Epoch 9730/10000\n",
            "225/225 [==============================] - 0s 512us/step - loss: 3.9858 - accuracy: 0.8622\n",
            "Epoch 9731/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.8495 - accuracy: 0.9022\n",
            "Epoch 9732/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9899 - accuracy: 0.8578\n",
            "Epoch 9733/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.1181 - accuracy: 0.8400\n",
            "Epoch 9734/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9154 - accuracy: 0.8400\n",
            "Epoch 9735/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9066 - accuracy: 0.8533\n",
            "Epoch 9736/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9029 - accuracy: 0.8933\n",
            "Epoch 9737/10000\n",
            "225/225 [==============================] - 0s 493us/step - loss: 3.9640 - accuracy: 0.8933\n",
            "Epoch 9738/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9309 - accuracy: 0.8533\n",
            "Epoch 9739/10000\n",
            "225/225 [==============================] - 0s 557us/step - loss: 3.9733 - accuracy: 0.8578\n",
            "Epoch 9740/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9459 - accuracy: 0.8622\n",
            "Epoch 9741/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0290 - accuracy: 0.8844\n",
            "Epoch 9742/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9198 - accuracy: 0.8444\n",
            "Epoch 9743/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9536 - accuracy: 0.8578\n",
            "Epoch 9744/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.8449 - accuracy: 0.8400\n",
            "Epoch 9745/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 4.0091 - accuracy: 0.8756\n",
            "Epoch 9746/10000\n",
            "225/225 [==============================] - 0s 499us/step - loss: 3.9407 - accuracy: 0.8489\n",
            "Epoch 9747/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.8213 - accuracy: 0.8489\n",
            "Epoch 9748/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 4.1152 - accuracy: 0.8756\n",
            "Epoch 9749/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8971 - accuracy: 0.8444\n",
            "Epoch 9750/10000\n",
            "225/225 [==============================] - 0s 534us/step - loss: 3.9656 - accuracy: 0.8756\n",
            "Epoch 9751/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9573 - accuracy: 0.8889\n",
            "Epoch 9752/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9097 - accuracy: 0.8667\n",
            "Epoch 9753/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.8949 - accuracy: 0.8711\n",
            "Epoch 9754/10000\n",
            "225/225 [==============================] - 0s 524us/step - loss: 3.8788 - accuracy: 0.8222\n",
            "Epoch 9755/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 3.9149 - accuracy: 0.8578\n",
            "Epoch 9756/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9365 - accuracy: 0.8667\n",
            "Epoch 9757/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9541 - accuracy: 0.8622\n",
            "Epoch 9758/10000\n",
            "225/225 [==============================] - 0s 496us/step - loss: 3.9374 - accuracy: 0.8667\n",
            "Epoch 9759/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.7990 - accuracy: 0.8622\n",
            "Epoch 9760/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.1351 - accuracy: 0.8578\n",
            "Epoch 9761/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 4.1566 - accuracy: 0.8444\n",
            "Epoch 9762/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0091 - accuracy: 0.8578\n",
            "Epoch 9763/10000\n",
            "225/225 [==============================] - 0s 506us/step - loss: 3.8045 - accuracy: 0.8533\n",
            "Epoch 9764/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.9243 - accuracy: 0.8800\n",
            "Epoch 9765/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9489 - accuracy: 0.8711\n",
            "Epoch 9766/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 3.9648 - accuracy: 0.8667\n",
            "Epoch 9767/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.0459 - accuracy: 0.8578\n",
            "Epoch 9768/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0075 - accuracy: 0.8578\n",
            "Epoch 9769/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 3.9270 - accuracy: 0.8578\n",
            "Epoch 9770/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9587 - accuracy: 0.8622\n",
            "Epoch 9771/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.8791 - accuracy: 0.8622\n",
            "Epoch 9772/10000\n",
            "225/225 [==============================] - 0s 517us/step - loss: 3.9567 - accuracy: 0.8444\n",
            "Epoch 9773/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.8963 - accuracy: 0.8356\n",
            "Epoch 9774/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.9486 - accuracy: 0.8800\n",
            "Epoch 9775/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.9978 - accuracy: 0.8622\n",
            "Epoch 9776/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 4.0497 - accuracy: 0.8267\n",
            "Epoch 9777/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.8705 - accuracy: 0.8267\n",
            "Epoch 9778/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.8809 - accuracy: 0.8489\n",
            "Epoch 9779/10000\n",
            "225/225 [==============================] - 0s 515us/step - loss: 3.9469 - accuracy: 0.8933\n",
            "Epoch 9780/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9421 - accuracy: 0.8444\n",
            "Epoch 9781/10000\n",
            "225/225 [==============================] - 0s 519us/step - loss: 4.0204 - accuracy: 0.8400\n",
            "Epoch 9782/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 4.1341 - accuracy: 0.8711\n",
            "Epoch 9783/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.9280 - accuracy: 0.8400\n",
            "Epoch 9784/10000\n",
            "225/225 [==============================] - 0s 517us/step - loss: 3.8987 - accuracy: 0.8711\n",
            "Epoch 9785/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.8995 - accuracy: 0.8489\n",
            "Epoch 9786/10000\n",
            "225/225 [==============================] - 0s 525us/step - loss: 3.9016 - accuracy: 0.8667\n",
            "Epoch 9787/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 4.1719 - accuracy: 0.8356\n",
            "Epoch 9788/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.8601 - accuracy: 0.8444\n",
            "Epoch 9789/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.8858 - accuracy: 0.8622\n",
            "Epoch 9790/10000\n",
            "225/225 [==============================] - 0s 546us/step - loss: 3.9122 - accuracy: 0.8489\n",
            "Epoch 9791/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.9735 - accuracy: 0.8800\n",
            "Epoch 9792/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9693 - accuracy: 0.8622\n",
            "Epoch 9793/10000\n",
            "225/225 [==============================] - 0s 516us/step - loss: 3.9739 - accuracy: 0.8400\n",
            "Epoch 9794/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.9601 - accuracy: 0.8400\n",
            "Epoch 9795/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 4.0202 - accuracy: 0.8622\n",
            "Epoch 9796/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0125 - accuracy: 0.8578\n",
            "Epoch 9797/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.6654 - accuracy: 0.8800\n",
            "Epoch 9798/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.8844 - accuracy: 0.8800\n",
            "Epoch 9799/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.7303 - accuracy: 0.8533\n",
            "Epoch 9800/10000\n",
            "225/225 [==============================] - 0s 509us/step - loss: 3.8781 - accuracy: 0.8622\n",
            "Epoch 9801/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 3.9067 - accuracy: 0.8711\n",
            "Epoch 9802/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9102 - accuracy: 0.8356\n",
            "Epoch 9803/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9414 - accuracy: 0.8667\n",
            "Epoch 9804/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0030 - accuracy: 0.8578\n",
            "Epoch 9805/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 4.0284 - accuracy: 0.8711\n",
            "Epoch 9806/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0907 - accuracy: 0.8578\n",
            "Epoch 9807/10000\n",
            "225/225 [==============================] - 0s 503us/step - loss: 3.9395 - accuracy: 0.8489\n",
            "Epoch 9808/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9029 - accuracy: 0.8622\n",
            "Epoch 9809/10000\n",
            "225/225 [==============================] - 0s 522us/step - loss: 3.9904 - accuracy: 0.8622\n",
            "Epoch 9810/10000\n",
            "225/225 [==============================] - 0s 526us/step - loss: 3.9489 - accuracy: 0.9022\n",
            "Epoch 9811/10000\n",
            "225/225 [==============================] - 0s 532us/step - loss: 3.9476 - accuracy: 0.8356\n",
            "Epoch 9812/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9292 - accuracy: 0.8400\n",
            "Epoch 9813/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9926 - accuracy: 0.8311\n",
            "Epoch 9814/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.8563 - accuracy: 0.8444\n",
            "Epoch 9815/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9562 - accuracy: 0.8889\n",
            "Epoch 9816/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9675 - accuracy: 0.8578\n",
            "Epoch 9817/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.9496 - accuracy: 0.8489\n",
            "Epoch 9818/10000\n",
            "225/225 [==============================] - 0s 497us/step - loss: 3.9057 - accuracy: 0.8444\n",
            "Epoch 9819/10000\n",
            "225/225 [==============================] - 0s 479us/step - loss: 3.9554 - accuracy: 0.8578\n",
            "Epoch 9820/10000\n",
            "225/225 [==============================] - 0s 450us/step - loss: 3.6771 - accuracy: 0.8622\n",
            "Epoch 9821/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0574 - accuracy: 0.8356\n",
            "Epoch 9822/10000\n",
            "225/225 [==============================] - 0s 449us/step - loss: 4.1016 - accuracy: 0.8800\n",
            "Epoch 9823/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 3.9434 - accuracy: 0.8622\n",
            "Epoch 9824/10000\n",
            "225/225 [==============================] - 0s 445us/step - loss: 4.0051 - accuracy: 0.8356\n",
            "Epoch 9825/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.7612 - accuracy: 0.8844\n",
            "Epoch 9826/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9361 - accuracy: 0.8533\n",
            "Epoch 9827/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9857 - accuracy: 0.8444\n",
            "Epoch 9828/10000\n",
            "225/225 [==============================] - 0s 488us/step - loss: 4.0187 - accuracy: 0.8267\n",
            "Epoch 9829/10000\n",
            "225/225 [==============================] - 0s 491us/step - loss: 3.8486 - accuracy: 0.8533\n",
            "Epoch 9830/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.8757 - accuracy: 0.8578\n",
            "Epoch 9831/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9265 - accuracy: 0.8578\n",
            "Epoch 9832/10000\n",
            "225/225 [==============================] - 0s 520us/step - loss: 3.9490 - accuracy: 0.8444\n",
            "Epoch 9833/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9999 - accuracy: 0.8622\n",
            "Epoch 9834/10000\n",
            "225/225 [==============================] - 0s 558us/step - loss: 4.0160 - accuracy: 0.8533\n",
            "Epoch 9835/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.2413 - accuracy: 0.8489\n",
            "Epoch 9836/10000\n",
            "225/225 [==============================] - 0s 492us/step - loss: 3.9625 - accuracy: 0.8489\n",
            "Epoch 9837/10000\n",
            "225/225 [==============================] - 0s 539us/step - loss: 3.8967 - accuracy: 0.8000\n",
            "Epoch 9838/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.8975 - accuracy: 0.8578\n",
            "Epoch 9839/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.8676 - accuracy: 0.8489\n",
            "Epoch 9840/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9397 - accuracy: 0.8844\n",
            "Epoch 9841/10000\n",
            "225/225 [==============================] - 0s 451us/step - loss: 3.8942 - accuracy: 0.8489\n",
            "Epoch 9842/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 4.0344 - accuracy: 0.8489\n",
            "Epoch 9843/10000\n",
            "225/225 [==============================] - 0s 448us/step - loss: 3.8952 - accuracy: 0.8578\n",
            "Epoch 9844/10000\n",
            "225/225 [==============================] - 0s 452us/step - loss: 3.8870 - accuracy: 0.8756\n",
            "Epoch 9845/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.9249 - accuracy: 0.8667\n",
            "Epoch 9846/10000\n",
            "225/225 [==============================] - 0s 541us/step - loss: 3.6783 - accuracy: 0.8311\n",
            "Epoch 9847/10000\n",
            "225/225 [==============================] - 0s 540us/step - loss: 3.7871 - accuracy: 0.8311\n",
            "Epoch 9848/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9043 - accuracy: 0.8578\n",
            "Epoch 9849/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.8948 - accuracy: 0.8444\n",
            "Epoch 9850/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0489 - accuracy: 0.8578\n",
            "Epoch 9851/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9625 - accuracy: 0.8489\n",
            "Epoch 9852/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9322 - accuracy: 0.8933\n",
            "Epoch 9853/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9049 - accuracy: 0.8578\n",
            "Epoch 9854/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 4.0123 - accuracy: 0.8444\n",
            "Epoch 9855/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9862 - accuracy: 0.8400\n",
            "Epoch 9856/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 4.0488 - accuracy: 0.8667\n",
            "Epoch 9857/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 4.1496 - accuracy: 0.8489\n",
            "Epoch 9858/10000\n",
            "225/225 [==============================] - 0s 487us/step - loss: 3.7381 - accuracy: 0.8667\n",
            "Epoch 9859/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9260 - accuracy: 0.8622\n",
            "Epoch 9860/10000\n",
            "225/225 [==============================] - 0s 490us/step - loss: 3.9244 - accuracy: 0.8444\n",
            "Epoch 9861/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 4.0253 - accuracy: 0.8622\n",
            "Epoch 9862/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 4.1895 - accuracy: 0.8489\n",
            "Epoch 9863/10000\n",
            "225/225 [==============================] - 0s 536us/step - loss: 3.9411 - accuracy: 0.8311\n",
            "Epoch 9864/10000\n",
            "225/225 [==============================] - 0s 513us/step - loss: 3.9312 - accuracy: 0.8489\n",
            "Epoch 9865/10000\n",
            "225/225 [==============================] - 0s 512us/step - loss: 4.0403 - accuracy: 0.8533\n",
            "Epoch 9866/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.8918 - accuracy: 0.8844\n",
            "Epoch 9867/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0617 - accuracy: 0.8667\n",
            "Epoch 9868/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0422 - accuracy: 0.8400\n",
            "Epoch 9869/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0260 - accuracy: 0.8400\n",
            "Epoch 9870/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 3.7813 - accuracy: 0.8622\n",
            "Epoch 9871/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 3.9709 - accuracy: 0.8444\n",
            "Epoch 9872/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.0617 - accuracy: 0.8489\n",
            "Epoch 9873/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.8420 - accuracy: 0.8444\n",
            "Epoch 9874/10000\n",
            "225/225 [==============================] - 0s 489us/step - loss: 3.9903 - accuracy: 0.8667\n",
            "Epoch 9875/10000\n",
            "225/225 [==============================] - 0s 453us/step - loss: 3.9770 - accuracy: 0.8800\n",
            "Epoch 9876/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9911 - accuracy: 0.8711\n",
            "Epoch 9877/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9553 - accuracy: 0.8622\n",
            "Epoch 9878/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0237 - accuracy: 0.8533\n",
            "Epoch 9879/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 4.0638 - accuracy: 0.8444\n",
            "Epoch 9880/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9817 - accuracy: 0.8578\n",
            "Epoch 9881/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.8857 - accuracy: 0.8844\n",
            "Epoch 9882/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 4.0169 - accuracy: 0.8578\n",
            "Epoch 9883/10000\n",
            "225/225 [==============================] - 0s 535us/step - loss: 3.8283 - accuracy: 0.8711\n",
            "Epoch 9884/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.8908 - accuracy: 0.8267\n",
            "Epoch 9885/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.9739 - accuracy: 0.8489\n",
            "Epoch 9886/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9636 - accuracy: 0.8578\n",
            "Epoch 9887/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 4.0568 - accuracy: 0.8444\n",
            "Epoch 9888/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9363 - accuracy: 0.8667\n",
            "Epoch 9889/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9063 - accuracy: 0.8533\n",
            "Epoch 9890/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 4.0870 - accuracy: 0.8444\n",
            "Epoch 9891/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9373 - accuracy: 0.8444\n",
            "Epoch 9892/10000\n",
            "225/225 [==============================] - 0s 484us/step - loss: 3.9796 - accuracy: 0.8667\n",
            "Epoch 9893/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.8535 - accuracy: 0.8489\n",
            "Epoch 9894/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.8000 - accuracy: 0.8800\n",
            "Epoch 9895/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9430 - accuracy: 0.8711\n",
            "Epoch 9896/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.0482 - accuracy: 0.8400\n",
            "Epoch 9897/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9338 - accuracy: 0.8622\n",
            "Epoch 9898/10000\n",
            "225/225 [==============================] - 0s 497us/step - loss: 3.9836 - accuracy: 0.8400\n",
            "Epoch 9899/10000\n",
            "225/225 [==============================] - 0s 531us/step - loss: 3.6869 - accuracy: 0.8756\n",
            "Epoch 9900/10000\n",
            "225/225 [==============================] - 0s 472us/step - loss: 3.9814 - accuracy: 0.8578\n",
            "Epoch 9901/10000\n",
            "225/225 [==============================] - 0s 507us/step - loss: 3.8957 - accuracy: 0.8578\n",
            "Epoch 9902/10000\n",
            "225/225 [==============================] - 0s 504us/step - loss: 3.9208 - accuracy: 0.8622\n",
            "Epoch 9903/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9467 - accuracy: 0.8756\n",
            "Epoch 9904/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.8886 - accuracy: 0.8489\n",
            "Epoch 9905/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9403 - accuracy: 0.8444\n",
            "Epoch 9906/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.8024 - accuracy: 0.8489\n",
            "Epoch 9907/10000\n",
            "225/225 [==============================] - 0s 471us/step - loss: 3.6586 - accuracy: 0.8533\n",
            "Epoch 9908/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.0280 - accuracy: 0.8578\n",
            "Epoch 9909/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 4.0228 - accuracy: 0.8711\n",
            "Epoch 9910/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9097 - accuracy: 0.8756\n",
            "Epoch 9911/10000\n",
            "225/225 [==============================] - 0s 535us/step - loss: 3.9125 - accuracy: 0.8400\n",
            "Epoch 9912/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.9433 - accuracy: 0.8533\n",
            "Epoch 9913/10000\n",
            "225/225 [==============================] - 0s 451us/step - loss: 3.9243 - accuracy: 0.8711\n",
            "Epoch 9914/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9070 - accuracy: 0.8356\n",
            "Epoch 9915/10000\n",
            "225/225 [==============================] - 0s 451us/step - loss: 3.8394 - accuracy: 0.8756\n",
            "Epoch 9916/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.8946 - accuracy: 0.8800\n",
            "Epoch 9917/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.8576 - accuracy: 0.8622\n",
            "Epoch 9918/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9439 - accuracy: 0.8133\n",
            "Epoch 9919/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0864 - accuracy: 0.8933\n",
            "Epoch 9920/10000\n",
            "225/225 [==============================] - 0s 518us/step - loss: 3.9305 - accuracy: 0.8844\n",
            "Epoch 9921/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.9655 - accuracy: 0.8578\n",
            "Epoch 9922/10000\n",
            "225/225 [==============================] - 0s 462us/step - loss: 3.8323 - accuracy: 0.8489\n",
            "Epoch 9923/10000\n",
            "225/225 [==============================] - 0s 562us/step - loss: 3.9124 - accuracy: 0.8622\n",
            "Epoch 9924/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0906 - accuracy: 0.8667\n",
            "Epoch 9925/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.7896 - accuracy: 0.8533\n",
            "Epoch 9926/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 4.0352 - accuracy: 0.8622\n",
            "Epoch 9927/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9526 - accuracy: 0.8222\n",
            "Epoch 9928/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 4.2271 - accuracy: 0.8444\n",
            "Epoch 9929/10000\n",
            "225/225 [==============================] - 0s 526us/step - loss: 3.8408 - accuracy: 0.8578\n",
            "Epoch 9930/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.8677 - accuracy: 0.8667\n",
            "Epoch 9931/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.8884 - accuracy: 0.8356\n",
            "Epoch 9932/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.7595 - accuracy: 0.8667\n",
            "Epoch 9933/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 3.9109 - accuracy: 0.8667\n",
            "Epoch 9934/10000\n",
            "225/225 [==============================] - 0s 467us/step - loss: 3.9482 - accuracy: 0.8311\n",
            "Epoch 9935/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 4.0566 - accuracy: 0.8622\n",
            "Epoch 9936/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.7298 - accuracy: 0.8533\n",
            "Epoch 9937/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.9116 - accuracy: 0.8711\n",
            "Epoch 9938/10000\n",
            "225/225 [==============================] - 0s 574us/step - loss: 3.9419 - accuracy: 0.8267\n",
            "Epoch 9939/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9489 - accuracy: 0.8667\n",
            "Epoch 9940/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0128 - accuracy: 0.8578\n",
            "Epoch 9941/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.0159 - accuracy: 0.8533\n",
            "Epoch 9942/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 4.1131 - accuracy: 0.8533\n",
            "Epoch 9943/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9861 - accuracy: 0.8489\n",
            "Epoch 9944/10000\n",
            "225/225 [==============================] - 0s 483us/step - loss: 3.9001 - accuracy: 0.8356\n",
            "Epoch 9945/10000\n",
            "225/225 [==============================] - 0s 460us/step - loss: 3.8298 - accuracy: 0.8844\n",
            "Epoch 9946/10000\n",
            "225/225 [==============================] - 0s 450us/step - loss: 3.9479 - accuracy: 0.8533\n",
            "Epoch 9947/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.5897 - accuracy: 0.8489\n",
            "Epoch 9948/10000\n",
            "225/225 [==============================] - 0s 532us/step - loss: 3.8973 - accuracy: 0.8711\n",
            "Epoch 9949/10000\n",
            "225/225 [==============================] - 0s 482us/step - loss: 3.8783 - accuracy: 0.8578\n",
            "Epoch 9950/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.9692 - accuracy: 0.8311\n",
            "Epoch 9951/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9251 - accuracy: 0.8444\n",
            "Epoch 9952/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.1132 - accuracy: 0.8489\n",
            "Epoch 9953/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9126 - accuracy: 0.8578\n",
            "Epoch 9954/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 3.9098 - accuracy: 0.8444\n",
            "Epoch 9955/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.9721 - accuracy: 0.8711\n",
            "Epoch 9956/10000\n",
            "225/225 [==============================] - 0s 476us/step - loss: 4.0442 - accuracy: 0.8400\n",
            "Epoch 9957/10000\n",
            "225/225 [==============================] - 0s 500us/step - loss: 3.9598 - accuracy: 0.8489\n",
            "Epoch 9958/10000\n",
            "225/225 [==============================] - 0s 477us/step - loss: 3.8408 - accuracy: 0.8444\n",
            "Epoch 9959/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 4.0789 - accuracy: 0.8578\n",
            "Epoch 9960/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9791 - accuracy: 0.8311\n",
            "Epoch 9961/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9142 - accuracy: 0.8400\n",
            "Epoch 9962/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.9095 - accuracy: 0.8489\n",
            "Epoch 9963/10000\n",
            "225/225 [==============================] - 0s 464us/step - loss: 3.7207 - accuracy: 0.8533\n",
            "Epoch 9964/10000\n",
            "225/225 [==============================] - 0s 469us/step - loss: 3.9228 - accuracy: 0.8578\n",
            "Epoch 9965/10000\n",
            "225/225 [==============================] - 0s 451us/step - loss: 3.9262 - accuracy: 0.8444\n",
            "Epoch 9966/10000\n",
            "225/225 [==============================] - 0s 497us/step - loss: 3.9645 - accuracy: 0.8667\n",
            "Epoch 9967/10000\n",
            "225/225 [==============================] - 0s 475us/step - loss: 3.9794 - accuracy: 0.8622\n",
            "Epoch 9968/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.9294 - accuracy: 0.8578\n",
            "Epoch 9969/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9829 - accuracy: 0.8622\n",
            "Epoch 9970/10000\n",
            "225/225 [==============================] - 0s 458us/step - loss: 3.9302 - accuracy: 0.8489\n",
            "Epoch 9971/10000\n",
            "225/225 [==============================] - 0s 478us/step - loss: 3.9768 - accuracy: 0.8756\n",
            "Epoch 9972/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 4.0308 - accuracy: 0.8267\n",
            "Epoch 9973/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 3.9450 - accuracy: 0.8533\n",
            "Epoch 9974/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 4.0525 - accuracy: 0.8711\n",
            "Epoch 9975/10000\n",
            "225/225 [==============================] - 0s 461us/step - loss: 4.1214 - accuracy: 0.8444\n",
            "Epoch 9976/10000\n",
            "225/225 [==============================] - 0s 534us/step - loss: 3.9809 - accuracy: 0.8667\n",
            "Epoch 9977/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.8600 - accuracy: 0.8756\n",
            "Epoch 9978/10000\n",
            "225/225 [==============================] - 0s 527us/step - loss: 4.0084 - accuracy: 0.8667\n",
            "Epoch 9979/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.9189 - accuracy: 0.8533\n",
            "Epoch 9980/10000\n",
            "225/225 [==============================] - 0s 474us/step - loss: 4.0266 - accuracy: 0.8533\n",
            "Epoch 9981/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.5902 - accuracy: 0.8533\n",
            "Epoch 9982/10000\n",
            "225/225 [==============================] - 0s 465us/step - loss: 3.9258 - accuracy: 0.8578\n",
            "Epoch 9983/10000\n",
            "225/225 [==============================] - 0s 473us/step - loss: 3.6041 - accuracy: 0.8622\n",
            "Epoch 9984/10000\n",
            "225/225 [==============================] - 0s 459us/step - loss: 4.0041 - accuracy: 0.8444\n",
            "Epoch 9985/10000\n",
            "225/225 [==============================] - 0s 538us/step - loss: 3.9816 - accuracy: 0.8622\n",
            "Epoch 9986/10000\n",
            "225/225 [==============================] - 0s 481us/step - loss: 3.9092 - accuracy: 0.8711\n",
            "Epoch 9987/10000\n",
            "225/225 [==============================] - 0s 456us/step - loss: 3.9557 - accuracy: 0.8444\n",
            "Epoch 9988/10000\n",
            "225/225 [==============================] - 0s 457us/step - loss: 3.9840 - accuracy: 0.8578\n",
            "Epoch 9989/10000\n",
            "225/225 [==============================] - 0s 455us/step - loss: 3.8912 - accuracy: 0.8756\n",
            "Epoch 9990/10000\n",
            "225/225 [==============================] - 0s 470us/step - loss: 3.9245 - accuracy: 0.8400\n",
            "Epoch 9991/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.9543 - accuracy: 0.8711\n",
            "Epoch 9992/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.1153 - accuracy: 0.8711\n",
            "Epoch 9993/10000\n",
            "225/225 [==============================] - 0s 480us/step - loss: 3.9381 - accuracy: 0.8667\n",
            "Epoch 9994/10000\n",
            "225/225 [==============================] - 0s 523us/step - loss: 3.9145 - accuracy: 0.8444\n",
            "Epoch 9995/10000\n",
            "225/225 [==============================] - 0s 466us/step - loss: 4.0692 - accuracy: 0.8800\n",
            "Epoch 9996/10000\n",
            "225/225 [==============================] - 0s 468us/step - loss: 3.7988 - accuracy: 0.8533\n",
            "Epoch 9997/10000\n",
            "225/225 [==============================] - 0s 454us/step - loss: 3.8272 - accuracy: 0.8400\n",
            "Epoch 9998/10000\n",
            "225/225 [==============================] - 0s 463us/step - loss: 3.9510 - accuracy: 0.8489\n",
            "Epoch 9999/10000\n",
            "225/225 [==============================] - 0s 495us/step - loss: 4.0463 - accuracy: 0.8489\n",
            "Epoch 10000/10000\n",
            "225/225 [==============================] - 0s 486us/step - loss: 3.9340 - accuracy: 0.8889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f3d100539e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlRywsLRNaH0",
        "colab_type": "code",
        "outputId": "0cf70d4a-593d-481a-9dc9-1f09cc32ce93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "import random\n",
        "\n",
        "group_kfold = GroupKFold(n_splits=15)\n",
        "group_kfold.get_n_splits(data2, classes)\n",
        "gkf = list(group_kfold.split(data2, classes, database[database.columns[0]]))\n",
        "estimator = KerasRegressor(build_fn=baseline_model, epochs=500, batch_size=10, verbose=0, callbacks=callbacks_list)\n",
        "outcomes = []\n",
        "# fold = 0\n",
        "seed = 7\n",
        "best = []\n",
        "\n",
        "for i in range(1000):\n",
        "  mid_outcomes = []\n",
        "  print(\"Iteration: \" + str(i))\n",
        "  random.shuffle(gkf)\n",
        "  fold =0\n",
        "  for train_index, test_index in gkf:\n",
        "    fold += 1 \n",
        "    X_train, X_test = scalar.fit_transform(data2.values[train_index]), scalar.fit_transform(data2.values[test_index])\n",
        "    y_train, y_test = classes.values[train_index], classes.values[test_index]\n",
        "#         clf.fit(X_train, y_train)\n",
        "    estimator.fit(X_train, y_train)\n",
        "    predictions = estimator.predict(X_test)\n",
        "#         accuracy = accuracy_score(y_test, predictions)\n",
        "    accuracy = np.mean(np.sqrt((predictions - y_test) ** 2))\n",
        "    \n",
        "#     precent = sum(np.sqrt((predictions - y_test) ** 2) > 1) / sum(np.sqrt((predictions - y_test) ** 2)) * 100\n",
        "    precent = loss2(predictions, y_test, 0.5)\n",
        "    accuracy = loss2(predictions, y_test, 1)\n",
        "    if accuracy > 80:\n",
        "      best.append((train_index, test_index))\n",
        "    # outcomes.append(accuracy)\n",
        "    print(\"Fold {0} accuracy: {1} above 1 error precent: {2}\".format(fold, accuracy, precent))\n",
        "    mid_outcomes.append(accuracy)\n",
        "  outcomes.append(np.mean(mid_outcomes))\n",
        "  print(predictions)\n",
        "#     break\n",
        "mean_outcome = np.mean(outcomes)\n",
        "print(\"Mean Accuracy: {0}\".format(mean_outcome)) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-8a9e76df9c21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#         clf.fit(X_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         accuracy = accuracy_score(y_test, predictions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_best_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab6Yb0P_QZEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.shuffle(gkf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MlTN8TLw-Y-",
        "colab_type": "code",
        "outputId": "8ebb8c9b-015d-41a9-e8fa-a4f6d6b857c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.23151286, -0.15404112, -0.11945799, ..., -0.80491643,\n",
              "        -0.46151267, -0.89143811],\n",
              "       [ 0.04977536, -0.15415687, -0.14387222, ..., -0.80296615,\n",
              "        -0.52736392,  1.65512753],\n",
              "       [-0.09574923, -0.13952304, -0.13166142, ..., -1.28662487,\n",
              "         0.04214682,  0.0168052 ],\n",
              "       ...,\n",
              "       [-0.13267029, -0.10616259, -0.10155903, ..., -1.64480515,\n",
              "        -0.06975462,  0.6323478 ],\n",
              "       [-0.08913987, -0.13320756, -0.11785971, ..., -0.95762538,\n",
              "        -0.37312782,  2.5265282 ],\n",
              "       [-0.21517457, -0.15559052, -0.12182597, ..., -1.034588  ,\n",
              "        -0.88065114,  1.64456259]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aldq-P4W0bst",
        "colab_type": "code",
        "outputId": "0223ed9d-26c5-4495-bb79-3e2395e05b46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gkf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 28, 101, 146, 207])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "          52,  53,  54,  55,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
              "         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
              "         131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
              "         171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
              "         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224]), array([ 56, 134, 194])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 21,  81, 127, 187])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  60,  61,  62,  63,  64,  65,  66,\n",
              "          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224]),\n",
              "  array([ 27,  59, 161, 222])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224]), array([ 89, 110, 126])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 19,  79, 139, 185])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 42, 103, 148, 209])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   7,   8,   9,  10,  11,  12,  13,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([  6,  66, 140, 172])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
              "         171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
              "         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
              "         197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224]), array([ 33,  94, 200])),\n",
              " (array([  0,   1,   2,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  64,  65,  66,\n",
              "          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([  3,  63, 165, 195])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  13,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 12,  73, 119, 179])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119,\n",
              "         120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 26,  72, 118, 178])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  46,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 47, 108, 141, 214])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224]), array([ 29,  90, 167])),\n",
              " (array([  0,   1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  63,  64,  65,  66,\n",
              "          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([  2,  62, 164, 196])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 45, 106, 151, 212])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,  10,  11,  12,  13,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119,\n",
              "         120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([  9,  69, 115, 175])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 38,  99, 144, 205])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 51,  83, 157, 218])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 184, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 17,  77, 123, 183])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  61,  62,  63,  64,  65,  66,\n",
              "          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 25,  60, 162, 211])),\n",
              " (array([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  62,  63,  64,  65,  66,\n",
              "          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([  1,  61, 163, 197])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 44, 105, 150, 210])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 37,  97, 143, 204])),\n",
              " (array([  0,   1,   2,   3,   4,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  66,\n",
              "          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 172,\n",
              "         173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([  5,  65, 166, 171])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "          52,  53,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
              "         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
              "         131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
              "         171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
              "         184, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224]), array([ 54, 132, 192])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 40, 102, 147, 208])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
              "         171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
              "         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
              "         197, 198, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224]), array([ 32,  93, 199])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
              "         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
              "         171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
              "         184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223]),\n",
              "  array([ 23, 129, 189, 224])),\n",
              " (array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  36,  37,  38,  39,  40,\n",
              "          41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,\n",
              "          54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
              "          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
              "         107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n",
              "         120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([  0,  35,  96, 202])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119,\n",
              "         120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 10,  70, 116, 176])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 43, 104, 149, 198])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 16,  76, 122, 182])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 14,  74, 120, 180])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224]), array([ 88, 112, 137])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
              "         171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
              "         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
              "         197, 198, 199, 200, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224]), array([ 34,  95, 201])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
              "          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 221, 222, 223, 224]),\n",
              "  array([ 41,  57, 159, 220])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "          52,  53,  54,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
              "         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
              "         131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
              "         171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
              "         184, 185, 186, 187, 188, 189, 190, 191, 192, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224]), array([ 55, 133, 193])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   9,  10,  11,  12,  13,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119,\n",
              "         120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([  8,  68, 114, 174])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "          78,  79,  80,  81,  82,  83,  84,  85,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224]), array([ 86, 113, 135])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 20,  80, 125, 186])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 39, 100, 145, 206])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224]), array([ 31,  92, 169])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
              "         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
              "         171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
              "         184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224]), array([ 24, 130, 190])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 18,  78, 124, 184])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 15,  75, 121, 181])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
              "         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
              "         171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
              "         184, 185, 186, 187, 188, 189, 190, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224]), array([ 13, 131, 191])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 36,  85, 142, 203])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
              "         224]), array([ 30,  91, 168])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "          78,  79,  80,  81,  82,  83,  84,  85,  86,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
              "         118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
              "         131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
              "         171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
              "         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
              "         197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
              "         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
              "         224]), array([ 87, 136, 223])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   8,   9,  10,  11,  12,  13,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([  7,  67, 138, 173])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 46, 107, 152, 213])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  46,  47,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 48, 109, 153, 215])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "          52,  54,  55,  56,  57,  59,  60,  61,  62,  63,  64,  65,  66,\n",
              "          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         158, 159, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 222, 223, 224]),\n",
              "  array([ 53,  58, 160, 221])),\n",
              " (array([  0,   1,   2,   3,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  65,  66,\n",
              "          67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172,\n",
              "         173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([  4,  64, 154, 170])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222, 223, 224]),\n",
              "  array([ 52,  82, 158, 219])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
              "         105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 22, 111, 128, 188])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "          92,  93,  94,  95,  96,  97,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 49,  98, 155, 216])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  12,  13,\n",
              "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "          27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "          40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  72,  73,  74,  75,  76,  77,  78,  79,\n",
              "          80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119,\n",
              "         120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
              "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "         146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185,\n",
              "         186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
              "         199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
              "         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 11,  71, 117, 177])),\n",
              " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  51,  52,\n",
              "          53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "          66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "          79,  80,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,  92,\n",
              "          93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
              "         106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
              "         119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
              "         132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
              "         145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158,\n",
              "         159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
              "         172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
              "         185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
              "         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
              "         211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224]),\n",
              "  array([ 50,  84, 156, 217]))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-ArXkXqPtaM",
        "colab_type": "code",
        "outputId": "d45518df-9fe2-4f2d-fa63-cb263b856028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "estimator.model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f0fe1658550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrRkIO1l_ins",
        "colab_type": "code",
        "outputId": "5722ae48-6f62-492b-d14b-a524a675b8cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "|data2.values[train_index].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(202, 2910)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZNCl9uh_yUG",
        "colab_type": "code",
        "outputId": "acd9064b-9567-4438-df59-39e543aabbfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(225, 2910)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXLFVvJA_1aJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = baseline_model()\n",
        "inp = model.input                                           # input placeholder\n",
        "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
        "functors = [K.function([inp, K.learning_phase()], [out]) for out in outputs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYt42m_C52eC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.learning_phase?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXH98kmI6bbv",
        "colab_type": "code",
        "outputId": "e1d13d9f-990c-4f20-f0c8-34274dea614c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "K.learning_phase()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'learning_phase:0' shape=() dtype=int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab5n5Z5F6obi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.function??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNWAJGed6wQ2",
        "colab_type": "code",
        "outputId": "c5355211-2df3-4690-b6eb-7de056a8ac06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2910,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBMEyzhi7C9N",
        "colab_type": "code",
        "outputId": "a019be76-9091-4c7d-b258-1cb044e64e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "layer_outs = [func([X_train[0], K.learning_phase()]) for func in functors]\n",
        "print(layer_outs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "_SymbolicException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: An op outside of the function building code is being passed\na \"Graph\" tensor. It is possible to have Graph tensors\nleak out of the function building context by including a\ntf.init_scope in your function building code.\nFor example, the following function will fail:\n  @tf.function\n  def has_init_scope():\n    my_constant = tf.constant(1.)\n    with tf.init_scope():\n      added = my_constant * 2\nThe graph tensor has name: learning_phase:0",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31m_SymbolicException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-da299ef8f271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunctors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-da299ef8f271>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunctors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     72\u001b[0m       raise core._SymbolicException(\n\u001b[1;32m     73\u001b[0m           \u001b[0;34m\"Inputs to eager execution function cannot be Keras symbolic \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m           \"tensors, but found {}\".format(keras_symbolic_tensors))\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_SymbolicException\u001b[0m: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'learning_phase:0' shape=() dtype=int32>]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_5g8coK7oN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = estimator.model\n",
        "inp = model.input                                           # input placeholder\n",
        "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
        "functors = [K.function([inp], [out]) for out in outputs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuZiGNgcIYO_",
        "colab_type": "code",
        "outputId": "3e2544d1-708c-459e-8b83-a635c156b4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "layer_outs = [func([X_train]) for func in functors]\n",
        "print(layer_outs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[array([[0.        , 0.        , 5.2434616 , ..., 0.        , 0.20762572,\n",
            "        0.        ],\n",
            "       [2.2706046 , 3.7941692 , 0.3229487 , ..., 0.        , 1.4527415 ,\n",
            "        0.        ],\n",
            "       [1.0201445 , 0.        , 0.        , ..., 4.6925626 , 0.        ,\n",
            "        2.3362944 ],\n",
            "       ...,\n",
            "       [2.0308568 , 0.24314162, 5.6879554 , ..., 0.        , 2.93006   ,\n",
            "        0.        ],\n",
            "       [2.5652559 , 0.15287124, 2.5245836 , ..., 4.941967  , 2.6387713 ,\n",
            "        1.9576228 ],\n",
            "       [3.6854773 , 2.2450893 , 1.0256157 , ..., 0.        , 3.5285814 ,\n",
            "        0.6602014 ]], dtype=float32)], [array([[0.        , 0.        , 5.2434616 , ..., 0.        , 0.20762572,\n",
            "        0.        ],\n",
            "       [2.2706046 , 3.7941692 , 0.3229487 , ..., 0.        , 1.4527415 ,\n",
            "        0.        ],\n",
            "       [1.0201445 , 0.        , 0.        , ..., 4.6925626 , 0.        ,\n",
            "        2.3362944 ],\n",
            "       ...,\n",
            "       [2.0308568 , 0.24314162, 5.6879554 , ..., 0.        , 2.93006   ,\n",
            "        0.        ],\n",
            "       [2.5652559 , 0.15287124, 2.5245836 , ..., 4.941967  , 2.6387713 ,\n",
            "        1.9576228 ],\n",
            "       [3.6854773 , 2.2450893 , 1.0256157 , ..., 0.        , 3.5285814 ,\n",
            "        0.6602014 ]], dtype=float32)], [array([[-5.3535414 ,  0.07750207,  3.3867218 , ...,  2.131989  ,\n",
            "        -1.616444  ,  0.7195291 ],\n",
            "       [-6.479529  , -4.6681204 ,  6.0957417 , ...,  4.3385477 ,\n",
            "         4.2517023 ,  3.4883637 ],\n",
            "       [-2.4952466 , -3.1534705 , -2.9232178 , ..., -2.0811436 ,\n",
            "        -8.096555  ,  6.899313  ],\n",
            "       ...,\n",
            "       [-4.9292483 , -1.0958564 , -1.7194862 , ..., -3.9489725 ,\n",
            "         1.0717517 ,  5.2994742 ],\n",
            "       [-2.6858752 , -1.8902322 ,  2.124678  , ..., -1.3712846 ,\n",
            "        -4.0580354 , 10.995856  ],\n",
            "       [ 1.7327678 , -3.362638  ,  4.2773643 , ...,  3.172166  ,\n",
            "         0.32745686,  3.703421  ]], dtype=float32)], [array([[ 5.7618537 ,  0.        ,  0.        , ...,  6.472198  ,\n",
            "         0.        ,  0.        ],\n",
            "       [ 1.1087117 ,  0.        ,  0.        , ..., 15.662842  ,\n",
            "         0.        ,  0.        ],\n",
            "       [ 2.1257062 ,  2.1742668 ,  0.        , ...,  4.1727066 ,\n",
            "         1.8766366 ,  0.        ],\n",
            "       ...,\n",
            "       [ 0.21155255,  0.        ,  0.        , ...,  4.8006372 ,\n",
            "         0.97153026,  0.        ],\n",
            "       [ 1.8085008 ,  1.1038818 ,  0.        , ...,  9.171795  ,\n",
            "         0.60626495,  0.        ],\n",
            "       [ 7.357421  ,  4.459433  ,  3.0803401 , ..., 11.800079  ,\n",
            "         0.        ,  0.        ]], dtype=float32)], [array([[ 5.7618537 ,  0.        ,  0.        , ...,  6.472198  ,\n",
            "         0.        ,  0.        ],\n",
            "       [ 1.1087117 ,  0.        ,  0.        , ..., 15.662842  ,\n",
            "         0.        ,  0.        ],\n",
            "       [ 2.1257062 ,  2.1742668 ,  0.        , ...,  4.1727066 ,\n",
            "         1.8766366 ,  0.        ],\n",
            "       ...,\n",
            "       [ 0.21155255,  0.        ,  0.        , ...,  4.8006372 ,\n",
            "         0.97153026,  0.        ],\n",
            "       [ 1.8085008 ,  1.1038818 ,  0.        , ...,  9.171795  ,\n",
            "         0.60626495,  0.        ],\n",
            "       [ 7.357421  ,  4.459433  ,  3.0803401 , ..., 11.800079  ,\n",
            "         0.        ,  0.        ]], dtype=float32)], [array([[-0.95057046,  0.34115434, -1.2885138 , ..., -0.88088393,\n",
            "         2.9543476 , -0.4851245 ],\n",
            "       [-0.16725072, -1.2127255 , -2.132037  , ..., -1.1568485 ,\n",
            "         4.0159187 , -0.06550275],\n",
            "       [-0.77544904, -1.0894989 , -1.7267302 , ..., -2.3175998 ,\n",
            "         2.6555452 , -0.09569918],\n",
            "       ...,\n",
            "       [ 0.21919733, -1.4077983 , -0.72074854, ..., -3.6943905 ,\n",
            "         2.8951626 ,  0.5291643 ],\n",
            "       [ 0.5445674 , -1.7901267 , -1.3915409 , ..., -1.2818866 ,\n",
            "         2.697516  ,  0.24582852],\n",
            "       [-1.7302846 , -0.6537779 , -1.6027498 , ...,  1.5541537 ,\n",
            "         1.9486861 ,  3.2701972 ]], dtype=float32)], [array([[0.19739805, 0.        , 0.        , ..., 0.39172617, 0.        ,\n",
            "        0.        ],\n",
            "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
            "        0.        ],\n",
            "       [0.5955616 , 0.        , 0.22714189, ..., 0.        , 0.53637975,\n",
            "        0.        ],\n",
            "       ...,\n",
            "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
            "        0.        ],\n",
            "       [0.41548258, 0.        , 0.        , ..., 0.09637257, 0.        ,\n",
            "        0.        ],\n",
            "       [0.        , 0.        , 0.        , ..., 1.8935256 , 0.        ,\n",
            "        0.        ]], dtype=float32)], [array([[0.19739805, 0.        , 0.        , ..., 0.39172617, 0.        ,\n",
            "        0.        ],\n",
            "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
            "        0.        ],\n",
            "       [0.5955616 , 0.        , 0.22714189, ..., 0.        , 0.53637975,\n",
            "        0.        ],\n",
            "       ...,\n",
            "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
            "        0.        ],\n",
            "       [0.41548258, 0.        , 0.        , ..., 0.09637257, 0.        ,\n",
            "        0.        ],\n",
            "       [0.        , 0.        , 0.        , ..., 1.8935256 , 0.        ,\n",
            "        0.        ]], dtype=float32)], [array([[5.1878023, 5.581377 , 5.154193 , 3.6857843],\n",
            "       [4.363952 , 5.649343 , 5.3750134, 3.7133107],\n",
            "       [4.3063393, 5.570685 , 5.3611383, 4.665878 ],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [4.85159  , 5.7435884, 5.3585296, 3.8980427],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [4.84552  , 5.881465 , 4.9715447, 4.4003344],\n",
            "       [5.1273804, 5.6331263, 5.363081 , 4.0982604],\n",
            "       [5.398389 , 6.0822134, 5.839678 , 3.4719236],\n",
            "       [5.176975 , 6.36096  , 5.6904855, 3.4205377],\n",
            "       [5.062474 , 6.0122447, 5.331078 , 3.1522574],\n",
            "       [4.9651937, 5.924982 , 4.487665 , 4.250586 ],\n",
            "       [4.8246965, 6.0336685, 5.3610597, 3.8639128],\n",
            "       [5.2653103, 6.012141 , 4.780554 , 3.9314535],\n",
            "       [5.084965 , 5.946926 , 5.6317973, 3.6526139],\n",
            "       [4.8081913, 6.031557 , 5.5686183, 3.702512 ],\n",
            "       [5.2881737, 5.7641377, 5.8446255, 3.8015864],\n",
            "       [4.807434 , 5.916377 , 5.412886 , 4.3523293],\n",
            "       [5.0136013, 5.962575 , 5.2753987, 3.4219654],\n",
            "       [4.8704023, 5.4471955, 5.029601 , 3.8081985],\n",
            "       [5.1953197, 6.022249 , 5.077474 , 3.8128567],\n",
            "       [5.0419846, 5.7055364, 5.2089896, 4.027127 ],\n",
            "       [5.3571033, 5.798542 , 4.5493894, 4.059462 ],\n",
            "       [4.970275 , 5.305007 , 4.8666253, 3.7456818],\n",
            "       [5.2301664, 5.441677 , 5.166428 , 3.5290647],\n",
            "       [4.487116 , 5.2477927, 5.048561 , 4.243582 ],\n",
            "       [5.0123167, 5.2127857, 5.9853897, 3.1324909],\n",
            "       [4.6873918, 6.0691957, 4.8552   , 4.336426 ],\n",
            "       [4.7573576, 6.0012474, 5.7158823, 4.325933 ],\n",
            "       [5.16407  , 5.8719687, 5.894042 , 3.6181266],\n",
            "       [4.790885 , 5.2166853, 4.697896 , 3.7519424],\n",
            "       [5.3255777, 5.777299 , 5.422639 , 3.5796337],\n",
            "       [5.1815233, 5.5552893, 5.3201656, 3.697865 ],\n",
            "       [5.0599566, 5.7686954, 5.309099 , 3.911624 ],\n",
            "       [4.7658834, 5.090546 , 4.928364 , 3.6949558],\n",
            "       [5.096594 , 5.635899 , 5.6249304, 3.6278963],\n",
            "       [4.942813 , 5.5612454, 5.0567307, 4.2259755],\n",
            "       [5.290231 , 5.6431217, 5.6233606, 3.3279176],\n",
            "       [4.826813 , 5.600778 , 5.308954 , 3.7465053],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [5.206012 , 5.5159454, 4.195504 , 4.2670984],\n",
            "       [4.926238 , 5.7773438, 5.404306 , 3.7121391],\n",
            "       [4.7733884, 5.829868 , 5.0750675, 3.8365397],\n",
            "       [5.084711 , 5.9169374, 5.0873003, 4.294578 ],\n",
            "       [4.873334 , 5.2952433, 5.3801713, 3.482699 ],\n",
            "       [5.1157513, 5.8350554, 5.1195464, 3.6419756],\n",
            "       [5.250126 , 5.879737 , 4.5104113, 4.437215 ],\n",
            "       [4.9762   , 5.7212048, 4.9320374, 3.3531053],\n",
            "       [5.076086 , 5.726789 , 5.1738725, 3.6070232],\n",
            "       [4.7913485, 5.839452 , 5.3298965, 4.0398183],\n",
            "       [5.01227  , 5.7517915, 4.919099 , 3.7974763],\n",
            "       [5.323245 , 5.942122 , 5.275308 , 3.647502 ],\n",
            "       [5.1141386, 5.7961907, 4.82798  , 3.7215285],\n",
            "       [5.360832 , 6.3098497, 5.4748464, 4.3075676],\n",
            "       [4.9178286, 5.7050157, 4.934328 , 3.9219036],\n",
            "       [4.816536 , 5.538459 , 5.270052 , 3.6930828],\n",
            "       [4.805763 , 5.3918304, 5.1270485, 3.992392 ],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [4.757798 , 5.9964185, 4.947455 , 3.6106942],\n",
            "       [5.251835 , 5.684434 , 4.983309 , 4.327415 ],\n",
            "       [5.0051484, 6.0767365, 4.863707 , 3.6800957],\n",
            "       [4.9914465, 6.0212874, 5.171317 , 4.158654 ],\n",
            "       [4.4663377, 5.718251 , 5.316972 , 3.8450987],\n",
            "       [5.696231 , 6.359858 , 5.668625 , 3.3032632],\n",
            "       [4.9911833, 5.1742706, 5.743272 , 3.5011983],\n",
            "       [4.9659085, 5.4072466, 4.9767866, 3.5658932],\n",
            "       [4.6808596, 5.6391926, 5.2131867, 3.9774785],\n",
            "       [5.0120153, 5.6590567, 5.3408623, 3.4606185],\n",
            "       [4.4178057, 5.7058134, 5.127351 , 4.130838 ],\n",
            "       [5.1782537, 5.8023496, 4.8963284, 3.4447536],\n",
            "       [4.813526 , 5.25477  , 5.028115 , 3.502579 ],\n",
            "       [4.685715 , 5.454956 , 5.4908686, 3.2061696],\n",
            "       [4.565806 , 5.395544 , 5.21085  , 3.8339133],\n",
            "       [4.90127  , 5.5720253, 4.832485 , 4.061604 ],\n",
            "       [4.7484713, 5.0892634, 5.218423 , 3.3047793],\n",
            "       [4.8300395, 6.2730536, 5.618327 , 3.9107172],\n",
            "       [4.8093224, 5.097262 , 4.3691683, 4.277158 ],\n",
            "       [4.71187  , 5.4906197, 5.6219516, 3.322145 ],\n",
            "       [5.038304 , 5.7482157, 5.246798 , 3.6766906],\n",
            "       [5.1199045, 6.107428 , 5.2986827, 4.1506577],\n",
            "       [5.122036 , 5.826038 , 4.81662  , 3.978767 ],\n",
            "       [5.343547 , 5.2631207, 5.5426283, 3.1409316],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [4.7468243, 5.989835 , 5.111818 , 4.5322466],\n",
            "       [4.5634966, 5.9285994, 4.8047585, 4.61319  ],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [4.904582 , 5.609743 , 4.7358704, 4.2612524],\n",
            "       [4.776429 , 5.7722034, 5.5330167, 3.57551  ],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [5.200713 , 5.844192 , 5.415365 , 3.697427 ],\n",
            "       [5.1273503, 6.0153084, 5.2588854, 4.0928016],\n",
            "       [5.35352  , 5.3964243, 4.8633347, 3.4703581],\n",
            "       [4.743468 , 5.6412554, 5.0162044, 4.0547833],\n",
            "       [4.7878165, 5.485653 , 4.9008446, 4.102105 ],\n",
            "       [5.2519703, 5.6625667, 5.3170466, 3.5754132],\n",
            "       [5.3933544, 5.742319 , 5.286457 , 3.539204 ],\n",
            "       [5.3326   , 5.8934298, 4.890191 , 4.1353345],\n",
            "       [5.067198 , 5.897637 , 5.7867384, 3.5355449],\n",
            "       [5.134305 , 5.683087 , 4.727359 , 3.8537464],\n",
            "       [4.3813176, 5.5494657, 4.8078136, 3.9790878],\n",
            "       [4.694849 , 5.0867567, 5.3039017, 3.6022708],\n",
            "       [5.0180745, 6.062604 , 5.1302605, 3.9787905],\n",
            "       [4.982939 , 5.955265 , 5.4482226, 3.7022915],\n",
            "       [4.5278983, 5.181503 , 5.4394965, 3.7532768],\n",
            "       [4.6009054, 5.6303444, 4.9911423, 4.2838354],\n",
            "       [5.3846426, 5.5674233, 5.6046433, 3.6545374],\n",
            "       [5.563955 , 6.037652 , 5.0892234, 3.667758 ],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [5.3212156, 5.8681197, 5.072644 , 3.7873216],\n",
            "       [5.2935634, 5.2823215, 5.185128 , 3.4392283],\n",
            "       [4.532456 , 5.122438 , 4.916241 , 4.00981  ],\n",
            "       [4.6790686, 5.285968 , 4.937478 , 3.8410058],\n",
            "       [4.540248 , 5.47573  , 5.113229 , 3.8936362],\n",
            "       [5.0621877, 5.1585846, 5.2739654, 3.4017735],\n",
            "       [4.536838 , 5.474524 , 5.1461797, 3.7830343],\n",
            "       [4.709464 , 5.17333  , 4.8105917, 4.123538 ],\n",
            "       [5.223114 , 6.230966 , 5.4839573, 4.139617 ],\n",
            "       [4.392004 , 5.725899 , 5.198066 , 4.3500795],\n",
            "       [5.113536 , 5.3812084, 5.7762594, 4.095707 ],\n",
            "       [4.69259  , 5.546998 , 5.086712 , 3.8687513],\n",
            "       [4.642261 , 5.7101293, 5.2362785, 3.8919241],\n",
            "       [4.635957 , 5.487583 , 4.955472 , 3.3224132],\n",
            "       [5.1264234, 5.935018 , 4.921022 , 4.504726 ],\n",
            "       [4.3776503, 5.1350136, 5.129021 , 3.9033372],\n",
            "       [5.217887 , 6.035447 , 5.3180895, 3.9708424],\n",
            "       [6.6939487, 6.7226167, 4.4597216, 4.855989 ],\n",
            "       [5.2162013, 6.244759 , 5.8423223, 3.941857 ],\n",
            "       [4.977361 , 5.9826903, 5.055241 , 4.227362 ],\n",
            "       [5.081291 , 5.957977 , 5.441246 , 3.9037213],\n",
            "       [4.5782557, 5.952061 , 5.485358 , 4.2213435],\n",
            "       [4.4623404, 5.8195615, 5.4358864, 4.368415 ],\n",
            "       [5.5686035, 6.1231947, 5.4750366, 3.6269197],\n",
            "       [5.1173234, 5.9556303, 5.1869545, 4.153448 ],\n",
            "       [5.0189886, 5.986299 , 5.0722694, 4.2210636],\n",
            "       [4.5863466, 6.0102873, 5.284889 , 4.223899 ],\n",
            "       [4.657381 , 5.5462894, 5.234599 , 4.0281615],\n",
            "       [4.6725044, 5.99989  , 5.180479 , 4.0687313],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [5.1066723, 5.9167624, 5.1209655, 3.7498918],\n",
            "       [5.009716 , 5.754249 , 5.9278216, 2.9440894],\n",
            "       [4.896501 , 5.87873  , 5.0323563, 3.8831499],\n",
            "       [4.807003 , 5.666415 , 4.4974737, 4.4587746],\n",
            "       [4.7652617, 5.7496443, 5.4132104, 3.7301798],\n",
            "       [5.401837 , 5.4340773, 5.3165326, 4.4100904],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [4.990219 , 6.0790296, 5.023824 , 3.916821 ],\n",
            "       [5.2706227, 6.3508444, 4.9744225, 4.365662 ],\n",
            "       [4.9683747, 5.6788154, 5.0687995, 3.9584842],\n",
            "       [6.4804463, 6.649024 , 4.763307 , 4.492214 ],\n",
            "       [6.107272 , 6.6431265, 5.378894 , 5.290531 ],\n",
            "       [5.3629007, 5.949896 , 5.1778784, 3.5083914],\n",
            "       [5.1837926, 5.8854046, 4.855851 , 4.0074177],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [5.1875014, 5.86095  , 4.9004602, 3.9430904],\n",
            "       [4.5831175, 5.4189177, 5.020998 , 4.070072 ],\n",
            "       [5.125819 , 5.467835 , 4.97397  , 3.7592175],\n",
            "       [4.6882973, 5.2813983, 5.3171067, 3.736014 ],\n",
            "       [4.479501 , 5.6192694, 4.6341963, 4.413346 ],\n",
            "       [4.724601 , 5.4435415, 5.21269  , 3.809259 ],\n",
            "       [4.8537564, 6.046589 , 5.374419 , 4.0769544],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [4.8688765, 5.4687495, 5.25301  , 3.807078 ],\n",
            "       [5.508975 , 5.772194 , 4.928872 , 3.8376987],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [5.1050105, 6.2377567, 5.338348 , 3.9030647],\n",
            "       [5.040991 , 5.6117344, 5.131033 , 3.5297973],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [5.6726007, 6.148215 , 5.5520287, 3.1225646],\n",
            "       [5.4776826, 6.094506 , 5.2964077, 3.826154 ],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [5.260438 , 6.160796 , 5.2913513, 3.925746 ],\n",
            "       [5.1137238, 5.5777426, 4.7628875, 4.1372857],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [4.97795  , 5.611639 , 5.4221435, 3.5985994],\n",
            "       [6.2645717, 6.9460173, 5.7714176, 3.8649073],\n",
            "       [4.989236 , 6.136207 , 5.4302254, 4.5558257],\n",
            "       [4.58968  , 6.1039925, 5.4888635, 3.4756966],\n",
            "       [4.8369846, 5.701251 , 5.220417 , 3.7026782],\n",
            "       [4.941179 , 5.3918495, 4.721305 , 4.2133484],\n",
            "       [4.948424 , 5.899947 , 5.8296103, 3.4288635],\n",
            "       [4.9841614, 5.750005 , 5.2083063, 4.069272 ],\n",
            "       [5.4135294, 6.055401 , 5.7218223, 4.0684543],\n",
            "       [4.6573405, 5.888714 , 5.3498425, 4.025668 ],\n",
            "       [5.3028774, 5.970975 , 5.1204224, 4.1858816],\n",
            "       [4.896154 , 5.570405 , 5.431755 , 3.6028845],\n",
            "       [4.783408 , 5.832339 , 5.428862 , 4.7501698],\n",
            "       [4.8792195, 5.698222 , 5.2789073, 3.96083  ],\n",
            "       [5.003348 , 6.1740427, 5.52254  , 4.278971 ],\n",
            "       [5.13146  , 6.1842947, 5.2863674, 4.309459 ],\n",
            "       [4.6218762, 5.5570345, 5.60756  , 4.1365166],\n",
            "       [5.4374857, 5.9456506, 4.7804794, 3.8964627],\n",
            "       [5.2835946, 6.2057614, 5.50257  , 3.7947464],\n",
            "       [5.0199285, 6.12296  , 5.723757 , 4.110506 ],\n",
            "       [5.054732 , 6.2628837, 5.727763 , 3.546065 ],\n",
            "       [4.9139633, 5.7245975, 5.0023365, 4.1901107],\n",
            "       [5.231114 , 6.0382204, 5.0477395, 3.8588915],\n",
            "       [4.1535454, 4.4480343, 4.4010167, 3.9338312],\n",
            "       [4.858409 , 5.1495667, 5.0588226, 3.598857 ],\n",
            "       [4.8655286, 4.9553127, 4.696623 , 3.7987447],\n",
            "       [4.626877 , 5.9418354, 5.527842 , 4.1567564],\n",
            "       [4.7126307, 5.7013083, 4.8724966, 3.761589 ],\n",
            "       [5.466242 , 6.4302964, 5.6487675, 3.2918339],\n",
            "       [5.0834556, 5.5927663, 5.1713276, 3.78755  ],\n",
            "       [4.7533193, 5.9146795, 5.4534173, 4.3307447],\n",
            "       [4.954299 , 6.2200007, 5.524541 , 4.1595902]], dtype=float32)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8ScY4gSIcYv",
        "colab_type": "code",
        "outputId": "726e795d-18b8-476c-a37f-70e8baa610b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "layer_outs[-1][0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(221, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7LvDA8eI2yK",
        "colab_type": "code",
        "outputId": "5275ce64-4461-4a62-ed7c-351ed48f816b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "|np.argwhere(np.isnan(X_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[128, 320],\n",
              "       [128, 321],\n",
              "       [128, 322],\n",
              "       [128, 323],\n",
              "       [128, 324],\n",
              "       [128, 325],\n",
              "       [128, 326],\n",
              "       [128, 327],\n",
              "       [128, 328],\n",
              "       [128, 329],\n",
              "       [128, 330],\n",
              "       [128, 331],\n",
              "       [128, 332],\n",
              "       [128, 333],\n",
              "       [128, 334],\n",
              "       [151, 320],\n",
              "       [151, 321],\n",
              "       [151, 322],\n",
              "       [151, 323],\n",
              "       [151, 324],\n",
              "       [151, 325],\n",
              "       [151, 326],\n",
              "       [151, 327],\n",
              "       [151, 328],\n",
              "       [151, 329],\n",
              "       [151, 330],\n",
              "       [151, 331],\n",
              "       [151, 332],\n",
              "       [151, 333],\n",
              "       [151, 334],\n",
              "       [152, 320],\n",
              "       [152, 321],\n",
              "       [152, 322],\n",
              "       [152, 323],\n",
              "       [152, 324],\n",
              "       [152, 325],\n",
              "       [152, 326],\n",
              "       [152, 327],\n",
              "       [152, 328],\n",
              "       [152, 329],\n",
              "       [152, 330],\n",
              "       [152, 331],\n",
              "       [152, 332],\n",
              "       [152, 333],\n",
              "       [152, 334],\n",
              "       [183, 320],\n",
              "       [183, 321],\n",
              "       [183, 322],\n",
              "       [183, 323],\n",
              "       [183, 324],\n",
              "       [183, 325],\n",
              "       [183, 326],\n",
              "       [183, 327],\n",
              "       [183, 328],\n",
              "       [183, 329],\n",
              "       [183, 330],\n",
              "       [183, 331],\n",
              "       [183, 332],\n",
              "       [183, 333],\n",
              "       [183, 334]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HAHcwI1OKey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zgbcjkg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN0kYRQQnh74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ug-W3Z2o5_r",
        "colab_type": "text"
      },
      "source": [
        "function ClickConnect() {\n",
        "  console.log('Working')\n",
        "  document\n",
        "    .querySelector('#top-toolbar > colab-connect-button')\n",
        "    .shadowRoot.querySelector('#connect')\n",
        "    .click()\n",
        "}\n",
        "\n",
        "setInterval(ClickConnect, 60000)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h54JH9yo909",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}